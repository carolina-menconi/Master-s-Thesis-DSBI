{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae083fdc-44f6-4204-a9ab-979031ad259a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, duckdb, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import torchvision.transforms as T\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451aa018-0b88-4f80-9de9-72d9291ca3e0",
   "metadata": {},
   "source": [
    "# LOAD EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e63b0684-904e-4f10-84fa-c363cf0c8295",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dir = Path(\"D:/dataset/efficientnetb0_emb\")\n",
    "MODEL_NAME = \"efficientnet_b0\"\n",
    "\n",
    "def load_effnet_split(split_name, emb_dir=emb_dir, model_name=MODEL_NAME):\n",
    "    all_path = emb_dir / f\"{model_name}_{split_name}_ALL.npz\"\n",
    "    data = np.load(all_path, allow_pickle=True)\n",
    "    F = data[\"feats\"]     \n",
    "    P = data[\"post_id\"]   \n",
    "    print(split_name, F.shape, len(P))\n",
    "    return F, P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12df1e42-30d3-4b79-9733-6e90f2347121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (960048, 1280) 960048\n",
      "val (556982, 1280) 556982\n"
     ]
    }
   ],
   "source": [
    "X_train, ids_train = load_effnet_split(\"train\")\n",
    "X_val, ids_val = load_effnet_split(\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e269f19d-65ac-4349-b08b-f9a11245ceb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "post_id unici in ids_train: 773497\n",
      "post_id unici in ids_val: 412325\n"
     ]
    }
   ],
   "source": [
    "unique_posts_tr = len(np.unique(ids_train))\n",
    "unique_posts_va = len(np.unique(ids_val))\n",
    "print(\"post_id unici in ids_train:\", unique_posts_tr)\n",
    "print(\"post_id unici in ids_val:\", unique_posts_va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85f1fe75-c925-4bc1-8536-6b55b2460038",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_by_post(F, P, agg=\"mean\"):\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        \"post_id\": P,\n",
    "        \"feat\": list(F) \n",
    "    })\n",
    "\n",
    "    if agg == \"mean\":\n",
    "        agg_func = lambda arrs: np.mean(np.stack(arrs), axis=0)\n",
    "    elif agg == \"max\":\n",
    "        agg_func = lambda arrs: np.max(np.stack(arrs), axis=0)\n",
    "    else:\n",
    "        raise ValueError(\"agg deve essere 'mean' o 'max'\")\n",
    "\n",
    "    df_post = (\n",
    "        df.groupby(\"post_id\")[\"feat\"]\n",
    "          .apply(agg_func)\n",
    "          .reset_index()\n",
    "    )\n",
    "    return df_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d75209a2-c193-4335-bbef-05edb1f0d65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_img = aggregate_by_post(X_train, ids_train, agg=\"mean\")\n",
    "df_val_img = aggregate_by_post(X_val, ids_val, agg=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee5c6171-49fa-45d6-8ede-241bd53d966e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(773497, 2) (412325, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df_train_img.shape, df_val_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e57ca817-6633-4668-bff5-750e4ced9983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up ready\n"
     ]
    }
   ],
   "source": [
    "DB_PATH = \"D:/db/meta.duckdb\"\n",
    "con = duckdb.connect(DB_PATH)\n",
    "try:\n",
    "    con.execute(\"PRAGMA threads=8;\")\n",
    "except duckdb.InvalidInputException:\n",
    "    pass\n",
    "\n",
    "print(\"Set up ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a685c41f-5510-4da9-b196-339a06c4d2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_ids = con.sql(\"\"\"SELECT post_id, er_bins3 FROM md1718 WHERE split = 'train'\"\"\").df()\n",
    "y_val_ids = con.sql(\"\"\"SELECT post_id, er_bins3 FROM md1718 WHERE split = 'validation'\"\"\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0c8787a-d85a-4134-b400-a4bf7db9a85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train_img.merge(\n",
    "    y_tr_ids[[\"post_id\", \"er_bins3\"]],\n",
    "    on=\"post_id\", how=\"inner\"\n",
    ")\n",
    "\n",
    "df_val = df_val_img.merge(\n",
    "    y_val_ids[[\"post_id\", \"er_bins3\"]],\n",
    "    on=\"post_id\", how=\"inner\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10814d5c-136a-495a-acca-abf2c5c0a030",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = np.stack(df_train[\"feat\"].values)\n",
    "y_tr = df_train[\"er_bins3\"].values\n",
    "\n",
    "X_va = np.stack(df_val[\"feat\"].values)\n",
    "y_va = df_val[\"er_bins3\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08eed57e-01af-48f2-a897-e18c5f53d84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(773497, 1280) (412325, 1280) (773497,) (412325,)\n"
     ]
    }
   ],
   "source": [
    "print(X_tr.shape, X_va.shape, y_tr.shape, y_va.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e62733dc-6d45-4059-b1c2-9df01894c791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    100pintas-1769662389073991144\n",
       "1    100pintas-1782702664733979876\n",
       "2    100pintas-1797067212467389817\n",
       "3    100pintas-1807955339238986900\n",
       "4    100pintas-1808039696742034708\n",
       "Name: post_id, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['post_id'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd2cd3c9-0606-4c80-bf39-fafa057d27a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['medium', 'medium', 'medium', 'medium', 'high'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83f0642a-400d-43f6-bec1-f67f24fc9b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_tr = df_train['post_id'].values\n",
    "ids_va = df_val['post_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0aa0e5d-b1f9-4057-90cf-f4da111ec394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del X_train, X_val, df_train, df_train_img, df_val, df_val_img, ids_train, ids_val, y_tr_ids, y_val_ids\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca223ce7-31d1-4fc7-9a5e-71597bdb3248",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\n",
    "    \"D:/dataset/efficientnetb0_emb/train_data_3.npz\",\n",
    "    X=X_tr,\n",
    "    y=y_tr,\n",
    "    ids = ids_tr\n",
    ")\n",
    "\n",
    "np.savez_compressed(\n",
    "    \"D:/dataset/efficientnetb0_emb/val_data_3.npz\",\n",
    "    X=X_va,\n",
    "    y=y_va,\n",
    "    ids = ids_va\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60dd2a02-42e7-4c0d-b9af-aa772d824a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "579"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = np.load(\"D:/dataset/efficientnetb0_emb/train_data_3.npz\", allow_pickle = True)\n",
    "X_tr = train_data[\"X\"]\n",
    "y_tr = train_data[\"y\"]\n",
    "\n",
    "val_data = np.load(\"D:/dataset/efficientnetb0_emb/val_data_3.npz\", allow_pickle = True)\n",
    "X_va = val_data[\"X\"]\n",
    "y_va = val_data[\"y\"]\n",
    "\n",
    "del train_data, val_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dbe6e6c-1807-45f8-b6ab-ad6751bdc511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination: {'alpha': 1e-05, 'class_weight': None}\n",
      "macro-F1 (val): 0.40787615140160755 | accuracy (val): 0.4142169405202207\n",
      "\n",
      "Combination: {'alpha': 1e-05, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.3984984384307299 | accuracy (val): 0.41779421572788455\n",
      "\n",
      "Combination: {'alpha': 0.0001, 'class_weight': None}\n",
      "macro-F1 (val): 0.4068502983466689 | accuracy (val): 0.4146995695143394\n",
      "\n",
      "Combination: {'alpha': 0.0001, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.396013011089475 | accuracy (val): 0.41826714363669437\n",
      "\n",
      "Combination: {'alpha': 0.001, 'class_weight': None}\n",
      "macro-F1 (val): 0.40344063465924057 | accuracy (val): 0.41383617292184566\n",
      "\n",
      "Combination: {'alpha': 0.001, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.3894171511357631 | accuracy (val): 0.4165379251803796\n",
      "\n",
      "Combination: {'alpha': 0.01, 'class_weight': None}\n",
      "macro-F1 (val): 0.4010127675288108 | accuracy (val): 0.4119153580306797\n",
      "\n",
      "Combination: {'alpha': 0.01, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.38539996979673163 | accuracy (val): 0.4137003577275208\n",
      "\n",
      "Best hyperparameter configuration:\n",
      "{'alpha': 1e-05, 'class_weight': None}\n",
      "Validation macro-F1: 0.40787615140160755\n",
      "\n",
      "Ordered results by macro-F1 (validation):\n",
      "     alpha class_weight  val_macro_f1  val_accuracy\n",
      "0  0.00001         None      0.407876      0.414217\n",
      "2  0.00010         None      0.406850      0.414700\n",
      "4  0.00100         None      0.403441      0.413836\n",
      "6  0.01000         None      0.401013      0.411915\n",
      "1  0.00001     balanced      0.398498      0.417794\n",
      "3  0.00010     balanced      0.396013      0.418267\n",
      "5  0.00100     balanced      0.389417      0.416538\n",
      "7  0.01000     balanced      0.385400      0.413700\n"
     ]
    }
   ],
   "source": [
    "# SGD\n",
    "param_grid = {\n",
    "    \"alpha\": [1e-5, 1e-4, 1e-3, 1e-2],\n",
    "    \"class_weight\": [None, \"balanced\"],\n",
    "}\n",
    "\n",
    "results = []\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    print(f\"\\nCombination: {params}\")\n",
    "\n",
    "    clf = SGDClassifier(\n",
    "        loss=\"hinge\",            \n",
    "        penalty=\"l2\",            \n",
    "        **params,\n",
    "        average = True,\n",
    "        random_state=42,\n",
    "        max_iter=1000,\n",
    "        tol=1e-3,\n",
    "    )\n",
    "\n",
    "    clf.fit(X_tr, y_tr)\n",
    "\n",
    "    y_val_pred = clf.predict(X_va)\n",
    "\n",
    "    macro_f1 = f1_score(y_va, y_val_pred, average=\"macro\")\n",
    "    acc = accuracy_score(y_va, y_val_pred)\n",
    "\n",
    "    print(f\"macro-F1 (val): {macro_f1} | accuracy (val): {acc}\")\n",
    "\n",
    "    results.append({\n",
    "        \"alpha\": params[\"alpha\"],\n",
    "        \"class_weight\": params[\"class_weight\"],\n",
    "        \"val_macro_f1\": macro_f1,\n",
    "        \"val_accuracy\": acc,\n",
    "    })\n",
    "\n",
    "    if macro_f1 > best_score:\n",
    "        best_score = macro_f1\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\nBest hyperparameter configuration:\")\n",
    "print(best_params)\n",
    "print(\"Validation macro-F1:\", best_score)\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(\"val_macro_f1\", ascending=False)\n",
    "print(\"\\nOrdered results by macro-F1 (validation):\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71392ce0-defc-4261-80fe-df3205eb247f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination: {'var_smoothing': 1e-09}\n",
      "macro-F1 (val): 0.3726 | accuracy (val): 0.4114\n",
      "\n",
      "Combination: {'var_smoothing': 1e-08}\n",
      "macro-F1 (val): 0.3726 | accuracy (val): 0.4114\n",
      "\n",
      "Combination: {'var_smoothing': 1e-07}\n",
      "macro-F1 (val): 0.3726 | accuracy (val): 0.4114\n",
      "\n",
      "Combination: {'var_smoothing': 1e-06}\n",
      "macro-F1 (val): 0.3726 | accuracy (val): 0.4114\n",
      "\n",
      "Best hyperparameter configuration:\n",
      "{'var_smoothing': 1e-09}\n",
      "Validation macro-F1: 0.37261486210082356\n",
      "\n",
      "Ordered results by macro-F1 (validation):\n",
      "   var_smoothing  val_macro_f1  val_accuracy\n",
      "0   1.000000e-09      0.372615      0.411362\n",
      "1   1.000000e-08      0.372615      0.411362\n",
      "2   1.000000e-07      0.372615      0.411362\n",
      "3   1.000000e-06      0.372615      0.411362\n"
     ]
    }
   ],
   "source": [
    "# NAIVE BAYES - GAUSSIAN\n",
    "param_grid_nb = {\n",
    "    \"var_smoothing\": [1e-9, 1e-8, 1e-7, 1e-6]\n",
    "}\n",
    "\n",
    "results = []\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "for params in ParameterGrid(param_grid_nb):\n",
    "    print(f\"\\nCombination: {params}\")\n",
    "\n",
    "    clf = GaussianNB(**params)\n",
    "\n",
    "    # Fit su TRAIN\n",
    "    clf.fit(X_tr, y_tr)\n",
    "\n",
    "    # Valutazione su VALIDATION\n",
    "    y_val_pred = clf.predict(X_va)\n",
    "\n",
    "    macro_f1 = f1_score(y_va, y_val_pred, average=\"macro\")\n",
    "    acc = accuracy_score(y_va, y_val_pred)\n",
    "\n",
    "    print(f\"macro-F1 (val): {macro_f1:.4f} | accuracy (val): {acc:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        \"var_smoothing\": params[\"var_smoothing\"],\n",
    "        \"val_macro_f1\": macro_f1,\n",
    "        \"val_accuracy\": acc,\n",
    "    })\n",
    "\n",
    "    # Aggiorno il best model in base alla macro-F1\n",
    "    if macro_f1 > best_score:\n",
    "        best_score = macro_f1\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\nBest hyperparameter configuration:\")\n",
    "print(best_params)\n",
    "print(\"Validation macro-F1:\", best_score)\n",
    "\n",
    "# Metto i risultati in un DataFrame per ispezionarli meglio\n",
    "results_df = pd.DataFrame(results).sort_values(\"val_macro_f1\", ascending=False)\n",
    "print(\"\\nOrdered results by macro-F1 (validation):\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcd977dd-eee2-4719-8a5f-dedf9da36971",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.3989 | accuracy (val): 0.3981\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.4000 | accuracy (val): 0.3991\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.4005 | accuracy (val): 0.3996\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.3998 | accuracy (val): 0.3989\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.4005 | accuracy (val): 0.3995\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.4011 | accuracy (val): 0.4001\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.3947 | accuracy (val): 0.3954\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.3951 | accuracy (val): 0.3958\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.3953 | accuracy (val): 0.3961\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.3949 | accuracy (val): 0.3954\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.3949 | accuracy (val): 0.3956\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.3953 | accuracy (val): 0.3960\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.4032 | accuracy (val): 0.4018\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.4048 | accuracy (val): 0.4033\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.4061 | accuracy (val): 0.4046\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.4035 | accuracy (val): 0.4020\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.4052 | accuracy (val): 0.4037\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.4055 | accuracy (val): 0.4040\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.4011 | accuracy (val): 0.3998\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.4023 | accuracy (val): 0.4011\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.4029 | accuracy (val): 0.4017\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.4022 | accuracy (val): 0.4009\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.4031 | accuracy (val): 0.4019\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.4034 | accuracy (val): 0.4022\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.4022 | accuracy (val): 0.4008\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.4046 | accuracy (val): 0.4032\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.4062 | accuracy (val): 0.4047\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.4031 | accuracy (val): 0.4018\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.4057 | accuracy (val): 0.4044\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.4076 | accuracy (val): 0.4062\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.4023 | accuracy (val): 0.4011\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.4047 | accuracy (val): 0.4034\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.4064 | accuracy (val): 0.4049\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.4019 | accuracy (val): 0.4006\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.4040 | accuracy (val): 0.4026\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.4060 | accuracy (val): 0.4045\n",
      "\n",
      "Best hyperparameter configuration (Random Forest):\n",
      "{'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "Validation macro-F1: 0.40758837082971205\n",
      "\n",
      "Ordered results by macro-F1 (validation):\n",
      "    n_estimators  max_depth  min_samples_leaf max_features  val_macro_f1  \\\n",
      "29            80         12                 5         0.05      0.407588   \n",
      "32            80         12                 2         sqrt      0.406388   \n",
      "26            80         12                 2         0.05      0.406177   \n",
      "14            80         10                 2         0.05      0.406133   \n",
      "35            80         12                 5         sqrt      0.405991   \n",
      "28            50         12                 5         0.05      0.405721   \n",
      "17            80         10                 5         0.05      0.405545   \n",
      "16            50         10                 5         0.05      0.405233   \n",
      "13            50         10                 2         0.05      0.404804   \n",
      "31            50         12                 2         sqrt      0.404698   \n",
      "25            50         12                 2         0.05      0.404631   \n",
      "34            50         12                 5         sqrt      0.404029   \n",
      "15            30         10                 5         0.05      0.403479   \n",
      "23            80         10                 5         sqrt      0.403427   \n",
      "12            30         10                 2         0.05      0.403249   \n",
      "22            50         10                 5         sqrt      0.403149   \n",
      "27            30         12                 5         0.05      0.403056   \n",
      "20            80         10                 2         sqrt      0.402901   \n",
      "30            30         12                 2         sqrt      0.402338   \n",
      "19            50         10                 2         sqrt      0.402319   \n",
      "21            30         10                 5         sqrt      0.402188   \n",
      "24            30         12                 2         0.05      0.402180   \n",
      "33            30         12                 5         sqrt      0.401851   \n",
      "5             80          8                 5         0.05      0.401087   \n",
      "18            30         10                 2         sqrt      0.401069   \n",
      "4             50          8                 5         0.05      0.400539   \n",
      "2             80          8                 2         0.05      0.400477   \n",
      "1             50          8                 2         0.05      0.399967   \n",
      "3             30          8                 5         0.05      0.399831   \n",
      "0             30          8                 2         0.05      0.398863   \n",
      "11            80          8                 5         sqrt      0.395338   \n",
      "8             80          8                 2         sqrt      0.395325   \n",
      "7             50          8                 2         sqrt      0.395138   \n",
      "10            50          8                 5         sqrt      0.394934   \n",
      "9             30          8                 5         sqrt      0.394877   \n",
      "6             30          8                 2         sqrt      0.394657   \n",
      "\n",
      "    val_accuracy  \n",
      "29      0.406206  \n",
      "32      0.404928  \n",
      "26      0.404722  \n",
      "14      0.404569  \n",
      "35      0.404484  \n",
      "28      0.404407  \n",
      "17      0.403956  \n",
      "16      0.403677  \n",
      "13      0.403277  \n",
      "31      0.403359  \n",
      "25      0.403204  \n",
      "34      0.402590  \n",
      "15      0.402032  \n",
      "23      0.402192  \n",
      "12      0.401773  \n",
      "22      0.401918  \n",
      "27      0.401834  \n",
      "20      0.401669  \n",
      "30      0.401094  \n",
      "19      0.401101  \n",
      "21      0.400941  \n",
      "24      0.400837  \n",
      "33      0.400565  \n",
      "5       0.400126  \n",
      "18      0.399801  \n",
      "4       0.399544  \n",
      "2       0.399631  \n",
      "1       0.399093  \n",
      "3       0.398882  \n",
      "0       0.398128  \n",
      "11      0.395967  \n",
      "8       0.396078  \n",
      "7       0.395843  \n",
      "10      0.395620  \n",
      "9       0.395443  \n",
      "6       0.395392  \n"
     ]
    }
   ],
   "source": [
    "# RANDOM FOREST\n",
    "param_grid_rf = {\n",
    "    \"n_estimators\": [30, 50, 80],\n",
    "    \"max_depth\": [8, 10, 12],\n",
    "    \"min_samples_leaf\": [2, 5],\n",
    "    \"max_features\": [0.05, \"sqrt\"],\n",
    "}\n",
    "\n",
    "results = []\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "for params in ParameterGrid(param_grid_rf):\n",
    "    print(f\"\\nCombination: {params}\")\n",
    "\n",
    "    clf = RandomForestClassifier(\n",
    "        **params,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Fit su TRAIN\n",
    "    clf.fit(X_tr, y_tr)\n",
    "\n",
    "    # Valutazione su VALIDATION\n",
    "    y_val_pred = clf.predict(X_va)\n",
    "\n",
    "    macro_f1 = f1_score(y_va, y_val_pred, average=\"macro\")\n",
    "    acc = accuracy_score(y_va, y_val_pred)\n",
    "\n",
    "    print(f\"macro-F1 (val): {macro_f1:.4f} | accuracy (val): {acc:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        \"n_estimators\": params[\"n_estimators\"],\n",
    "        \"max_depth\": params[\"max_depth\"],\n",
    "        \"min_samples_leaf\": params[\"min_samples_leaf\"],\n",
    "        \"max_features\": params[\"max_features\"],\n",
    "        \"val_macro_f1\": macro_f1,\n",
    "        \"val_accuracy\": acc,\n",
    "    })\n",
    "\n",
    "    # Aggiorno il best model in base alla macro-F1\n",
    "    if macro_f1 > best_score:\n",
    "        best_score = macro_f1\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\nBest hyperparameter configuration (Random Forest):\")\n",
    "print(best_params)\n",
    "print(\"Validation macro-F1:\", best_score)\n",
    "\n",
    "# Metto i risultati in un DataFrame per ispezionarli meglio\n",
    "results_df_rf = pd.DataFrame(results).sort_values(\"val_macro_f1\", ascending=False)\n",
    "print(\"\\nOrdered results by macro-F1 (validation):\")\n",
    "print(results_df_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f13c643e-4f04-4495-b38a-63887c62b53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.4112 | accuracy (val): 0.4138\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 150, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.4125 | accuracy (val): 0.4158\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.4136 | accuracy (val): 0.4170\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 150, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.4151 | accuracy (val): 0.4186\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.4112 | accuracy (val): 0.4138\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 150, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.4125 | accuracy (val): 0.4158\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.4140 | accuracy (val): 0.4173\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 150, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.4149 | accuracy (val): 0.4183\n",
      "\n",
      "Best hyperparameter configuration (XGBoost):\n",
      "{'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 150, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "Validation macro-F1: 0.41511333119182\n",
      "\n",
      "Ordered results:\n",
      "   colsample_bytree  gamma  learning_rate  max_depth  n_estimators  \\\n",
      "3               0.5      0            0.1          6           150   \n",
      "7               0.5      1            0.1          6           150   \n",
      "6               0.5      1            0.1          6           100   \n",
      "2               0.5      0            0.1          6           100   \n",
      "5               0.5      1            0.1          4           150   \n",
      "1               0.5      0            0.1          4           150   \n",
      "0               0.5      0            0.1          4           100   \n",
      "4               0.5      1            0.1          4           100   \n",
      "\n",
      "   reg_lambda  subsample  val_macro_f1  val_accuracy  \n",
      "3           1        0.8      0.415113      0.418607  \n",
      "7           1        0.8      0.414869      0.418325  \n",
      "6           1        0.8      0.414020      0.417292  \n",
      "2           1        0.8      0.413628      0.416989  \n",
      "5           1        0.8      0.412455      0.415837  \n",
      "1           1        0.8      0.412455      0.415837  \n",
      "0           1        0.8      0.411157      0.413822  \n",
      "4           1        0.8      0.411157      0.413822  \n"
     ]
    }
   ],
   "source": [
    "# XGBOOST\n",
    "\n",
    "# Convert the labels into numbers\n",
    "le = LabelEncoder()\n",
    "y_tr_enc = le.fit_transform(y_tr)\n",
    "y_val_enc = le.transform(y_va)\n",
    "\n",
    "\n",
    "param_grid_xgb = {\n",
    "    \"n_estimators\": [100, 150],\n",
    "    \"max_depth\": [4, 6],\n",
    "    \"learning_rate\": [0.1],\n",
    "    \"subsample\": [0.8],\n",
    "    \"colsample_bytree\": [0.5],\n",
    "    \"gamma\": [0, 1],\n",
    "    \"reg_lambda\": [1],\n",
    "}\n",
    "\n",
    "results = []\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "for params in ParameterGrid(param_grid_xgb):\n",
    "    print(f\"\\nCombination: {params}\")\n",
    "\n",
    "    clf = XGBClassifier(\n",
    "        **params,\n",
    "        objective=\"multi:softmax\",\n",
    "        num_class=len(np.unique(y_tr_enc)),\n",
    "        tree_method=\"hist\",\n",
    "        eval_metric=\"mlogloss\",\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        verbosity=0,\n",
    "    )\n",
    "\n",
    "    # Fit\n",
    "    clf.fit(X_tr, y_tr_enc)\n",
    "\n",
    "    # Validation\n",
    "    y_val_pred = clf.predict(X_va)\n",
    "\n",
    "    macro_f1 = f1_score(y_val_enc, y_val_pred, average=\"macro\")\n",
    "    acc = accuracy_score(y_val_enc, y_val_pred)\n",
    "\n",
    "    print(f\"macro-F1 (val): {macro_f1:.4f} | accuracy (val): {acc:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        **params,\n",
    "        \"val_macro_f1\": macro_f1,\n",
    "        \"val_accuracy\": acc,\n",
    "    })\n",
    "\n",
    "    if macro_f1 > best_score:\n",
    "        best_score = macro_f1\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\nBest hyperparameter configuration (XGBoost):\")\n",
    "print(best_params)\n",
    "print(\"Validation macro-F1:\", best_score)\n",
    "\n",
    "results_df_xgb = pd.DataFrame(results).sort_values(\"val_macro_f1\", ascending=False)\n",
    "print(\"\\nOrdered results:\")\n",
    "print(results_df_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861b278d-5913-40c3-badd-0006715e6484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PERFORMANCE SUL TEST SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a55aa3d-d944-4cbd-ac7f-88c628aff286",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dir = Path(\"D:/dataset/efficientnetb0_emb\")\n",
    "MODEL_NAME = \"efficientnet_b0\"  # stesso nome di prima\n",
    "\n",
    "def load_effnet_split(split_name, emb_dir=emb_dir, model_name=MODEL_NAME):\n",
    "    all_path = emb_dir / f\"{model_name}_{split_name}_ALL.npz\"\n",
    "    data = np.load(all_path, allow_pickle=True)\n",
    "    F = data[\"feats\"]      # shape: [N_images, feat_dim]\n",
    "    P = data[\"post_id\"]    # shape: [N_images], dtype=object (stringhe/ID)\n",
    "    print(split_name, F.shape, len(P))\n",
    "    return F, P\n",
    "\n",
    "def aggregate_by_post(F, P, agg=\"mean\"):\n",
    "    # F: [N_img, D], P: [N_img]\n",
    "    df = pd.DataFrame({\n",
    "        \"post_id\": P,\n",
    "        \"feat\": list(F)  # ogni riga Ã¨ un array 1D di lunghezza D\n",
    "    })\n",
    "\n",
    "    if agg == \"mean\":\n",
    "        agg_func = lambda arrs: np.mean(np.stack(arrs), axis=0)\n",
    "    elif agg == \"max\":\n",
    "        agg_func = lambda arrs: np.max(np.stack(arrs), axis=0)\n",
    "    else:\n",
    "        raise ValueError(\"agg deve essere 'mean' o 'max'\")\n",
    "\n",
    "    df_post = (\n",
    "        df.groupby(\"post_id\")[\"feat\"]\n",
    "          .apply(agg_func)\n",
    "          .reset_index()\n",
    "    )\n",
    "    # df_post: colonne = [\"post_id\", \"feat\"], UN record per post\n",
    "    return df_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c36758b-6aea-4492-9a5e-cbb6526dd429",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, ids_train = load_effnet_split(\"train\")\n",
    "# X_val, ids_val = load_effnet_split(\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "deb372ec-6b7b-4666-9632-884c9b03a6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "post_id unici in ids_train: 773497\n",
      "post_id unici in ids_val: 412325\n"
     ]
    }
   ],
   "source": [
    "unique_posts_tr = len(np.unique(ids_train))\n",
    "# unique_posts_va = len(np.unique(ids_val))\n",
    "print(\"post_id unici in ids_train:\", unique_posts_tr)\n",
    "# print(\"post_id unici in ids_val:\", unique_posts_va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "584892bd-b43c-44bb-9769-7336e32f3baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del unique_posts_tr, unique_posts_va, X_val\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34e5be66-3166-40b1-b072-4f1de493753f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_img = aggregate_by_post(X_train, ids_train, agg=\"mean\")\n",
    "# df_val_img = aggregate_by_post(X_val, ids_val, agg=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1952b415-b3f6-41f2-8f00-7ccf583c1baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(773497, 2) (412325, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df_train_img.shape, df_val_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "977e87c2-5357-4a62-893a-690f842a7874",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train, X_val\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "728ba2ed-f656-470a-90ce-ebae8e5bd7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up ready\n"
     ]
    }
   ],
   "source": [
    "DB_PATH = \"D:/db/meta.duckdb\"\n",
    "con = duckdb.connect(DB_PATH)\n",
    "try:\n",
    "    con.execute(\"PRAGMA threads=8;\")\n",
    "except duckdb.InvalidInputException:\n",
    "    pass\n",
    "\n",
    "print(\"Set up ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82edbd0e-3c3d-4543-b4d6-4a1d92c6f5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_ids = con.sql(\"\"\"SELECT post_id, er_bins3 FROM md1718 WHERE split = 'train'\"\"\").df()\n",
    "y_val_ids = con.sql(\"\"\"SELECT post_id, er_bins3 FROM md1718 WHERE split = 'validation'\"\"\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "219bdf85-4805-4093-aec1-4bd61f16cf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train_img.merge(\n",
    "    y_tr_ids[[\"post_id\", \"er_bins3\"]],\n",
    "    on=\"post_id\", how=\"inner\"\n",
    ")\n",
    "\n",
    "df_val = df_val_img.merge(\n",
    "    y_val_ids[[\"post_id\", \"er_bins3\"]],\n",
    "    on=\"post_id\", how=\"inner\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2904851-6904-49d7-bd87-6c93d74d3b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_train_img, df_val_img\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce57abb7-9d2c-4ec8-a356-4152ed1e833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = np.stack(df_train[\"feat\"].values)\n",
    "y_tr = df_train[\"er_bins3\"].values\n",
    "\n",
    "X_va = np.stack(df_val[\"feat\"].values)\n",
    "y_va = df_val[\"er_bins3\"].values\n",
    "\n",
    "X_trva = np.concatenate((X_tr, X_va), axis = 0)\n",
    "y_trva = np.concatenate((y_tr, y_va), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ba31393-fc16-4cbe-b46a-54d17269878f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1185822, 1280) (1185822,)\n"
     ]
    }
   ],
   "source": [
    "print(X_trva.shape, y_trva.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44d05af0-773b-4b20-a2e9-78faa4ea8231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "477"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_train, df_val\n",
    "del ids_train, ids_val, y_tr_ids, y_val_ids\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7974d5d1-d535-40fd-b2eb-e98b2c5225e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\n",
    "    \"D:/dataset/efficientnetb0_emb/trainval_data_3.npz\",\n",
    "    X=X_trva,\n",
    "    y=y_trva\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "960bb1bc-3402-45bb-9093-fca3fd53d08e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del X_tr, X_va, y_tr, y_va, X_trva, y_trva\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b313763a-967d-4999-a5cd-bd6f3d79aa47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test (588557, 1280) 588557\n",
      "post_id unici in ids_te: 423604\n",
      "(423604, 2)\n"
     ]
    }
   ],
   "source": [
    "X_test, ids_test = load_effnet_split(\"test\")\n",
    "unique_posts_te = len(np.unique(ids_test))\n",
    "print(\"post_id unici in ids_te:\", unique_posts_te)\n",
    "del unique_posts_te\n",
    "gc.collect()\n",
    "df_test_img = aggregate_by_post(X_test, ids_test, agg=\"mean\")\n",
    "print(df_test_img.shape)\n",
    "del X_test\n",
    "gc.collect()\n",
    "y_test_ids = con.sql(\"\"\"SELECT post_id, er_bins3 FROM md1718 WHERE split = 'test'\"\"\").df()\n",
    "df_test = df_test_img.merge(\n",
    "    y_test_ids[[\"post_id\", \"er_bins3\"]],\n",
    "    on=\"post_id\", how=\"inner\"\n",
    ")\n",
    "\n",
    "X_te = np.stack(df_test[\"feat\"].values)\n",
    "y_te = df_test[\"er_bins3\"].values\n",
    "\n",
    "np.savez_compressed(\n",
    "    \"D:/dataset/efficientnetb0_emb/test_data_3.npz\",\n",
    "    X=X_te,\n",
    "    y=y_te\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e63b0408-0e6f-4bc2-9fee-261480a73251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del ids_test, df_test_img, y_test_ids, df_test, X_te, y_te\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d6bae14-6687-4a3b-aa91-9a898cb6af31",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(\"D:/dataset/efficientnetb0_emb/trainval_data_3.npz\", allow_pickle = True)\n",
    "X_tr = train_data[\"X\"]\n",
    "y_tr = train_data[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43484cbe-7e70-4fd1-ab23-aad32fddebbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = np.load(\"D:/dataset/efficientnetb0_emb/test_data_3.npz\", allow_pickle = True)\n",
    "X_te = test_data[\"X\"]\n",
    "y_te = test_data[\"y\"]\n",
    "\n",
    "del test_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96f6030e-abdd-4f15-94c0-bfd4e3cc5b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(773497, 1280) (423604, 1280) (773497,) (423604,)\n"
     ]
    }
   ],
   "source": [
    "print(X_tr.shape, X_te.shape, y_tr.shape, y_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f24a4f7-c9f7-49ea-9609-cfdf2e7930fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_tr_enc = le.fit_transform(y_tr)\n",
    "y_te_enc = le.transform(y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0475184a-3454-4ca7-a250-fcf34aff5188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configuration: GaussianNB()\n",
      "macro-F1 (test): 0.3747 | accuracy (test): 0.4116\n",
      "\n",
      "Configuration: RandomForestClassifier(max_depth=12, max_features=0.05, min_samples_leaf=5,\n",
      "                       n_estimators=80, n_jobs=-1, random_state=42)\n",
      "macro-F1 (test): 0.4063 | accuracy (test): 0.4048\n",
      "\n",
      "Configuration: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.5, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric='mlogloss',\n",
      "              feature_types=None, feature_weights=None, gamma=0,\n",
      "              grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=150, n_jobs=-1, num_class=3, ...)\n",
      "macro-F1 (test): 0.4141 | accuracy (test): 0.4176\n"
     ]
    }
   ],
   "source": [
    "cfgs = [\n",
    "    GaussianNB(var_smoothing = 1e-09),\n",
    "    RandomForestClassifier(\n",
    "        max_depth=12, max_features=0.05, min_samples_leaf=5, n_estimators=80, n_jobs=-1, random_state=42\n",
    "    ),\n",
    "    XGBClassifier(colsample_bytree = 0.5, gamma = 0, learning_rate = 0.1, max_depth= 6, n_estimators= 150, reg_lambda= 1, subsample= 0.8,\n",
    "        objective=\"multi:softmax\",\n",
    "        num_class=len(np.unique(y_tr_enc)),\n",
    "        tree_method=\"hist\", eval_metric=\"mlogloss\",\n",
    "        n_jobs=-1, random_state=42, verbosity=0\n",
    "    )\n",
    "]\n",
    "\n",
    "for cfg in cfgs:\n",
    "    print(f\"\\nConfiguration: {cfg}\")\n",
    "\n",
    "    # XGB requires a numerical target\n",
    "    if isinstance(cfg, XGBClassifier):\n",
    "        cfg.fit(X_tr, y_tr_enc)\n",
    "        y_te_pred = cfg.predict(X_te)\n",
    "        macro_f1 = f1_score(y_te_enc, y_te_pred, average=\"macro\")\n",
    "        acc = accuracy_score(y_te_enc, y_te_pred)\n",
    "\n",
    "    else:\n",
    "        cfg.fit(X_tr, y_tr)\n",
    "        y_te_pred = cfg.predict(X_te)\n",
    "        macro_f1 = f1_score(y_te, y_te_pred, average=\"macro\")\n",
    "        acc = accuracy_score(y_te, y_te_pred)\n",
    "\n",
    "    print(f\"macro-F1 (test): {macro_f1:.4f} | accuracy (test): {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cc5eb4f-d52f-4015-94b0-16781a7f3c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macro-F1 (test): 0.4072 | accuracy (test): 0.4141\n"
     ]
    }
   ],
   "source": [
    "cfg = SGDClassifier(\n",
    "        loss=\"hinge\",\n",
    "        penalty=\"l2\",\n",
    "        alpha = 1e-05,\n",
    "        average = True,\n",
    "        class_weight = None,\n",
    "        random_state=42,\n",
    "        max_iter=1000,\n",
    "        tol=1e-3,\n",
    "    )\n",
    "\n",
    "\n",
    "cfg.fit(X_tr, y_tr)\n",
    "y_te_pred = cfg.predict(X_te)\n",
    "macro_f1 = f1_score(y_te, y_te_pred, average=\"macro\")\n",
    "acc = accuracy_score(y_te, y_te_pred)\n",
    "\n",
    "print(f\"macro-F1 (test): {macro_f1:.4f} | accuracy (test): {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638db0eb-5650-409d-9fe9-8fa63ae71b8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (CLIP Env)",
   "language": "python",
   "name": "clip_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
