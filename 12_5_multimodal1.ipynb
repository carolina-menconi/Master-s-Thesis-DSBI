{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a15947b-e3ce-4705-84d9-2c2be9b3f73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb, os, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import load_npz, hstack, save_npz, vstack\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2bc8367-b35a-453b-bc71-af553d9ebc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up ready\n"
     ]
    }
   ],
   "source": [
    "DB_PATH = \"D:/db/meta.duckdb\"\n",
    "con = duckdb.connect(DB_PATH)\n",
    "try:\n",
    "    con.execute(\"PRAGMA threads=8;\")\n",
    "except duckdb.InvalidInputException:\n",
    "    pass\n",
    "\n",
    "print(\"Set up ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7286d1ab-90ec-4656-8f7d-39800fce5320",
   "metadata": {},
   "source": [
    "# SET UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "867af6b3-3d5a-4aa0-af79-a489bd381a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['filename', 'username', 'like_count', 'comment_count', 'width', 'height', 'time_utc', 'caption', 'aspect_ratio', 'area', 'orientation', 'date_day', 'dow', 'hour_utc', 'has_caption', 'caption_len_char', 'month', 'year', 'n_hashtags', 'n_mentions', 'n_urls', 'n_emojis', 'category', 'followers', 'followees', 'posts', 'engagement_rate', 'er_log', 'er_bins', 'post_id', 'caption_language', 'caption_clean', 'caption_lang', 'caption_tfidf', 'caption_bert_clip', 'split', 'in_train_balanced', 'er_bins3', 'er_bins2']\n"
     ]
    }
   ],
   "source": [
    "# RETRIVE METADATA - CHECK FEATURES\n",
    "columns = con.sql(\"\"\"PRAGMA table_info(md1718)\"\"\").fetchdf()\n",
    "print(columns['name'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47e1a3b5-7243-4bae-bf48-dc4d46d521f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5c784a26abd424aa85eaa5b295c35a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecd3abf10a164e788633feb9d94d3830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metadata_tr = con.sql(\"\"\"SELECT * FROM md1718 WHERE split = 'train'\"\"\").df()\n",
    "metadata_val = con.sql(\"\"\"SELECT * FROM md1718 WHERE split = 'validation'\"\"\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ace0455f-76e6-453e-838f-2e2c6dfb883c",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_exclude = ['filename', 'username', 'like_count', 'comment_count', 'caption', 'followers', 'engagement_rate', 'er_log', 'caption_language', 'caption_tfidf', 'caption_bert_clip',\n",
    "                  'er_bins', 'split', 'in_train_balanced', 'time_utc', 'date_day', 'caption_lang', 'caption_clean']\n",
    "\n",
    "feature_columns = [col for col in metadata_tr.columns if col not in col_to_exclude]\n",
    "\n",
    "y_tr = metadata_tr['er_bins']\n",
    "y_val = metadata_val['er_bins']\n",
    "\n",
    "meta_tr = metadata_tr[feature_columns]\n",
    "meta_val = metadata_val[feature_columns] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cfd3133-4756-425a-ad9b-23cde1c76396",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "width                 int32\n",
       "height                int32\n",
       "aspect_ratio        float64\n",
       "area                  int32\n",
       "orientation          object\n",
       "dow                   int64\n",
       "hour_utc              int64\n",
       "has_caption            bool\n",
       "caption_len_char      Int64\n",
       "month                 int64\n",
       "year                  int64\n",
       "n_hashtags            int64\n",
       "n_mentions            int64\n",
       "n_urls                int64\n",
       "n_emojis              int64\n",
       "category             object\n",
       "followees             int32\n",
       "posts                 int32\n",
       "post_id              object\n",
       "er_bins3             object\n",
       "er_bins2             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_tr.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "948e5616-047c-4446-a40e-abf318c48416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding for orientation and category\n",
    "cat_cols = ['orientation', 'category']\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "meta_train_encoded = encoder.fit_transform(meta_tr[cat_cols])\n",
    "meta_val_encoded = encoder.transform(meta_val[cat_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f5fd67f-5371-4caa-8f82-5395dacdf2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_cols = encoder.get_feature_names_out(cat_cols)\n",
    "meta_train_encoded = pd.DataFrame(meta_train_encoded, columns=encoded_cols, index=meta_tr.index)\n",
    "meta_val_encoded = pd.DataFrame(meta_val_encoded, columns=encoded_cols, index=meta_val.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6051c933-fa20-453f-b286-033211f7bb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling numerical variables\n",
    "scaler = StandardScaler()\n",
    "num_cols = [\n",
    "    'width', 'height', 'aspect_ratio', 'area',\n",
    "    'dow', 'hour_utc', 'month', 'year', 'caption_len_char',\n",
    "    'n_hashtags', 'n_mentions', 'n_urls', 'n_emojis',\n",
    "    'followees', 'posts'\n",
    "]\n",
    "\n",
    "bin_cols = ['has_caption'] \n",
    "\n",
    "meta_train_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(meta_tr[num_cols]),\n",
    "    columns=num_cols,\n",
    "    index=meta_tr.index\n",
    ")\n",
    "meta_val_scaled = pd.DataFrame(\n",
    "    scaler.transform(meta_val[num_cols]),\n",
    "    columns=num_cols,\n",
    "    index=meta_val.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "beeae959-729a-4b44-9b85-93ea92a097d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_train_bin = meta_tr[bin_cols].astype(int)\n",
    "meta_val_bin = meta_val[bin_cols].astype(int)\n",
    "\n",
    "# Merge all: scaled numeric + boolean + one-hot\n",
    "meta_train_final = pd.concat([meta_train_scaled, meta_train_bin, meta_train_encoded], axis=1)\n",
    "meta_val_final = pd.concat([meta_val_scaled, meta_val_bin, meta_val_encoded], axis=1)\n",
    "# Add post_id\n",
    "meta_train_final.insert(0, 'post_id', metadata_tr['post_id'].values)\n",
    "meta_val_final.insert(0, 'post_id', metadata_val['post_id'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8197bbce-599c-4269-bb65-78bf9ebb76e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN metadata (train): True\n",
      "NaN metadata (val): True\n"
     ]
    }
   ],
   "source": [
    "print(\"NaN metadata (train):\", np.isnan(meta_train_final.drop(columns=['post_id'])).any().any())\n",
    "print(\"NaN metadata (val):\", np.isnan(meta_val_final.drop(columns=['post_id'])).any().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a1c753e-4985-4b55-b717-1d085c30b2b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "caption_len_char     6634\n",
       "post_id                 0\n",
       "posts                   0\n",
       "category_pet            0\n",
       "category_other          0\n",
       "category_interior       0\n",
       "category_food           0\n",
       "category_fitness        0\n",
       "category_fashion        0\n",
       "category_family         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_train_final.isna().sum().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db9c4703-b3d5-4b8d-8520-2bfaa1d7de32",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_train_final['caption_len_char'] = meta_train_final['caption_len_char'].fillna(0)\n",
    "meta_val_final['caption_len_char'] = meta_val_final['caption_len_char'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48f6526f-201b-4542-8c3d-3d0217b78ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "post_id              0\n",
       "posts                0\n",
       "category_pet         0\n",
       "category_other       0\n",
       "category_interior    0\n",
       "category_food        0\n",
       "category_fitness     0\n",
       "category_fashion     0\n",
       "category_family      0\n",
       "category_beauty      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_train_final.isna().sum().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b988228d-c79e-4686-a232-e7a00c58e9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RETRIEVE CAPTIONS TF-IDF\n",
    "OUT_DIR = r\"D:/dataset/text_features/tfidf_v3\"\n",
    "\n",
    "x_train_tfidf = load_npz(f\"{OUT_DIR}/tfidf_topwords_train.npz\")\n",
    "x_val_tfidf = load_npz(f\"{OUT_DIR}/tfidf_topwords_val.npz\")\n",
    "\n",
    "x_train_postids = np.load(os.path.join(OUT_DIR, \"tfidf_train_post_ids.npy\"), allow_pickle=True)\n",
    "x_val_postids = np.load(os.path.join(OUT_DIR, \"tfidf_val_post_ids.npy\"), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da009d50-5f47-4d15-8078-f1ef6a56998b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidf_train = pd.DataFrame({'post_id': x_train_postids})\n",
    "df_tfidf_val   = pd.DataFrame({'post_id': x_val_postids})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5040cf9b-0254-410f-833a-9115a888ef46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['post_id', 'h_mean', 'h_std', 's_mean', 's_std', 'v_mean', 'v_std', 'h_hist_00', 'h_hist_01', 'h_hist_02', 'h_hist_03', 'h_hist_04', 'h_hist_05', 'h_hist_06', 'h_hist_07', 'h_hist_08', 'h_hist_09', 'h_hist_10', 'h_hist_11', 'h_hist_12', 'h_hist_13', 'h_hist_14', 'h_hist_15', 's_hist_00', 's_hist_01', 's_hist_02', 's_hist_03', 's_hist_04', 's_hist_05', 's_hist_06', 's_hist_07', 's_hist_08', 's_hist_09', 's_hist_10', 's_hist_11', 's_hist_12', 's_hist_13', 's_hist_14', 's_hist_15', 'v_hist_00', 'v_hist_01', 'v_hist_02', 'v_hist_03', 'v_hist_04', 'v_hist_05', 'v_hist_06', 'v_hist_07', 'v_hist_08', 'v_hist_09', 'v_hist_10', 'v_hist_11', 'v_hist_12', 'v_hist_13', 'v_hist_14', 'v_hist_15', 'gray_hist_00', 'gray_hist_01', 'gray_hist_02', 'gray_hist_03', 'gray_hist_04', 'gray_hist_05', 'gray_hist_06', 'gray_hist_07', 'gray_hist_08', 'gray_hist_09', 'gray_hist_10', 'gray_hist_11', 'gray_hist_12', 'gray_hist_13', 'gray_hist_14', 'gray_hist_15', 'laplacian_var', 'edge_density', 'entropy_gray', 'colorfulness', 'lbp_u59_00', 'lbp_u59_01', 'lbp_u59_02', 'lbp_u59_03', 'lbp_u59_04', 'lbp_u59_05', 'lbp_u59_06', 'lbp_u59_07', 'lbp_u59_08', 'lbp_u59_09', 'lbp_u59_10', 'lbp_u59_11', 'lbp_u59_12', 'lbp_u59_13', 'lbp_u59_14', 'lbp_u59_15', 'lbp_u59_16', 'lbp_u59_17', 'lbp_u59_18', 'lbp_u59_19', 'lbp_u59_20', 'lbp_u59_21', 'lbp_u59_22', 'lbp_u59_23', 'lbp_u59_24', 'lbp_u59_25', 'lbp_u59_26', 'lbp_u59_27', 'lbp_u59_28', 'lbp_u59_29', 'lbp_u59_30', 'lbp_u59_31', 'lbp_u59_32', 'lbp_u59_33', 'lbp_u59_34', 'lbp_u59_35', 'lbp_u59_36', 'lbp_u59_37', 'lbp_u59_38', 'lbp_u59_39', 'lbp_u59_40', 'lbp_u59_41', 'lbp_u59_42', 'lbp_u59_43', 'lbp_u59_44', 'lbp_u59_45', 'lbp_u59_46', 'lbp_u59_47', 'lbp_u59_48', 'lbp_u59_49', 'lbp_u59_50', 'lbp_u59_51', 'lbp_u59_52', 'lbp_u59_53', 'lbp_u59_54', 'lbp_u59_55', 'lbp_u59_56', 'lbp_u59_57', 'lbp_u59_58', 'glcm_contrast_0', 'glcm_contrast_45', 'glcm_contrast_90', 'glcm_contrast_135', 'glcm_homogeneity_0', 'glcm_homogeneity_45', 'glcm_homogeneity_90', 'glcm_homogeneity_135', 'glcm_energy_0', 'glcm_energy_45', 'glcm_energy_90', 'glcm_energy_135', 'glcm_correlation_0', 'glcm_correlation_45', 'glcm_correlation_90', 'glcm_correlation_135', 'split', 'rn', 'er_bins', 'er_bins3', 'er_bins2']\n"
     ]
    }
   ],
   "source": [
    "column_names = con.sql(\"\"\"PRAGMA table_info('features.img_handcrafted');\"\"\").fetchdf()\n",
    "print(column_names['name'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e661542d-eb83-4e80-85eb-7369eab68206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf5024b7e01144f8993d367cf8fc9331",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images dataset extracted\n",
      "Train, validation and test split\n"
     ]
    }
   ],
   "source": [
    "# RETRIEVE IMAGES\n",
    "# Exctract the df\n",
    "df_images = con.sql(\"\"\"SELECT * FROM features.img_handcrafted\"\"\").df()\n",
    "print(\"Images dataset extracted\")\n",
    "# Split\n",
    "\n",
    "train = df_images[df_images[\"split\"] == \"train\"].copy()\n",
    "val   = df_images[df_images[\"split\"] == \"validation\"].copy()\n",
    "print(\"Train, validation and test split\")\n",
    "\n",
    "cols_to_drop = ['rn', 'split', 'er_bins']\n",
    "feature_cols = [col for col in train.columns if col not in cols_to_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1571af81-0606-4141-87df-f27721424ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 infinite values in laplacian_var\n"
     ]
    }
   ],
   "source": [
    "X_train_img = train[feature_cols]\n",
    "X_val_img1 = val[feature_cols] Ã¬\n",
    "\n",
    "col = 'laplacian_var'\n",
    "\n",
    "# found infinite values and substitute\n",
    "mask = ~np.isfinite(X_val_img1[col])\n",
    "\n",
    "print(f\"Found {mask.sum()} infinite values in {col}\")\n",
    "X_val_img1.loc[mask, col] = 0\n",
    "X_val_np = X_val_img1.values\n",
    "\n",
    "X_val_img = pd.DataFrame(\n",
    "    X_val_np,\n",
    "    index=X_val_img1.index,\n",
    "    columns=X_val_img1.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e960b12d-fe3a-46ba-abda-8c5825a0abf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 infinite values in laplacian_var\n"
     ]
    }
   ],
   "source": [
    "mask = ~np.isfinite(X_val_img1[col])\n",
    "\n",
    "print(f\"Found {mask.sum()} infinite values in {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a68c03e7-6d42-45e1-b41b-507a56c40567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['post_id', 'h_mean', 'h_std', 's_mean', 's_std', 'v_mean', 'v_std', 'h_hist_00', 'h_hist_01', 'h_hist_02', 'h_hist_03', 'h_hist_04', 'h_hist_05', 'h_hist_06', 'h_hist_07', 'h_hist_08', 'h_hist_09', 'h_hist_10', 'h_hist_11', 'h_hist_12', 'h_hist_13', 'h_hist_14', 'h_hist_15', 's_hist_00', 's_hist_01', 's_hist_02', 's_hist_03', 's_hist_04', 's_hist_05', 's_hist_06', 's_hist_07', 's_hist_08', 's_hist_09', 's_hist_10', 's_hist_11', 's_hist_12', 's_hist_13', 's_hist_14', 's_hist_15', 'v_hist_00', 'v_hist_01', 'v_hist_02', 'v_hist_03', 'v_hist_04', 'v_hist_05', 'v_hist_06', 'v_hist_07', 'v_hist_08', 'v_hist_09', 'v_hist_10', 'v_hist_11', 'v_hist_12', 'v_hist_13', 'v_hist_14', 'v_hist_15', 'gray_hist_00', 'gray_hist_01', 'gray_hist_02', 'gray_hist_03', 'gray_hist_04', 'gray_hist_05', 'gray_hist_06', 'gray_hist_07', 'gray_hist_08', 'gray_hist_09', 'gray_hist_10', 'gray_hist_11', 'gray_hist_12', 'gray_hist_13', 'gray_hist_14', 'gray_hist_15', 'laplacian_var', 'edge_density', 'entropy_gray', 'colorfulness', 'lbp_u59_00', 'lbp_u59_01', 'lbp_u59_02', 'lbp_u59_03', 'lbp_u59_04', 'lbp_u59_05', 'lbp_u59_06', 'lbp_u59_07', 'lbp_u59_08', 'lbp_u59_09', 'lbp_u59_10', 'lbp_u59_11', 'lbp_u59_12', 'lbp_u59_13', 'lbp_u59_14', 'lbp_u59_15', 'lbp_u59_16', 'lbp_u59_17', 'lbp_u59_18', 'lbp_u59_19', 'lbp_u59_20', 'lbp_u59_21', 'lbp_u59_22', 'lbp_u59_23', 'lbp_u59_24', 'lbp_u59_25', 'lbp_u59_26', 'lbp_u59_27', 'lbp_u59_28', 'lbp_u59_29', 'lbp_u59_30', 'lbp_u59_31', 'lbp_u59_32', 'lbp_u59_33', 'lbp_u59_34', 'lbp_u59_35', 'lbp_u59_36', 'lbp_u59_37', 'lbp_u59_38', 'lbp_u59_39', 'lbp_u59_40', 'lbp_u59_41', 'lbp_u59_42', 'lbp_u59_43', 'lbp_u59_44', 'lbp_u59_45', 'lbp_u59_46', 'lbp_u59_47', 'lbp_u59_48', 'lbp_u59_49', 'lbp_u59_50', 'lbp_u59_51', 'lbp_u59_52', 'lbp_u59_53', 'lbp_u59_54', 'lbp_u59_55', 'lbp_u59_56', 'lbp_u59_57', 'lbp_u59_58', 'glcm_contrast_0', 'glcm_contrast_45', 'glcm_contrast_90', 'glcm_contrast_135', 'glcm_homogeneity_0', 'glcm_homogeneity_45', 'glcm_homogeneity_90', 'glcm_homogeneity_135', 'glcm_energy_0', 'glcm_energy_45', 'glcm_energy_90', 'glcm_energy_135', 'glcm_correlation_0', 'glcm_correlation_45', 'glcm_correlation_90', 'glcm_correlation_135', 'er_bins3', 'er_bins2']\n"
     ]
    }
   ],
   "source": [
    "print([col for col in X_train_img.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c76afafd-61ea-407a-8ca7-0fbbb2170d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler applied\n",
      "Post Id added\n"
     ]
    }
   ],
   "source": [
    "# StandardScaler\n",
    "scaler = StandardScaler()\n",
    "num_cols = [col for col in X_train_img.columns if col not in ('post_id', 'er_bins3', 'er_bins2')]\n",
    "\n",
    "\n",
    "img_train_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(X_train_img[num_cols]),\n",
    "    columns=num_cols,\n",
    "    index=X_train_img.index\n",
    ")\n",
    "img_val_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_val_img[num_cols]),\n",
    "    columns=num_cols,\n",
    "    index=X_val_img.index\n",
    ")\n",
    "\n",
    "print(\"StandardScaler applied\")\n",
    "\n",
    "img_train_final = pd.concat([img_train_scaled, X_train_img['post_id']], axis=1)\n",
    "img_val_final = pd.concat([img_val_scaled, X_val_img['post_id']], axis=1)\n",
    "# img_test_final = pd.concat([img_test_scaled, X_test_img['post_id']], axis=1)\n",
    "print(\"Post Id added\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6f52e74-0e98-41c0-bbfe-8869bc84f398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common post_ids\n",
    "common_train_ids = (\n",
    "    set(meta_train_final['post_id'])\n",
    "    & set(df_tfidf_train['post_id'])\n",
    "    & set(img_train_final['post_id'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07b5e78f-0adf-4671-a5b6-559e19f30c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to ensure they all have the same ids and order\n",
    "meta_train_final = meta_train_final[meta_train_final['post_id'].isin(common_train_ids)]\n",
    "img_train_final = img_train_final[img_train_final['post_id'].isin(common_train_ids)]\n",
    "df_tfidf_train   = df_tfidf_train[df_tfidf_train['post_id'].isin(common_train_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8b6533d-35da-45fd-a7e4-534ed4e0dcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_val_ids = (\n",
    "    set(meta_val_final['post_id'])\n",
    "    & set(img_val_final['post_id'])\n",
    "    & set(df_tfidf_val['post_id'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99f37a89-7541-4adf-bc50-082da2054b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_val_final = meta_val_final[meta_val_final['post_id'].isin(common_val_ids)]\n",
    "img_val_final = img_val_final[img_val_final['post_id'].isin(common_val_ids)]\n",
    "df_tfidf_val   = df_tfidf_val[df_tfidf_val['post_id'].isin(common_val_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "038041e1-6c47-4e23-bb8f-8392ee3248ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter TF-IDF matrix\n",
    "# Define a mask of booleans to filter the matrix\n",
    "\n",
    "mask_train = np.array([pid in common_train_ids for pid in x_train_postids])\n",
    "x_train_tfidf_aligned = x_train_tfidf[mask_train]\n",
    "\n",
    "mask_val = np.array([pid in common_val_ids for pid in x_val_postids])\n",
    "x_val_tfidf_aligned = x_val_tfidf[mask_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2e734ee-b751-4797-9b5b-a86d7667b369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge metadata and immagini\n",
    "\n",
    "train_meta_img = meta_train_final.merge(img_train_final, on='post_id')\n",
    "val_meta_img   = meta_val_final.merge(img_val_final, on='post_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "40bc9d74-1ec1-462f-befa-86e864e040e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3667"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Free memory\n",
    "del metadata_tr, metadata_val\n",
    "del meta_tr, meta_val\n",
    "del meta_train_scaled, meta_val_scaled\n",
    "del meta_train_encoded, meta_val_encoded\n",
    "del img_train_scaled, img_val_scaled\n",
    "del df_images, train, val\n",
    "del X_train_img, X_val_img\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d32e5c7-c533-48e5-8b1e-46336331cfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataframe into a matrix to merge it with the TF-IDF matrix\n",
    "X_train_meta_img = train_meta_img.drop(columns=['post_id']).values\n",
    "\n",
    "X_train_full = hstack([x_train_tfidf_aligned, X_train_meta_img])\n",
    "X_val_full   = hstack([x_val_tfidf_aligned, val_meta_img.drop(columns=['post_id']).values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3fff6a27-89df-4bbb-ad41-4d3143f7605b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF train shape: (773497, 50079)\n",
      "Meta+Img train shape: (773497, 177)\n",
      "Full train shape: (773497, 50256)\n",
      "\n",
      "TF-IDF val shape: (412325, 50079)\n",
      "Meta+Img val shape: (412325, 177)\n",
      "Full val shape: (412325, 50256)\n"
     ]
    }
   ],
   "source": [
    "print(\"TF-IDF train shape:\", x_train_tfidf_aligned.shape)\n",
    "print(\"Meta+Img train shape:\", X_train_meta_img.shape)\n",
    "print(\"Full train shape:\", X_train_full.shape)\n",
    "print()\n",
    "print(\"TF-IDF val shape:\", x_val_tfidf_aligned.shape)\n",
    "print(\"Meta+Img val shape:\", val_meta_img.drop(columns=['post_id']).shape)\n",
    "print(\"Full val shape:\", X_val_full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e49fa4b4-6e0d-442f-be61-b3f6b3431558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Controllo ordine post_id train: True\n",
      "Controllo ordine post_id val: True\n"
     ]
    }
   ],
   "source": [
    "# Controllo ordine dei post_id sia coerente per non mescolare i target\n",
    "print(\"Controllo ordine post_id train:\", \n",
    "      (df_tfidf_train['post_id'].values == train_meta_img['post_id'].values).all())\n",
    "\n",
    "print(\"Controllo ordine post_id val:\", \n",
    "      (df_tfidf_val['post_id'].values == val_meta_img['post_id'].values).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eae54edb-5edf-44cd-a11f-decce75973bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train: 773497\n",
      "X_train_full: 773497\n",
      "y_val: 412325\n",
      "X_val_full: 412325\n"
     ]
    }
   ],
   "source": [
    "# Controllo dimensioni di y\n",
    "print(\"y_train:\", len(y_tr))\n",
    "print(\"X_train_full:\", X_train_full.shape[0])\n",
    "print(\"y_val:\", len(y_val))\n",
    "print(\"X_val_full:\", X_val_full.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0f7fdad9-a340-42e8-9215-31327871ffcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._coo.coo_matrix'>\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train_full))\n",
    "print(X_train_full.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f9448735-b6eb-411a-868a-5837559daf76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 773497 samples, 50256 features\n",
      "Validation set: 412325 samples, 50256 features\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train set: {X_train_full.shape[0]} samples, {X_train_full.shape[1]} features\")\n",
    "print(f\"Validation set: {X_val_full.shape[0]} samples, {X_val_full.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "71a96086-b0c3-4265-96f3-e16d2c7a255f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_npz(\"D:/dataset/multimodal/X_train_full_TR.npz\", X_train_full)\n",
    "save_npz(\"D:/dataset/multimodal/X_val_full_TR.npz\", X_val_full)\n",
    "\n",
    "np.save(\"D:/dataset/multimodal/y_train.npy\", y_tr.values)\n",
    "np.save(\"D:/dataset/multimodal/y_val.npy\", y_val.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5f4c13-50ae-4ab1-ade2-31da820b9ff5",
   "metadata": {},
   "source": [
    "# LOAD AND CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bd48e83-935c-4a51-815f-d4b4edc9d666",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = \"D:/dataset/multimodal\"\n",
    "Xtr_full = load_npz(f\"{DIR}/X_train_full_TR.npz\").tocsr().astype(np.float32)\n",
    "Xva_full = load_npz(f\"{DIR}/X_val_full_TR.npz\").tocsr().astype(np.float32)\n",
    "\n",
    "y_tr = np.load(os.path.join(DIR, \"y_train.npy\"), allow_pickle = True)\n",
    "y_val = np.load(os.path.join(DIR, \"y_val.npy\"), allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e30d05ee-1554-417c-92ec-f74a4cd051b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "print(type(Xtr_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7acf214c-237c-457e-a0ca-e6e303517752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(773497, 50256) (412325, 50256) (773497,) (412325,)\n"
     ]
    }
   ],
   "source": [
    "print(Xtr_full.shape, Xva_full.shape, y_tr.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecf40428-34a5-4503-9059-7751447437c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination: {'alpha': 1e-05, 'average': False, 'class_weight': None}\n",
      "macro-F1 (val): 0.2954541537732168 | accuracy (val): 0.3139683502091796\n",
      "\n",
      "Combination: {'alpha': 1e-05, 'average': False, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.2865529469701135 | accuracy (val): 0.3153847086642818\n",
      "\n",
      "Combination: {'alpha': 1e-05, 'average': True, 'class_weight': None}\n",
      "macro-F1 (val): 0.30391785896759793 | accuracy (val): 0.33945795185836414\n",
      "\n",
      "Combination: {'alpha': 1e-05, 'average': True, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.29232628597564436 | accuracy (val): 0.3409688958952283\n",
      "\n",
      "Combination: {'alpha': 0.0001, 'average': False, 'class_weight': None}\n",
      "macro-F1 (val): 0.280857715201816 | accuracy (val): 0.3079367004183593\n",
      "\n",
      "Combination: {'alpha': 0.0001, 'average': False, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.280356124983388 | accuracy (val): 0.31666040138240464\n",
      "\n",
      "Combination: {'alpha': 0.0001, 'average': True, 'class_weight': None}\n",
      "macro-F1 (val): 0.2964958035483933 | accuracy (val): 0.3391838961983872\n",
      "\n",
      "Combination: {'alpha': 0.0001, 'average': True, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.28148590686352437 | accuracy (val): 0.3389656217789365\n",
      "\n",
      "Combination: {'alpha': 0.001, 'average': False, 'class_weight': None}\n",
      "macro-F1 (val): 0.28182197195073344 | accuracy (val): 0.29208512702358574\n",
      "\n",
      "Combination: {'alpha': 0.001, 'average': False, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.2810953899903527 | accuracy (val): 0.3084266052264597\n",
      "\n",
      "Combination: {'alpha': 0.001, 'average': True, 'class_weight': None}\n",
      "macro-F1 (val): 0.2958128230921716 | accuracy (val): 0.3366955678166495\n",
      "\n",
      "Combination: {'alpha': 0.001, 'average': True, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.2739659237552905 | accuracy (val): 0.33549263323834355\n",
      "\n",
      "Combination: {'alpha': 0.01, 'average': False, 'class_weight': None}\n",
      "macro-F1 (val): 0.27455162274582123 | accuracy (val): 0.2972727823925302\n",
      "\n",
      "Combination: {'alpha': 0.01, 'average': False, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.27469949754454465 | accuracy (val): 0.3083101922027527\n",
      "\n",
      "Combination: {'alpha': 0.01, 'average': True, 'class_weight': None}\n",
      "macro-F1 (val): 0.28940268764682586 | accuracy (val): 0.3317116352391924\n",
      "\n",
      "Combination: {'alpha': 0.01, 'average': True, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.26494199341145885 | accuracy (val): 0.3269896319650761\n",
      "\n",
      "Best hyperparameter configuration:\n",
      "{'alpha': 1e-05, 'average': True, 'class_weight': None}\n",
      "Validation macro-F1: 0.30391785896759793\n",
      "\n",
      "Ordered results by macro-F1 (validation):\n",
      "      alpha class_weight  average  val_macro_f1  val_accuracy\n",
      "2   0.00001         None     True      0.303918      0.339458\n",
      "6   0.00010         None     True      0.296496      0.339184\n",
      "10  0.00100         None     True      0.295813      0.336696\n",
      "0   0.00001         None    False      0.295454      0.313968\n",
      "3   0.00001     balanced     True      0.292326      0.340969\n",
      "14  0.01000         None     True      0.289403      0.331712\n",
      "1   0.00001     balanced    False      0.286553      0.315385\n",
      "8   0.00100         None    False      0.281822      0.292085\n",
      "7   0.00010     balanced     True      0.281486      0.338966\n",
      "9   0.00100     balanced    False      0.281095      0.308427\n",
      "4   0.00010         None    False      0.280858      0.307937\n",
      "5   0.00010     balanced    False      0.280356      0.316660\n",
      "13  0.01000     balanced    False      0.274699      0.308310\n",
      "12  0.01000         None    False      0.274552      0.297273\n",
      "11  0.00100     balanced     True      0.273966      0.335493\n",
      "15  0.01000     balanced     True      0.264942      0.326990\n"
     ]
    }
   ],
   "source": [
    "# SGD\n",
    "param_grid = {\n",
    "    \"alpha\": [1e-5, 1e-4, 1e-3, 1e-2],\n",
    "    \"class_weight\": [None, \"balanced\"]\n",
    "}\n",
    "\n",
    "results = []\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    print(f\"\\nCombination: {params}\")\n",
    "\n",
    "    clf = SGDClassifier(\n",
    "        loss=\"hinge\",            \n",
    "        penalty=\"l2\",            \n",
    "        **params,\n",
    "        average = True,\n",
    "        random_state=42,\n",
    "        max_iter=1000,\n",
    "        tol=1e-3,\n",
    "    )\n",
    "\n",
    "    clf.fit(Xtr_full, y_tr)\n",
    "\n",
    "    y_val_pred = clf.predict(Xva_full)\n",
    "\n",
    "    macro_f1 = f1_score(y_val, y_val_pred, average=\"macro\")\n",
    "    acc = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "    print(f\"macro-F1 (val): {macro_f1} | accuracy (val): {acc}\")\n",
    "\n",
    "    results.append({\n",
    "        \"alpha\": params[\"alpha\"],\n",
    "        \"class_weight\": params[\"class_weight\"],\n",
    "        \"average\": params[\"average\"],\n",
    "        \"val_macro_f1\": macro_f1,\n",
    "        \"val_accuracy\": acc,\n",
    "    })\n",
    "\n",
    "    if macro_f1 > best_score:\n",
    "        best_score = macro_f1\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\nBest hyperparameter configuration:\")\n",
    "print(best_params)\n",
    "print(\"Validation macro-F1:\", best_score)\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(\"val_macro_f1\", ascending=False)\n",
    "print(\"\\nOrdered results by macro-F1 (validation):\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93ef2efe-bf2d-456e-8a4d-796eb971d2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination: {'var_smoothing': 1e-09}\n",
      "macro-F1 (val): 0.1862 | accuracy (val): 0.2011\n",
      "\n",
      "Combination: {'var_smoothing': 1e-08}\n",
      "macro-F1 (val): 0.1892 | accuracy (val): 0.2013\n",
      "\n",
      "Combination: {'var_smoothing': 1e-07}\n",
      "macro-F1 (val): 0.1944 | accuracy (val): 0.2018\n",
      "\n",
      "Combination: {'var_smoothing': 1e-06}\n",
      "macro-F1 (val): 0.1915 | accuracy (val): 0.1989\n",
      "\n",
      "Best hyperparameter configuration:\n",
      "{'var_smoothing': 1e-07}\n",
      "Validation macro-F1: 0.19444250202226981\n",
      "\n",
      "Ordered results by macro-F1 (validation):\n",
      "   var_smoothing  val_macro_f1  val_accuracy\n",
      "2   1.000000e-07      0.194443      0.201792\n",
      "3   1.000000e-06      0.191519      0.198884\n",
      "1   1.000000e-08      0.189157      0.201293\n",
      "0   1.000000e-09      0.186222      0.201103\n"
     ]
    }
   ],
   "source": [
    "# NAIVE BAYES\n",
    "\n",
    "param_grid = {\n",
    "    \"var_smoothing\": [1e-9, 1e-8, 1e-7, 1e-6]\n",
    "}\n",
    "\n",
    "results = []\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "batch_size = 256\n",
    "classes = np.unique(y_tr)\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    print(f\"\\nCombination: {params}\")\n",
    "\n",
    "    clf = GaussianNB(**params)\n",
    "\n",
    "    # Fit the model using minibatch for memory\n",
    "    for start in range(0, Xtr_full.shape[0], batch_size):\n",
    "        # print(f\"Batch {start} fit\")\n",
    "        end = min(start + batch_size, Xtr_full.shape[0])\n",
    "\n",
    "        Xb = Xtr_full[start:end].toarray()\n",
    "        yb = y_tr[start:end]\n",
    "\n",
    "        if start == 0:\n",
    "            clf.partial_fit(Xb, yb, classes=classes)\n",
    "        else:\n",
    "            clf.partial_fit(Xb, yb)\n",
    "\n",
    "        del Xb, yb\n",
    "        gc.collect()\n",
    "\n",
    "    # Predict using minibatches\n",
    "    y_val_pred = []\n",
    "\n",
    "    for start in range(0, Xva_full.shape[0], batch_size):\n",
    "        # print(f\"Batch {start} predict\")\n",
    "        end = min(start + batch_size, Xva_full.shape[0])\n",
    "\n",
    "        Xb = Xva_full[start:end].toarray()\n",
    "        y_val_pred.append(clf.predict(Xb))\n",
    "\n",
    "        del Xb\n",
    "        gc.collect()\n",
    "\n",
    "    y_val_pred = np.concatenate(y_val_pred)\n",
    "\n",
    "    macro_f1 = f1_score(y_val, y_val_pred, average=\"macro\")\n",
    "    acc = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "    print(f\"macro-F1 (val): {macro_f1:.4f} | accuracy (val): {acc:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        \"var_smoothing\": params[\"var_smoothing\"],\n",
    "        \"val_macro_f1\": macro_f1,\n",
    "        \"val_accuracy\": acc,\n",
    "    })\n",
    "\n",
    "    if macro_f1 > best_score:\n",
    "        best_score = macro_f1\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\nBest hyperparameter configuration:\")\n",
    "print(best_params)\n",
    "print(\"Validation macro-F1:\", best_score)\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(\n",
    "    \"val_macro_f1\", ascending=False\n",
    ")\n",
    "print(\"\\nOrdered results by macro-F1 (validation):\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b80058a-17ca-4630-b948-4fbf1914999d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.3005 | accuracy (val): 0.3021\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.3031 | accuracy (val): 0.3044\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.3022 | accuracy (val): 0.3043\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.2986 | accuracy (val): 0.3013\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.3001 | accuracy (val): 0.3022\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.3033 | accuracy (val): 0.3046\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.1921 | accuracy (val): 0.2331\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.1914 | accuracy (val): 0.2320\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.1917 | accuracy (val): 0.2331\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.1988 | accuracy (val): 0.2461\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.1962 | accuracy (val): 0.2431\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.1965 | accuracy (val): 0.2408\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.3051 | accuracy (val): 0.3079\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.3080 | accuracy (val): 0.3101\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.3101 | accuracy (val): 0.3120\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.3043 | accuracy (val): 0.3056\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.3087 | accuracy (val): 0.3093\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.3087 | accuracy (val): 0.3090\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.1979 | accuracy (val): 0.2421\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.1974 | accuracy (val): 0.2423\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.1994 | accuracy (val): 0.2408\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.2030 | accuracy (val): 0.2447\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.2031 | accuracy (val): 0.2478\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.2024 | accuracy (val): 0.2464\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.3125 | accuracy (val): 0.3129\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.3128 | accuracy (val): 0.3139\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.3137 | accuracy (val): 0.3145\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.3139 | accuracy (val): 0.3145\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.3154 | accuracy (val): 0.3162\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.3161 | accuracy (val): 0.3174\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.2079 | accuracy (val): 0.2483\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.2065 | accuracy (val): 0.2483\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.2066 | accuracy (val): 0.2475\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.2064 | accuracy (val): 0.2453\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.2018 | accuracy (val): 0.2436\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.2030 | accuracy (val): 0.2431\n",
      "\n",
      "Best hyperparameter configuration (Random Forest):\n",
      "{'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "Validation macro-F1: 0.31609773850413136\n",
      "\n",
      "Ordered results:\n",
      "    max_depth max_features  min_samples_leaf  n_estimators  val_macro_f1  \\\n",
      "29         12         0.05                 5            80      0.316098   \n",
      "28         12         0.05                 5            50      0.315412   \n",
      "27         12         0.05                 5            30      0.313885   \n",
      "26         12         0.05                 2            80      0.313726   \n",
      "25         12         0.05                 2            50      0.312764   \n",
      "24         12         0.05                 2            30      0.312539   \n",
      "14         10         0.05                 2            80      0.310097   \n",
      "17         10         0.05                 5            80      0.308661   \n",
      "16         10         0.05                 5            50      0.308651   \n",
      "13         10         0.05                 2            50      0.307965   \n",
      "12         10         0.05                 2            30      0.305137   \n",
      "15         10         0.05                 5            30      0.304313   \n",
      "5           8         0.05                 5            80      0.303312   \n",
      "1           8         0.05                 2            50      0.303140   \n",
      "2           8         0.05                 2            80      0.302183   \n",
      "0           8         0.05                 2            30      0.300483   \n",
      "4           8         0.05                 5            50      0.300080   \n",
      "3           8         0.05                 5            30      0.298629   \n",
      "30         12         sqrt                 2            30      0.207855   \n",
      "32         12         sqrt                 2            80      0.206647   \n",
      "31         12         sqrt                 2            50      0.206548   \n",
      "33         12         sqrt                 5            30      0.206365   \n",
      "22         10         sqrt                 5            50      0.203119   \n",
      "35         12         sqrt                 5            80      0.203025   \n",
      "21         10         sqrt                 5            30      0.202955   \n",
      "23         10         sqrt                 5            80      0.202389   \n",
      "34         12         sqrt                 5            50      0.201795   \n",
      "20         10         sqrt                 2            80      0.199362   \n",
      "9           8         sqrt                 5            30      0.198782   \n",
      "18         10         sqrt                 2            30      0.197919   \n",
      "19         10         sqrt                 2            50      0.197429   \n",
      "11          8         sqrt                 5            80      0.196527   \n",
      "10          8         sqrt                 5            50      0.196247   \n",
      "6           8         sqrt                 2            30      0.192083   \n",
      "8           8         sqrt                 2            80      0.191746   \n",
      "7           8         sqrt                 2            50      0.191408   \n",
      "\n",
      "    val_accuracy  \n",
      "29      0.317439  \n",
      "28      0.316202  \n",
      "27      0.314451  \n",
      "26      0.314509  \n",
      "25      0.313898  \n",
      "24      0.312896  \n",
      "14      0.312035  \n",
      "17      0.309011  \n",
      "16      0.309302  \n",
      "13      0.310134  \n",
      "12      0.307942  \n",
      "15      0.305638  \n",
      "5       0.304578  \n",
      "1       0.304379  \n",
      "2       0.304321  \n",
      "0       0.302085  \n",
      "4       0.302201  \n",
      "3       0.301306  \n",
      "30      0.248333  \n",
      "32      0.247492  \n",
      "31      0.248338  \n",
      "33      0.245256  \n",
      "22      0.247763  \n",
      "35      0.243083  \n",
      "21      0.244669  \n",
      "23      0.246361  \n",
      "34      0.243619  \n",
      "20      0.240774  \n",
      "9       0.246073  \n",
      "18      0.242108  \n",
      "19      0.242285  \n",
      "11      0.240832  \n",
      "10      0.243097  \n",
      "6       0.233066  \n",
      "8       0.233098  \n",
      "7       0.231987  \n"
     ]
    }
   ],
   "source": [
    "# RANDOM FOREST\n",
    "\n",
    "param_grid_rf = {\n",
    "    \"n_estimators\": [30, 50, 80],\n",
    "    \"max_depth\": [8, 10, 12],   \n",
    "    \"min_samples_leaf\": [2, 5], \n",
    "    \"max_features\": [0.05, \"sqrt\"],\n",
    "}\n",
    "results = []\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "for params in ParameterGrid(param_grid_rf):\n",
    "    print(f\"\\nCombination: {params}\")\n",
    "\n",
    "    clf = RandomForestClassifier(\n",
    "        **params,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Fit\n",
    "    clf.fit(X_train_full, y_tr)\n",
    "\n",
    "    # Validation\n",
    "    y_val_pred = clf.predict(X_val_full)\n",
    "\n",
    "    macro_f1 = f1_score(y_val, y_val_pred, average=\"macro\")\n",
    "    acc = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "    print(f\"macro-F1 (val): {macro_f1:.4f} | accuracy (val): {acc:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        **params,\n",
    "        \"val_macro_f1\": macro_f1,\n",
    "        \"val_accuracy\": acc,\n",
    "    })\n",
    "\n",
    "    if macro_f1 > best_score:\n",
    "        best_score = macro_f1\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\nBest hyperparameter configuration (Random Forest):\")\n",
    "print(best_params)\n",
    "print(\"Validation macro-F1:\", best_score)\n",
    "\n",
    "results_df_rf = pd.DataFrame(results).sort_values(\"val_macro_f1\", ascending=False)\n",
    "print(\"\\nOrdered results:\")\n",
    "print(results_df_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5b5f21c-8020-4f2e-917a-7769554a6a6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.3152 | accuracy (val): 0.3315\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 150, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.3174 | accuracy (val): 0.3337\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.3241 | accuracy (val): 0.3375\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 150, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.3258 | accuracy (val): 0.3391\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.3153 | accuracy (val): 0.3314\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 150, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.3168 | accuracy (val): 0.3333\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.3240 | accuracy (val): 0.3370\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 150, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.3261 | accuracy (val): 0.3390\n",
      "\n",
      "Best hyperparameter configuration (XGBoost):\n",
      "{'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 150, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "Validation macro-F1: 0.3260809483012063\n",
      "\n",
      "Ordered results:\n",
      "   colsample_bytree  gamma  learning_rate  max_depth  n_estimators  \\\n",
      "7               0.5      1            0.1          6           150   \n",
      "3               0.5      0            0.1          6           150   \n",
      "2               0.5      0            0.1          6           100   \n",
      "6               0.5      1            0.1          6           100   \n",
      "1               0.5      0            0.1          4           150   \n",
      "5               0.5      1            0.1          4           150   \n",
      "4               0.5      1            0.1          4           100   \n",
      "0               0.5      0            0.1          4           100   \n",
      "\n",
      "   reg_lambda  subsample  val_macro_f1  val_accuracy  \n",
      "7           1        0.8      0.326081      0.338992  \n",
      "3           1        0.8      0.325842      0.339118  \n",
      "2           1        0.8      0.324131      0.337467  \n",
      "6           1        0.8      0.323952      0.337042  \n",
      "1           1        0.8      0.317383      0.333737  \n",
      "5           1        0.8      0.316810      0.333329  \n",
      "4           1        0.8      0.315326      0.331396  \n",
      "0           1        0.8      0.315191      0.331496  \n"
     ]
    }
   ],
   "source": [
    "# XGBOOST\n",
    "\n",
    "# Convert the labels into numbers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_tr_enc = le.fit_transform(y_tr)\n",
    "y_val_enc = le.transform(y_val)\n",
    "\n",
    "param_grid_xgb = {\n",
    "    \"n_estimators\": [100, 150],\n",
    "    \"max_depth\": [4, 6], \n",
    "    \"learning_rate\": [0.1],\n",
    "    \"subsample\": [0.8], \n",
    "    \"colsample_bytree\": [0.5],\n",
    "    \"gamma\": [0, 1], \n",
    "    \"reg_lambda\": [1], \n",
    "}\n",
    "\n",
    "results = []\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "for params in ParameterGrid(param_grid_xgb):\n",
    "    print(f\"\\nCombination: {params}\")\n",
    "\n",
    "    clf = XGBClassifier(\n",
    "        **params,\n",
    "        objective=\"multi:softmax\",\n",
    "        num_class=len(np.unique(y_tr_enc)),\n",
    "        tree_method=\"hist\",\n",
    "        eval_metric=\"mlogloss\",\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        verbosity=0,\n",
    "    )\n",
    "\n",
    "    # Fit\n",
    "    clf.fit(X_train_full, y_tr_enc)\n",
    "\n",
    "    # Validation\n",
    "    y_val_pred = clf.predict(X_val_full)\n",
    "\n",
    "    macro_f1 = f1_score(y_val_enc, y_val_pred, average=\"macro\")\n",
    "    acc = accuracy_score(y_val_enc, y_val_pred)\n",
    "\n",
    "    print(f\"macro-F1 (val): {macro_f1:.4f} | accuracy (val): {acc:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        **params,\n",
    "        \"val_macro_f1\": macro_f1,\n",
    "        \"val_accuracy\": acc,\n",
    "    })\n",
    "\n",
    "    if macro_f1 > best_score:\n",
    "        best_score = macro_f1\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\nBest hyperparameter configuration (XGBoost):\")\n",
    "print(best_params)\n",
    "print(\"Validation macro-F1:\", best_score)\n",
    "\n",
    "results_df_xgb = pd.DataFrame(results).sort_values(\"val_macro_f1\", ascending=False)\n",
    "print(\"\\nOrdered results:\")\n",
    "print(results_df_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad73c6d-fb33-42cd-b28d-6134cbfb89a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PERFORMANCE ON TEST SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea6c050d-1064-4fca-86df-82679fde3b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1132bb5e28d40c481a3175ae0618103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1419be8c08f0453384255ee07a5eeee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN metadata (train): True\n",
      "NaN metadata (test): True\n",
      "Mancanti in metadata_tr: 0\n",
      "Mancanti in metadata_te: 0\n"
     ]
    }
   ],
   "source": [
    "# METADATA\n",
    "metadata_tr = con.sql(\"\"\"SELECT * FROM md1718 WHERE split = 'train' OR split = 'validation'\"\"\").df()\n",
    "metadata_te = con.sql(\"\"\"SELECT * FROM md1718 WHERE split = 'test'\"\"\").df()\n",
    "col_to_exclude = ['filename', 'username', 'like_count', 'comment_count', 'caption', 'followers', 'engagement_rate', 'er_log', 'caption_language', 'caption_tfidf', 'caption_bert_clip',\n",
    "                  'er_bins', 'split', 'time_utc', 'date_day', 'caption_lang', 'caption_clean']\n",
    "feature_columns = [col for col in metadata_tr.columns if col not in col_to_exclude]\n",
    "\n",
    "meta_tr = metadata_tr[feature_columns].copy()\n",
    "meta_te = metadata_te[feature_columns].copy()\n",
    "\n",
    "# One hot encoding\n",
    "cat_cols = ['orientation', 'category']\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "meta_train_encoded = encoder.fit_transform(meta_tr[cat_cols])\n",
    "meta_test_encoded = encoder.transform(meta_te[cat_cols])\n",
    "encoded_cols = encoder.get_feature_names_out(cat_cols)\n",
    "meta_train_encoded = pd.DataFrame(meta_train_encoded, columns=encoded_cols, index=meta_tr.index)\n",
    "meta_test_encoded = pd.DataFrame(meta_test_encoded, columns=encoded_cols, index=meta_te.index)\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "num_cols = [\n",
    "    'width', 'height', 'aspect_ratio', 'area',\n",
    "    'dow', 'hour_utc', 'month', 'year', 'caption_len_char',\n",
    "    'n_hashtags', 'n_mentions', 'n_urls', 'n_emojis',\n",
    "    'followees', 'posts'\n",
    "]\n",
    "\n",
    "bin_cols = ['has_caption'] \n",
    "meta_train_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(meta_tr[num_cols]),\n",
    "    columns=num_cols,\n",
    "    index=meta_tr.index\n",
    ")\n",
    "\n",
    "meta_test_scaled = pd.DataFrame(\n",
    "    scaler.transform(meta_te[num_cols]),\n",
    "    columns=num_cols,\n",
    "    index=meta_te.index\n",
    ")\n",
    "\n",
    "meta_train_bin = meta_tr[bin_cols].astype(int)\n",
    "meta_test_bin = meta_te[bin_cols].astype(int)\n",
    "\n",
    "# Merge all: scaled numeric + boolean + one-hot\n",
    "meta_train_final = pd.concat([meta_train_scaled, meta_train_bin, meta_train_encoded], axis=1)\n",
    "meta_test_final = pd.concat([meta_test_scaled, meta_test_bin, meta_test_encoded], axis=1)\n",
    "# Add back post_id\n",
    "meta_train_final.insert(0, 'post_id', metadata_tr['post_id'].values)\n",
    "meta_test_final.insert(0, 'post_id', metadata_te['post_id'].values)\n",
    "\n",
    "print(\"NaN metadata (train):\", np.isnan(meta_train_final.drop(columns=['post_id'])).any().any())\n",
    "print(\"NaN metadata (test):\", np.isnan(meta_test_final.drop(columns=['post_id'])).any().any())\n",
    "meta_train_final['caption_len_char'] = meta_train_final['caption_len_char'].fillna(0)\n",
    "meta_test_final['caption_len_char'] = meta_test_final['caption_len_char'].fillna(0)\n",
    "\n",
    "# TEXTUAL DATA\n",
    "OUT_DIR = r\"D:/dataset/text_features/tfidf_v3\"\n",
    "\n",
    "x_train_tfidf = load_npz(f\"{OUT_DIR}/tfidf_topwords_train.npz\")\n",
    "x_val_tfidf = load_npz(f\"{OUT_DIR}/tfidf_topwords_val.npz\")\n",
    "x_test_tfidf = load_npz(f\"{OUT_DIR}/tfidf_topwords_test.npz\")\n",
    "\n",
    "x_trainval_tfidf = vstack([x_train_tfidf, x_val_tfidf])\n",
    "\n",
    "train_postids = np.load(os.path.join(OUT_DIR, \"tfidf_train_post_ids.npy\"), allow_pickle=True)\n",
    "val_postids = np.load(os.path.join(OUT_DIR, \"tfidf_val_post_ids.npy\"), allow_pickle=True)\n",
    "test_postids = np.load(os.path.join(OUT_DIR, \"tfidf_test_post_ids.npy\"), allow_pickle=True)\n",
    "\n",
    "trainval_postids = np.concatenate([train_postids, val_postids])\n",
    "\n",
    "df_tfidf_test   = pd.DataFrame({'post_id': test_postids})\n",
    "df_tfidf_trainval = pd.DataFrame({'post_id': trainval_postids})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd0745ed-417b-4cd2-826e-a8df93a177ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1185822, 29)\n",
      "(423604, 29)\n",
      "(1185822, 50079)\n",
      "(423604, 50079)\n",
      "(1185822,)\n",
      "(423604,)\n"
     ]
    }
   ],
   "source": [
    "print(meta_train_final.shape)\n",
    "print(meta_test_final.shape)\n",
    "print(x_trainval_tfidf.shape)\n",
    "print(x_test_tfidf.shape)\n",
    "print(trainval_postids.shape)\n",
    "print(test_postids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989f26f3-4525-488d-a25c-b353f368e30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free memory\n",
    "del metadata_tr, metadata_te\n",
    "del meta_tr, meta_te\n",
    "del meta_train_scaled, meta_test_scaled\n",
    "del meta_train_encoded, meta_test_encoded\n",
    "del x_train_tfidf, x_val_tfidf\n",
    "del train_postids, val_postids\n",
    "del meta_train_bin, meta_test_bin\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa3ffa49-746d-4cbe-9147-36a4d2f78170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9750a31a45724794ad3dfa361cb13a12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images dataset extracted\n",
      "Train and test split\n",
      "Train: Found 1 infinite values in laplacian_var\n",
      "Check train: Found 0 infinite values in laplacian_var\n",
      "Test: Found 1 infinite values in laplacian_var\n",
      "Check test: Found 0 infinite values in laplacian_var\n",
      "Fitting scaler incrementally...\n",
      "  Fitted rows 0 â 200000\n",
      "  Fitted rows 200000 â 400000\n",
      "  Fitted rows 400000 â 600000\n",
      "  Fitted rows 600000 â 800000\n",
      "  Fitted rows 800000 â 1000000\n",
      "  Fitted rows 1000000 â 1185822\n",
      "Incremental fit complete.\n",
      "\n",
      "Transforming train incrementally...\n",
      "  Transformed rows 0 â 200000\n",
      "  Transformed rows 200000 â 400000\n",
      "  Transformed rows 400000 â 600000\n",
      "  Transformed rows 600000 â 800000\n",
      "  Transformed rows 800000 â 1000000\n",
      "  Transformed rows 1000000 â 1185822\n",
      "Train transform complete.\n",
      "\n",
      "Transforming test...\n",
      "Test transform complete.\n",
      "\n",
      "Final DataFrames created!\n",
      "(1185822, 150)\n",
      "(423604, 150)\n"
     ]
    }
   ],
   "source": [
    "# VISUAL DATA\n",
    "# RETRIEVE IMAGES\n",
    "# Exctract the df\n",
    "df_images = con.sql(\"\"\"SELECT * FROM features.img_handcrafted\"\"\").df()\n",
    "print(\"Images dataset extracted\")\n",
    "\n",
    "# Split\n",
    "\n",
    "train = df_images[df_images[\"split\"].isin([\"train\", \"validation\"])].copy()\n",
    "test   = df_images[df_images[\"split\"] == \"test\"].copy()\n",
    "print(\"Train and test split\")\n",
    "\n",
    "cols_to_drop = ['rn', 'split', 'er_bins']\n",
    "feature_cols = [col for col in train.columns if col not in cols_to_drop]\n",
    "\n",
    "X_train_img1 = train[feature_cols]\n",
    "X_test_img1 = test[feature_cols] \n",
    "\n",
    "col = 'laplacian_var'\n",
    "\n",
    "mask = ~np.isfinite(X_train_img1[col])\n",
    "print(f\"Train: Found {mask.sum()} infinite values in {col}\")\n",
    "X_train_img1.loc[mask, col] = 0\n",
    "\n",
    "X_train_np = X_train_img1.values\n",
    "\n",
    "X_train_img = pd.DataFrame(\n",
    "    X_train_np,\n",
    "    index=X_train_img1.index,\n",
    "    columns=X_train_img1.columns\n",
    ")\n",
    "\n",
    "mask = ~np.isfinite(X_train_img1[col])\n",
    "print(f\"Check train: Found {mask.sum()} infinite values in {col}\")\n",
    "\n",
    "\n",
    "# Test\n",
    "mask = ~np.isfinite(X_test_img1[col])\n",
    "print(f\"Test: Found {mask.sum()} infinite values in {col}\")\n",
    "X_test_img1.loc[mask, col] = 0\n",
    "X_test_np = X_test_img1.values\n",
    "\n",
    "X_test_img = pd.DataFrame(\n",
    "    X_test_np,\n",
    "    index=X_test_img1.index,\n",
    "    columns=X_test_img1.columns\n",
    ")\n",
    "\n",
    "mask = ~np.isfinite(X_test_img1[col])\n",
    "print(f\"Check test: Found {mask.sum()} infinite values in {col}\")\n",
    "\n",
    "del df_images, train, test\n",
    "del X_train_img1, X_test_img1\n",
    "del X_train_np, X_test_np\n",
    "gc.collect()\n",
    "\n",
    "num_cols = [col for col in X_train_img.columns if col != 'post_id']\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Incremental fit on train\n",
    "chunk_size = 200_000\n",
    "n_train = len(X_train_img)\n",
    "\n",
    "print(\"Fitting scaler incrementally...\")\n",
    "for start in range(0, n_train, chunk_size):\n",
    "    end = start + chunk_size\n",
    "    chunk = X_train_img.iloc[start:end][num_cols]\n",
    "    scaler.partial_fit(chunk)\n",
    "    print(f\"  Fitted rows {start} â {min(end, n_train)}\")\n",
    "\n",
    "print(\"Incremental fit complete.\\n\")\n",
    "\n",
    "# Incremental transform on train\n",
    "print(\"Transforming train incrementally...\")\n",
    "train_chunks = []\n",
    "\n",
    "for start in range(0, n_train, chunk_size):\n",
    "    end = start + chunk_size\n",
    "    chunk = X_train_img.iloc[start:end][num_cols]\n",
    "    chunk_scaled = scaler.transform(chunk).astype('float32')\n",
    "    train_chunks.append(chunk_scaled)\n",
    "    print(f\"  Transformed rows {start} â {min(end, n_train)}\")\n",
    "\n",
    "img_train_scaled = np.vstack(train_chunks)\n",
    "del train_chunks\n",
    "gc.collect()\n",
    "\n",
    "print(\"Train transform complete.\\n\")\n",
    "\n",
    "# Incremental transform on train\n",
    "print(\"Transforming test...\")\n",
    "img_test_scaled = scaler.transform(X_test_img[num_cols]).astype('float32')\n",
    "print(\"Test transform complete.\\n\")\n",
    "\n",
    "img_train_final = pd.DataFrame(\n",
    "    img_train_scaled,\n",
    "    index=X_train_img.index,\n",
    "    columns=num_cols\n",
    ")\n",
    "img_train_final['post_id'] = X_train_img['post_id'].values\n",
    "\n",
    "img_test_final = pd.DataFrame(\n",
    "    img_test_scaled,\n",
    "    index=X_test_img.index,\n",
    "    columns=num_cols\n",
    ")\n",
    "img_test_final['post_id'] = X_test_img['post_id'].values\n",
    "\n",
    "print(\"Final DataFrames created!\")\n",
    "print(img_train_final.shape)\n",
    "print(img_test_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d815d93-c513-417f-904d-769a7f86ae35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del X_train_img, X_test_img\n",
    "del img_train_scaled, img_test_scaled\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc31ac2b-3b1a-4157-9fa5-0bc5a35c0cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common post_ids\n",
    "common_train_ids = (\n",
    "    set(meta_train_final['post_id'])\n",
    "    & set(df_tfidf_trainval['post_id'])\n",
    "    & set(img_train_final['post_id'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93a0b96d-7aab-4b02-b21e-998bea00ca77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1185822"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(common_train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da8fb0f1-5f40-42ea-9c0d-85b4ce5779ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to ensure they all have the same ids and order\n",
    "meta_train_final = meta_train_final[meta_train_final['post_id'].isin(common_train_ids)]\n",
    "img_train_final = img_train_final[img_train_final['post_id'].isin(common_train_ids)]\n",
    "df_tfidf_trainval   = df_tfidf_trainval[df_tfidf_trainval['post_id'].isin(common_train_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56b884ee-b3fc-4873-93f2-b58e01653a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_test_ids = (\n",
    "    set(meta_test_final['post_id'])\n",
    "    & set(img_test_final['post_id'])\n",
    "    & set(df_tfidf_test['post_id'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd369a1c-6681-4d19-b382-9d9a8e1bb705",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_test_final = meta_test_final[meta_test_final['post_id'].isin(common_test_ids)]\n",
    "img_test_final = img_test_final[img_test_final['post_id'].isin(common_test_ids)]\n",
    "df_tfidf_test = df_tfidf_test[df_tfidf_test['post_id'].isin(common_test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cb3a945-3cc0-4345-a047-de0eb0206a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "423604"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(common_test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "810b481f-7748-42df-a80f-1a47a0767727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter TF-IDF matrix\n",
    "# Define a mask of booleans to filter the matrix\n",
    "\n",
    "mask_train = np.array([pid in common_train_ids for pid in trainval_postids])\n",
    "x_trainval_tfidf_aligned = x_trainval_tfidf[mask_train]\n",
    "\n",
    "mask_test = np.array([pid in common_test_ids for pid in test_postids])\n",
    "x_test_tfidf_aligned = x_test_tfidf[mask_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6efb216d-e03e-4a14-bf3d-ecbe8a555095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge metadata and immagini\n",
    "\n",
    "train_meta_img = meta_train_final.merge(img_train_final, on='post_id')\n",
    "test_meta_img   = meta_test_final.merge(img_test_final, on='post_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc60e5e4-c991-481f-8a99-d18e7a039aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Controllo ordine post_id train: False\n",
      "Controllo ordine post_id test: True\n"
     ]
    }
   ],
   "source": [
    "# Check post_id order, it must be coherent between the two to not mix the y\n",
    "print(\"Controllo ordine post_id train:\", \n",
    "      (df_tfidf_trainval['post_id'].values == train_meta_img['post_id'].values).all())\n",
    "\n",
    "print(\"Controllo ordine post_id test:\", \n",
    "      (df_tfidf_test['post_id'].values == test_meta_img['post_id'].values).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb089086-0f1c-4f07-8ae0-e3eb9097e20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder meta according to tfidf order\n",
    "train_meta_img_ordered = train_meta_img.set_index('post_id').loc[trainval_postids].reset_index()\n",
    "test_meta_img_ordered = test_meta_img.set_index('post_id').loc[test_postids].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f67122d-5f26-4ce8-85ba-729544ac3881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Controllo ordine post_id train: True\n",
      "Controllo ordine post_id test: True\n"
     ]
    }
   ],
   "source": [
    "# Chech again\n",
    "print(\"Controllo ordine post_id train:\", \n",
    "      (df_tfidf_trainval['post_id'].values == train_meta_img_ordered['post_id'].values).all())\n",
    "\n",
    "print(\"Controllo ordine post_id test:\", \n",
    "      (df_tfidf_test['post_id'].values == test_meta_img['post_id'].values).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e679bff-a0cc-4fff-89fe-56492b163523",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_meta_img, x_trainval_tfidf, x_test_tfidf\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00d4cd57-d4d7-459d-a8f9-573f7fbfafeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_meta_img = train_meta_img_ordered.drop(columns=[]).copy()\n",
    "train_postids = train_meta_img_ordered['post_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0597f29-a0e7-4a91-adc4-51062aedc74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_postids = test_meta_img_ordered['post_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3fe4f169-a802-48a8-b9f4-d7ee70743bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full = hstack([x_trainval_tfidf_aligned, \n",
    "                       train_meta_img_ordered.drop(columns=['post_id']).values])\n",
    "X_test_full  = hstack([x_test_tfidf_aligned, \n",
    "                       test_meta_img_ordered.drop(columns=['post_id']).values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d0255b1-aea7-4239-9192-624794191b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF train shape: (1185822, 50079)\n",
      "Meta+Img train shape: (1185822, 178)\n",
      "Full train shape: (1185822, 50256)\n",
      "\n",
      "TF-IDF test shape: (423604, 50079)\n",
      "Meta+Img test shape: (423604, 177)\n",
      "Full test shape: (423604, 50256)\n"
     ]
    }
   ],
   "source": [
    "print(\"TF-IDF train shape:\", x_trainval_tfidf_aligned.shape)\n",
    "print(\"Meta+Img train shape:\", X_train_meta_img.shape)\n",
    "print(\"Full train shape:\", X_train_full.shape)\n",
    "print()\n",
    "print(\"TF-IDF test shape:\", x_test_tfidf_aligned.shape)\n",
    "print(\"Meta+Img test shape:\", test_meta_img.drop(columns=['post_id']).shape)\n",
    "print(\"Full test shape:\", X_test_full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47250b09-1764-4794-8933-6920533cdace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train: 1185822\n",
      "X_train_full: 1185822\n",
      "y_test: 423604\n",
      "X_test_full: 423604\n"
     ]
    }
   ],
   "source": [
    "# Controllo dimensioni di y\n",
    "print(\"y_train:\", len(y_trainval))\n",
    "print(\"X_train_full:\", X_train_full.shape[0])\n",
    "print(\"y_test:\", len(y_te))\n",
    "print(\"X_test_full:\", X_test_full.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6ef91f7-990e-456d-841b-59a248606591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._coo.coo_matrix'>\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train_full))\n",
    "print(X_train_full.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "990914b2-44bf-43fe-b360-901a2eeebd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 1185822 samples, 50256 features\n",
      "Test set: 423604 samples, 50256 features\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train set: {X_train_full.shape[0]} samples, {X_train_full.shape[1]} features\")\n",
    "print(f\"Test set: {X_test_full.shape[0]} samples, {X_test_full.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7ee7a67-8c5c-49b1-9d8f-a97dd438fa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# da DuckDB\n",
    "metadata_tr = con.sql(\"\"\"\n",
    "    SELECT post_id, er_bins FROM md1718\n",
    "    WHERE split = 'train' OR split = 'validation'\n",
    "\"\"\").df().set_index('post_id')\n",
    "\n",
    "metadata_te = con.sql(\"\"\"\n",
    "    SELECT post_id, er_bins FROM md1718\n",
    "    WHERE split = 'test'\n",
    "\"\"\").df().set_index('post_id')\n",
    "\n",
    "# allineamento diretto ai post_id in X\n",
    "y_train_full = metadata_tr.loc[train_postids, 'er_bins'].values\n",
    "y_test       = metadata_te.loc[test_postids, 'er_bins'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "66cf436b-6bd7-4fcf-8c78-1b1e52486be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_npz(\"D:/dataset/multimodal/X_trval_full_TR.npz\", X_train_full)\n",
    "save_npz(\"D:/dataset/multimodal/X_test_full_TR.npz\", X_test_full)\n",
    "\n",
    "y_trainval_np = np.asarray(y_trainval)\n",
    "y_test_np     = np.asarray(y_test)\n",
    "\n",
    "np.save(\"D:/dataset/multimodal/y_trval_full_TR.npy\", y_trainval_np)\n",
    "np.save(\"D:/dataset/multimodal/y_test_TR.npy\", y_test_np)\n",
    "\n",
    "train_postids_np = np.asarray(train_postids)\n",
    "test_postids_np  = np.asarray(test_postids)\n",
    "\n",
    "np.save(\"D:/dataset/multimodal/postid_trval_full_TR.npy\", train_postids_np)\n",
    "np.save(\"D:/dataset/multimodal/postid_test_TR.npy\", test_postids_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc0e2164-fbbb-445d-9e81-0c9a16d727be",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = r\"D:/dataset/multimodal\"\n",
    "\n",
    "X_train_full = load_npz(f\"{DIR}/X_trval_full_TR.npz\")\n",
    "X_test_full = load_npz(f\"{DIR}/X_test_full_TR.npz\")\n",
    "\n",
    "y_tr = np.load(os.path.join(DIR, \"y_trval_full_TR.npy\"), allow_pickle = True)\n",
    "y_te = np.load(os.path.join(DIR, \"y_test_TR.npy\"), allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "732eff44-a4eb-4987-9fec-6017fb84cf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_tr)\n",
    "y_te_enc = le.transform(y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c4cc56d-84fd-40f2-9c51-7da9c775143f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configuration: BernoulliNB(alpha=10)\n",
      "macro-F1 (test): 0.2643 | accuracy (test): 0.3094\n",
      "\n",
      "Configuration: RandomForestClassifier(max_depth=12, max_features=0.05, min_samples_leaf=5,\n",
      "                       n_estimators=80, n_jobs=-1, random_state=42)\n",
      "macro-F1 (test): 0.3185 | accuracy (test): 0.3368\n",
      "\n",
      "Configuration: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.5, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric='mlogloss',\n",
      "              feature_types=None, feature_weights=None, gamma=1,\n",
      "              grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=150, n_jobs=-1, num_class=5, ...)\n",
      "macro-F1 (test): 0.3318 | accuracy (test): 0.3646\n",
      "\n",
      "Configuration: LinearSVC(C=0.1, max_iter=5000, random_state=42)\n",
      "macro-F1 (test): 0.3315 | accuracy (test): 0.3666\n"
     ]
    }
   ],
   "source": [
    "cfgs = [\n",
    "    RandomForestClassifier(\n",
    "        max_depth=12, max_features=0.05, min_samples_leaf=5, n_estimators=80, n_jobs=-1, random_state=42\n",
    "    ),\n",
    "    XGBClassifier(colsample_bytree = 0.5, gamma = 1, learning_rate = 0.1, max_depth= 6, n_estimators= 150, reg_lambda= 1, subsample= 0.8,\n",
    "        objective=\"multi:softmax\",\n",
    "        num_class=len(np.unique(y_train_enc)),\n",
    "        tree_method=\"hist\", eval_metric=\"mlogloss\",\n",
    "        n_jobs=-1, random_state=42, verbosity=0\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "for cfg in cfgs:\n",
    "    print(f\"\\nConfiguration: {cfg}\")\n",
    "\n",
    "    # XGB requires a numerical target\n",
    "    if isinstance(cfg, XGBClassifier):\n",
    "        cfg.fit(X_train_full, y_train_enc)\n",
    "        y_te_pred = cfg.predict(X_test_full)\n",
    "        macro_f1 = f1_score(y_te_enc, y_te_pred, average=\"macro\")\n",
    "        acc = accuracy_score(y_te_enc, y_te_pred)\n",
    "\n",
    "    else:\n",
    "        cfg.fit(X_train_full, y_tr)\n",
    "        y_te_pred = cfg.predict(X_test_full)\n",
    "        macro_f1 = f1_score(y_te, y_te_pred, average=\"macro\")\n",
    "        acc = accuracy_score(y_te, y_te_pred)\n",
    "\n",
    "    print(f\"macro-F1 (test): {macro_f1:.4f} | accuracy (test): {acc:.4f}\")\n",
    "\n",
    "# Bernoulli results are wrong as they refer to another alpha, check cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f5e1414-1047-4651-af3c-041bffbeb5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = r\"D:/dataset/multimodal\"\n",
    "\n",
    "X_full = load_npz(f\"{DIR}/X_trval_full_TR.npz\").tocsr().astype(np.float32)\n",
    "Xte_full = load_npz(f\"{DIR}/X_test_full_TR.npz\").tocsr().astype(np.float32)\n",
    "\n",
    "y_tr = np.load(os.path.join(DIR, \"y_trval_full_TR.npy\"), allow_pickle = True)\n",
    "y_te = np.load(os.path.join(DIR, \"y_test_TR.npy\"), allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9e618aa-9fc7-4830-9a7a-8633ac561172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macro-F1 (test): 0.3104 | accuracy (test): 0.3619\n"
     ]
    }
   ],
   "source": [
    "cfg = SGDClassifier(\n",
    "        loss=\"hinge\",\n",
    "        penalty=\"l2\",\n",
    "        alpha = 1e-05,\n",
    "        average = True,\n",
    "        class_weight = None,\n",
    "        random_state=42,\n",
    "        max_iter=1000,\n",
    "        tol=1e-3,\n",
    "    )\n",
    "\n",
    "\n",
    "cfg.fit(X_full, y_tr)\n",
    "y_te_pred = cfg.predict(Xte_full)\n",
    "macro_f1 = f1_score(y_te, y_te_pred, average=\"macro\")\n",
    "acc = accuracy_score(y_te, y_te_pred)\n",
    "\n",
    "print(f\"macro-F1 (test): {macro_f1:.4f} | accuracy (test): {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acca1b7d-66f6-4af5-ad7a-436de519d5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macro-F1 (test): 0.2299 | accuracy (test): 0.2790\n"
     ]
    }
   ],
   "source": [
    "# TEST SU GAUSSIAN NAIVE BAYES\n",
    "\n",
    "batch_size = 256\n",
    "classes = np.unique(y_tr)\n",
    "\n",
    "clf = GaussianNB(var_smoothing = 1e-07)\n",
    "\n",
    "# Fit the model using minibatch for memory\n",
    "for start in range(0, X_full.shape[0], batch_size):\n",
    "    # print(f\"Batch {start} fit\")\n",
    "    end = min(start + batch_size, X_full.shape[0])\n",
    "\n",
    "    Xb = X_full[start:end].toarray()\n",
    "    yb = y_tr[start:end]\n",
    "\n",
    "    if start == 0:\n",
    "        clf.partial_fit(Xb, yb, classes=classes)\n",
    "    else:\n",
    "        clf.partial_fit(Xb, yb)\n",
    "\n",
    "    del Xb, yb\n",
    "    gc.collect()\n",
    "\n",
    "# Predict using minibatches\n",
    "y_te_pred = []\n",
    "\n",
    "for start in range(0, Xte_full.shape[0], batch_size):\n",
    "    # print(f\"Batch {start} predict\")\n",
    "    end = min(start + batch_size, Xte_full.shape[0])\n",
    "\n",
    "    Xb = Xte_full[start:end].toarray()\n",
    "    y_te_pred.append(clf.predict(Xb))\n",
    "\n",
    "    del Xb\n",
    "    gc.collect()\n",
    "\n",
    "y_te_pred = np.concatenate(y_te_pred)\n",
    "\n",
    "macro_f1 = f1_score(y_te, y_te_pred, average=\"macro\")\n",
    "acc = accuracy_score(y_te, y_te_pred)\n",
    "\n",
    "print(f\"macro-F1 (test): {macro_f1:.4f} | accuracy (test): {acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
