{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f99ddbe3-faf2-4609-bf3e-704906e39f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, duckdb, torch, timm, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import torchvision.transforms as T\n",
    "from pathlib import Path\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "import duckdb, torch\n",
    "from transformers import CLIPModel, CLIPProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1c79aa9-0d0a-4fe2-8353-8808b0281a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up ready\n"
     ]
    }
   ],
   "source": [
    "DB_PATH = \"D:/db/meta.duckdb\"\n",
    "con = duckdb.connect(DB_PATH)\n",
    "try:\n",
    "    con.execute(\"PRAGMA threads=8;\")\n",
    "except duckdb.InvalidInputException:\n",
    "    pass\n",
    "\n",
    "print(\"Set up ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc33b0a6-fc18-4dfe-b6ef-c77202e0f4fa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# SET UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cf80f75-9aeb-462c-a309-fa19b8b739c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "563b939e2060403b889c32ad79c2e9e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<_duckdb.DuckDBPyConnection at 0x1a2476f5130>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"\"\"\n",
    "CREATE OR REPLACE TABLE train_clip_sample AS\n",
    "WITH categories AS (\n",
    "    SELECT DISTINCT category FROM md1718\n",
    "),\n",
    "params AS (\n",
    "    SELECT COUNT(*) AS num_categories FROM categories\n",
    "),\n",
    "sampled AS (\n",
    "    SELECT *\n",
    "    FROM (\n",
    "        SELECT\n",
    "            *,\n",
    "            ROW_NUMBER() OVER (\n",
    "                PARTITION BY category\n",
    "                ORDER BY RANDOM()\n",
    "            ) AS rn\n",
    "        FROM md1718\n",
    "        WHERE split = 'train'\n",
    "    )\n",
    "    WHERE rn <= (25000 / (SELECT num_categories FROM params))\n",
    ")\n",
    "SELECT *\n",
    "FROM sampled;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c261b7b-59da-4ae6-94f0-505063559497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_duckdb.DuckDBPyConnection at 0x1a2476f5130>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"\"\"\n",
    "CREATE OR REPLACE TABLE val_clip_sample AS\n",
    "SELECT *\n",
    "FROM md1718\n",
    "WHERE split = 'validation'\n",
    "ORDER BY RANDOM()\n",
    "LIMIT 5000;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c92d18c-6e82-4cb8-b838-aaea82738309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_duckdb.DuckDBPyConnection at 0x1a2476f5130>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"\"\"CREATE OR REPLACE TABLE test_clip_sample AS\n",
    "SELECT *\n",
    "FROM md1718\n",
    "WHERE split = 'test'\n",
    "ORDER BY RANDOM()\n",
    "LIMIT 5000;\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a3a0bbc-290a-4422-91de-80b775c1671b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_duckdb.DuckDBPyConnection at 0x1a2476f5130>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"\"\"ALTER TABLE train_clip_sample DROP COLUMN rn\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3c3fca4-3da0-460e-aec6-a8139b5579a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_duckdb.DuckDBPyConnection at 0x1a2476f5130>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"\"\"CREATE OR REPLACE TABLE clip_full_sample AS\n",
    "SELECT * FROM train_clip_sample\n",
    "UNION ALL\n",
    "SELECT * FROM val_clip_sample\n",
    "UNION ALL\n",
    "SELECT * FROM test_clip_sample;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3341600e-0c74-4606-b20d-d4fdf26ea120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tot</th>\n",
       "      <th>duplicates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34993</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tot  duplicates\n",
       "0  34993           0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.sql(\"\"\"SELECT COUNT(*) AS tot, COUNT(*) - COUNT(DISTINCT post_id) AS duplicates FROM clip_full_sample\"\"\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ba1b792-363f-443c-a65d-fef21a8c5be0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>split</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>travel</td>\n",
       "      <td>validation</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>beauty</td>\n",
       "      <td>validation</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>family</td>\n",
       "      <td>test</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fitness</td>\n",
       "      <td>train</td>\n",
       "      <td>2777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pet</td>\n",
       "      <td>train</td>\n",
       "      <td>2777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>interior</td>\n",
       "      <td>validation</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fashion</td>\n",
       "      <td>test</td>\n",
       "      <td>1832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>other</td>\n",
       "      <td>test</td>\n",
       "      <td>859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>interior</td>\n",
       "      <td>train</td>\n",
       "      <td>2777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fitness</td>\n",
       "      <td>validation</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pet</td>\n",
       "      <td>validation</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>other</td>\n",
       "      <td>train</td>\n",
       "      <td>2777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fashion</td>\n",
       "      <td>train</td>\n",
       "      <td>2777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>fitness</td>\n",
       "      <td>test</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pet</td>\n",
       "      <td>test</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>food</td>\n",
       "      <td>train</td>\n",
       "      <td>2777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>family</td>\n",
       "      <td>validation</td>\n",
       "      <td>591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>travel</td>\n",
       "      <td>test</td>\n",
       "      <td>486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>beauty</td>\n",
       "      <td>test</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>beauty</td>\n",
       "      <td>train</td>\n",
       "      <td>2777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>travel</td>\n",
       "      <td>train</td>\n",
       "      <td>2777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>food</td>\n",
       "      <td>test</td>\n",
       "      <td>555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>family</td>\n",
       "      <td>train</td>\n",
       "      <td>2777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>food</td>\n",
       "      <td>validation</td>\n",
       "      <td>583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>fashion</td>\n",
       "      <td>validation</td>\n",
       "      <td>1838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>other</td>\n",
       "      <td>validation</td>\n",
       "      <td>846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>interior</td>\n",
       "      <td>test</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    category       split     n\n",
       "0     travel  validation   498\n",
       "1     beauty  validation   185\n",
       "2     family        test   651\n",
       "3    fitness       train  2777\n",
       "4        pet       train  2777\n",
       "5   interior  validation   208\n",
       "6    fashion        test  1832\n",
       "7      other        test   859\n",
       "8   interior       train  2777\n",
       "9    fitness  validation   139\n",
       "10       pet  validation   112\n",
       "11     other       train  2777\n",
       "12   fashion       train  2777\n",
       "13   fitness        test   150\n",
       "14       pet        test    97\n",
       "15      food       train  2777\n",
       "16    family  validation   591\n",
       "17    travel        test   486\n",
       "18    beauty        test   178\n",
       "19    beauty       train  2777\n",
       "20    travel       train  2777\n",
       "21      food        test   555\n",
       "22    family       train  2777\n",
       "23      food  validation   583\n",
       "24   fashion  validation  1838\n",
       "25     other  validation   846\n",
       "26  interior        test   192"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.sql(\"\"\"SELECT category, split, COUNT(*) as n\n",
    "FROM clip_full_sample\n",
    "GROUP BY category, split\"\"\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "911d6b22-4f5a-45d3-9c1c-56fdb9a2b426",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>er_bins</th>\n",
       "      <th>split</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>low</td>\n",
       "      <td>test</td>\n",
       "      <td>1009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>high</td>\n",
       "      <td>test</td>\n",
       "      <td>963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>medium</td>\n",
       "      <td>test</td>\n",
       "      <td>1021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>very_low</td>\n",
       "      <td>test</td>\n",
       "      <td>1039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>very_high</td>\n",
       "      <td>test</td>\n",
       "      <td>968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>low</td>\n",
       "      <td>train</td>\n",
       "      <td>5318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>very_low</td>\n",
       "      <td>train</td>\n",
       "      <td>4529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>very_high</td>\n",
       "      <td>train</td>\n",
       "      <td>4374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>high</td>\n",
       "      <td>train</td>\n",
       "      <td>5321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>medium</td>\n",
       "      <td>train</td>\n",
       "      <td>5451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>very_high</td>\n",
       "      <td>validation</td>\n",
       "      <td>1054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>low</td>\n",
       "      <td>validation</td>\n",
       "      <td>1010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>very_low</td>\n",
       "      <td>validation</td>\n",
       "      <td>989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>high</td>\n",
       "      <td>validation</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>medium</td>\n",
       "      <td>validation</td>\n",
       "      <td>949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      er_bins       split     n\n",
       "0         low        test  1009\n",
       "1        high        test   963\n",
       "2      medium        test  1021\n",
       "3    very_low        test  1039\n",
       "4   very_high        test   968\n",
       "5         low       train  5318\n",
       "6    very_low       train  4529\n",
       "7   very_high       train  4374\n",
       "8        high       train  5321\n",
       "9      medium       train  5451\n",
       "10  very_high  validation  1054\n",
       "11        low  validation  1010\n",
       "12   very_low  validation   989\n",
       "13       high  validation   998\n",
       "14     medium  validation   949"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.sql(\"\"\"SELECT er_bins, split, COUNT(*) as n\n",
    "FROM clip_full_sample\n",
    "GROUP BY er_bins, split\n",
    "ORDER BY split\"\"\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db17a512-931b-4122-a1a4-f5cbf8e0bea4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>er_bins3</th>\n",
       "      <th>split</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>medium</td>\n",
       "      <td>test</td>\n",
       "      <td>1629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>high</td>\n",
       "      <td>test</td>\n",
       "      <td>1639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>low</td>\n",
       "      <td>test</td>\n",
       "      <td>1732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high</td>\n",
       "      <td>train</td>\n",
       "      <td>8102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>medium</td>\n",
       "      <td>train</td>\n",
       "      <td>8868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>low</td>\n",
       "      <td>train</td>\n",
       "      <td>8023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>low</td>\n",
       "      <td>validation</td>\n",
       "      <td>1682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>high</td>\n",
       "      <td>validation</td>\n",
       "      <td>1751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>medium</td>\n",
       "      <td>validation</td>\n",
       "      <td>1567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  er_bins3       split     n\n",
       "0   medium        test  1629\n",
       "1     high        test  1639\n",
       "2      low        test  1732\n",
       "3     high       train  8102\n",
       "4   medium       train  8868\n",
       "5      low       train  8023\n",
       "6      low  validation  1682\n",
       "7     high  validation  1751\n",
       "8   medium  validation  1567"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.sql(\"\"\"SELECT er_bins3, split, COUNT(*) as n\n",
    "FROM clip_full_sample\n",
    "GROUP BY er_bins3, split\n",
    "ORDER BY split\"\"\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "625ae4f3-2efe-457e-9e8b-eb0fe03ca27c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>er_bins2</th>\n",
       "      <th>split</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>low</td>\n",
       "      <td>test</td>\n",
       "      <td>2555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>high</td>\n",
       "      <td>test</td>\n",
       "      <td>2445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>high</td>\n",
       "      <td>train</td>\n",
       "      <td>12504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>low</td>\n",
       "      <td>train</td>\n",
       "      <td>12489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>high</td>\n",
       "      <td>validation</td>\n",
       "      <td>2516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>low</td>\n",
       "      <td>validation</td>\n",
       "      <td>2484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  er_bins2       split      n\n",
       "0      low        test   2555\n",
       "1     high        test   2445\n",
       "2     high       train  12504\n",
       "3      low       train  12489\n",
       "4     high  validation   2516\n",
       "5      low  validation   2484"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.sql(\"\"\"SELECT er_bins2, split, COUNT(*) as n\n",
    "FROM clip_full_sample\n",
    "GROUP BY er_bins2, split\n",
    "ORDER BY split\"\"\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b99be44-a447-46ce-b6c1-e0363d91129e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cid</th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>notnull</th>\n",
       "      <th>dflt_value</th>\n",
       "      <th>pk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>filename</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>username</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>like_count</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>comment_count</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>width</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>height</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>time_utc</td>\n",
       "      <td>TIMESTAMP</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>caption</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>aspect_ratio</td>\n",
       "      <td>DOUBLE</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>area</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>orientation</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>date_day</td>\n",
       "      <td>TIMESTAMP</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>dow</td>\n",
       "      <td>BIGINT</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>hour_utc</td>\n",
       "      <td>BIGINT</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>has_caption</td>\n",
       "      <td>BOOLEAN</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>caption_len_char</td>\n",
       "      <td>BIGINT</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>month</td>\n",
       "      <td>BIGINT</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>year</td>\n",
       "      <td>BIGINT</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>n_hashtags</td>\n",
       "      <td>BIGINT</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>n_mentions</td>\n",
       "      <td>BIGINT</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>n_urls</td>\n",
       "      <td>BIGINT</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>n_emojis</td>\n",
       "      <td>BIGINT</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>category</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>followers</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>followees</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>posts</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>engagement_rate</td>\n",
       "      <td>DOUBLE</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>er_log</td>\n",
       "      <td>DOUBLE</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>er_bins</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>post_id</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>caption_language</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>caption_clean</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>caption_lang</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>caption_tfidf</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>caption_bert_clip</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>split</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>in_train_balanced</td>\n",
       "      <td>BOOLEAN</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>er_bins3</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>er_bins2</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cid               name       type  notnull dflt_value     pk\n",
       "0     0           filename    VARCHAR    False       None  False\n",
       "1     1           username    VARCHAR    False       None  False\n",
       "2     2         like_count    INTEGER    False       None  False\n",
       "3     3      comment_count    INTEGER    False       None  False\n",
       "4     4              width    INTEGER    False       None  False\n",
       "5     5             height    INTEGER    False       None  False\n",
       "6     6           time_utc  TIMESTAMP    False       None  False\n",
       "7     7            caption    VARCHAR    False       None  False\n",
       "8     8       aspect_ratio     DOUBLE    False       None  False\n",
       "9     9               area    INTEGER    False       None  False\n",
       "10   10        orientation    VARCHAR    False       None  False\n",
       "11   11           date_day  TIMESTAMP    False       None  False\n",
       "12   12                dow     BIGINT    False       None  False\n",
       "13   13           hour_utc     BIGINT    False       None  False\n",
       "14   14        has_caption    BOOLEAN    False       None  False\n",
       "15   15   caption_len_char     BIGINT    False       None  False\n",
       "16   16              month     BIGINT    False       None  False\n",
       "17   17               year     BIGINT    False       None  False\n",
       "18   18         n_hashtags     BIGINT    False       None  False\n",
       "19   19         n_mentions     BIGINT    False       None  False\n",
       "20   20             n_urls     BIGINT    False       None  False\n",
       "21   21           n_emojis     BIGINT    False       None  False\n",
       "22   22           category    VARCHAR    False       None  False\n",
       "23   23          followers    INTEGER    False       None  False\n",
       "24   24          followees    INTEGER    False       None  False\n",
       "25   25              posts    INTEGER    False       None  False\n",
       "26   26    engagement_rate     DOUBLE    False       None  False\n",
       "27   27             er_log     DOUBLE    False       None  False\n",
       "28   28            er_bins    VARCHAR    False       None  False\n",
       "29   29            post_id    VARCHAR    False       None  False\n",
       "30   30   caption_language    VARCHAR    False       None  False\n",
       "31   31      caption_clean    VARCHAR    False       None  False\n",
       "32   32       caption_lang    VARCHAR    False       None  False\n",
       "33   33      caption_tfidf    VARCHAR    False       None  False\n",
       "34   34  caption_bert_clip    VARCHAR    False       None  False\n",
       "35   35              split    VARCHAR    False       None  False\n",
       "36   36  in_train_balanced    BOOLEAN    False       None  False\n",
       "37   37           er_bins3    VARCHAR    False       None  False\n",
       "38   38           er_bins2    VARCHAR    False       None  False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.sql(\"\"\"PRAGMA table_info('clip_full_sample')\"\"\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c254db0c-0364-4b0b-94b0-66b0fc35ea9f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2611e8ce-08a8-4d6f-a1e9-4004f8e692dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size: 24993\n"
     ]
    }
   ],
   "source": [
    "sample_df = con.execute(\"SELECT post_id FROM clip_full_sample25 WHERE split = 'train'\").df()\n",
    "sample_ids = sample_df[\"post_id\"].to_numpy()\n",
    "\n",
    "print(\"Sample size:\", len(sample_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2cba9b08-eb37-4f87-9ad2-371908209ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve TEXT embeddings\n",
    "text_npz_path = \"D:/dataset/clip_text_emb_ALL/clip-vit-base-patch32_train_ids_y.npz\"\n",
    "train_text = np.load(text_npz_path, allow_pickle=True)\n",
    "\n",
    "X_all_text = train_text[\"embeddings\"] \n",
    "ids_all_text = train_text[\"ids\"]      \n",
    "\n",
    "mask_text = np.isin(ids_all_text, sample_ids)\n",
    "X_text_filt = X_all_text[mask_text]\n",
    "ids_text_filt = ids_all_text[mask_text]\n",
    "\n",
    "# DataFrame\n",
    "df_text = pd.DataFrame({\n",
    "    \"post_id\": ids_text_filt,\n",
    "    \"emb\": list(X_text_filt)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c20836b6-b05e-4b04-a536-a4f54cdbd276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve IMAGE embeddings \n",
    "\n",
    "img_npz_path = \"D:/dataset/clip_img_emb_ALL/clip_vit_b32_train_ALL.npz\"\n",
    "train_img = np.load(img_npz_path, allow_pickle=True)\n",
    "\n",
    "X_all_img = train_img[\"feats\"] \n",
    "ids_all_img = train_img[\"post_id\"] \n",
    "\n",
    "mask_img = np.isin(ids_all_img, sample_ids)\n",
    "X_img_filt = X_all_img[mask_img]\n",
    "ids_img_filt = ids_all_img[mask_img]\n",
    "\n",
    "df_img = pd.DataFrame({\n",
    "    \"post_id\": ids_img_filt,\n",
    "    \"emb\": list(X_img_filt)\n",
    "})\n",
    "\n",
    "agg = df_img.groupby(\"post_id\")[\"emb\"].apply(lambda s: np.mean(np.vstack(s.values), axis=0))\n",
    "\n",
    "df_img_agg = agg.reset_index() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4fee9db-b135-4e8e-8f60-ae76e0be9f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta rows after filter: 24993\n"
     ]
    }
   ],
   "source": [
    "meta = pd.read_csv(\"D:/dataset/meta_classification/meta_train_final.csv\")\n",
    "\n",
    "# Filter\n",
    "meta = meta[meta[\"post_id\"].isin(sample_ids)].copy()\n",
    "print(\"Meta rows after filter:\", len(meta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0f3f440-5a1d-4388-9f07-ecff6d9f1fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "post_id                   object\n",
       "width                    float64\n",
       "height                   float64\n",
       "aspect_ratio             float64\n",
       "area                     float64\n",
       "dow                      float64\n",
       "hour_utc                 float64\n",
       "month                    float64\n",
       "year                     float64\n",
       "caption_len_char         float64\n",
       "n_hashtags               float64\n",
       "n_mentions               float64\n",
       "n_urls                   float64\n",
       "n_emojis                 float64\n",
       "followees                float64\n",
       "posts                    float64\n",
       "has_caption                int64\n",
       "orientation_landscape    float64\n",
       "orientation_portrait     float64\n",
       "orientation_square       float64\n",
       "category_beauty          float64\n",
       "category_family          float64\n",
       "category_fashion         float64\n",
       "category_fitness         float64\n",
       "category_food            float64\n",
       "category_interior        float64\n",
       "category_other           float64\n",
       "category_pet             float64\n",
       "category_travel          float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d96c15c8-c175-4ee2-944c-f7cd40199c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = df_text.rename(columns={\"emb\": \"emb_text\"})\n",
    "df_img_agg = df_img_agg.rename(columns={\"emb\": \"emb_img\"})\n",
    "\n",
    "# Align\n",
    "aligned = (\n",
    "    sample_df[[\"post_id\"]]\n",
    "    .merge(df_text, on=\"post_id\", how=\"left\")\n",
    "    .merge(df_img_agg, on=\"post_id\", how=\"left\")\n",
    "    .merge(meta, on=\"post_id\", how=\"left\")\n",
    ")\n",
    "\n",
    "assert aligned[\"emb_text\"].notna().all()\n",
    "assert aligned[\"emb_img\"].notna().all()\n",
    "\n",
    "X_text = np.stack(aligned[\"emb_text\"].to_numpy())\n",
    "X_img  = np.stack(aligned[\"emb_img\"].to_numpy())\n",
    "\n",
    "meta_cols = meta.columns.drop(\"post_id\")\n",
    "X_meta = aligned[meta_cols].to_numpy(np.float32)\n",
    "\n",
    "X_train = np.hstack([X_text, X_img, X_meta])\n",
    "ids_train = aligned[\"post_id\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3cc4ebaf-b6e8-411b-a259-fa8e8fcb99fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24993, 512) (24993, 512) (24993, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_text.shape, X_img.shape, X_meta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aa783aeb-1ce4-471c-a230-cfb7e0456b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"D:/dataset/restricted_clip/X_tr\", X_train)\n",
    "np.save(\"D:/dataset/restricted_clip/ids_train\", ids_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ea45c4-d7dc-468d-9bba-94a725b7e71d",
   "metadata": {},
   "source": [
    "# VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b270d97d-26d4-4362-9fbe-816045234793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size: 5000\n"
     ]
    }
   ],
   "source": [
    "sample_df = con.execute(\"SELECT post_id FROM clip_full_sample WHERE split = 'validation'\").df()\n",
    "sample_ids = sample_df[\"post_id\"].to_numpy()\n",
    "\n",
    "print(\"Sample size:\", len(sample_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9c29e503-2796-4afb-8034-6f3a825a184d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve TEXT embeddings\n",
    "text_npz_path = \"D:/dataset/clip_text_emb_ALL/clip-vit-base-patch32_val_ids_y.npz\"\n",
    "val_text = np.load(text_npz_path, allow_pickle=True)\n",
    "\n",
    "X_all_text = val_text[\"embeddings\"] \n",
    "ids_all_text = val_text[\"ids\"]      \n",
    "mask_text = np.isin(ids_all_text, sample_ids)\n",
    "X_text_filt = X_all_text[mask_text]\n",
    "ids_text_filt = ids_all_text[mask_text]\n",
    "\n",
    "df_text = pd.DataFrame({\n",
    "    \"post_id\": ids_text_filt,\n",
    "    \"emb\": list(X_text_filt)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "efbfc160-fb41-4010-bdda-f7a17e7b0e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve IMAGE embeddings \n",
    "img_npz_path = \"D:/dataset/clip_img_emb_ALL/clip_vit_b32_validation_ALL.npz\"\n",
    "val_img = np.load(img_npz_path, allow_pickle=True)\n",
    "\n",
    "X_all_img = val_img[\"feats\"]     \n",
    "ids_all_img = val_img[\"post_id\"] \n",
    "\n",
    "mask_img = np.isin(ids_all_img, sample_ids)\n",
    "X_img_filt = X_all_img[mask_img]\n",
    "ids_img_filt = ids_all_img[mask_img]\n",
    "\n",
    "df_img = pd.DataFrame({\n",
    "    \"post_id\": ids_img_filt,\n",
    "    \"emb\": list(X_img_filt)\n",
    "})\n",
    "\n",
    "agg = df_img.groupby(\"post_id\")[\"emb\"].apply(lambda s: np.mean(np.vstack(s.values), axis=0))\n",
    "\n",
    "df_img_agg = agg.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2a7008de-9c08-4c31-8344-a3756b48dfaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta rows after filter: 5000\n"
     ]
    }
   ],
   "source": [
    "meta = pd.read_csv(\"D:/dataset/meta_classification/meta_val_final.csv\")\n",
    "\n",
    "meta = meta[meta[\"post_id\"].isin(sample_ids)].copy()\n",
    "print(\"Meta rows after filter:\", len(meta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2cfe08bd-bde7-4454-9e67-075c50c5e3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = df_text.rename(columns={\"emb\": \"emb_text\"})\n",
    "df_img_agg = df_img_agg.rename(columns={\"emb\": \"emb_img\"})\n",
    "\n",
    "# Alignment\n",
    "aligned = (\n",
    "    sample_df[[\"post_id\"]]\n",
    "    .merge(df_text, on=\"post_id\", how=\"left\")\n",
    "    .merge(df_img_agg, on=\"post_id\", how=\"left\")\n",
    "    .merge(meta, on=\"post_id\", how=\"left\")\n",
    ")\n",
    "\n",
    "assert aligned[\"emb_text\"].notna().all()\n",
    "assert aligned[\"emb_img\"].notna().all()\n",
    "\n",
    "X_text = np.stack(aligned[\"emb_text\"].to_numpy())\n",
    "X_img  = np.stack(aligned[\"emb_img\"].to_numpy())\n",
    "\n",
    "meta_cols = meta.columns.drop(\"post_id\")\n",
    "X_meta = aligned[meta_cols].to_numpy(np.float32)\n",
    "\n",
    "X_val = np.hstack([X_text, X_img, X_meta])\n",
    "ids_val = aligned[\"post_id\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e20ff0dc-b035-41ec-80e6-39df136519fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 512) (5000, 512) (5000, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_text.shape, X_img.shape, X_meta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0fb01894-230a-4191-91c0-bee5c8c3908d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"D:/dataset/restricted_clip/X_va\", X_val)\n",
    "np.save(\"D:/dataset/restricted_clip/ids_va\", ids_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1760b350-cfaf-4bfe-a85c-a7b36ae663c5",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "81dd8b7a-b488-4657-ad3c-80e22a240996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size: 5000\n"
     ]
    }
   ],
   "source": [
    "sample_df = con.execute(\"SELECT post_id FROM clip_full_sample WHERE split = 'test'\").df()\n",
    "sample_ids = sample_df[\"post_id\"].to_numpy()\n",
    "\n",
    "print(\"Sample size:\", len(sample_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a481282c-1fb1-4158-a4ba-6b342e253384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve TEXT embeddings\n",
    "text_npz_path = \"D:/dataset/clip_text_emb_ALL/clip-vit-base-patch32_test_ids_y.npz\"\n",
    "test_text = np.load(text_npz_path, allow_pickle=True)\n",
    "\n",
    "X_all_text = test_text[\"embeddings\"]  \n",
    "ids_all_text = test_text[\"ids\"]       \n",
    "\n",
    "mask_text = np.isin(ids_all_text, sample_ids)\n",
    "X_text_filt = X_all_text[mask_text]\n",
    "ids_text_filt = ids_all_text[mask_text]\n",
    "\n",
    "df_text = pd.DataFrame({\n",
    "    \"post_id\": ids_text_filt,\n",
    "    \"emb_text\": list(X_text_filt)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1558c4a8-8e98-4eb1-92f7-a5dac8a8ca61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve IMAGE embeddings \n",
    "img_npz_path = \"D:/dataset/clip_img_emb_ALL/clip_vit_b32_test_ALL.npz\"\n",
    "test_img = np.load(img_npz_path, allow_pickle=True)\n",
    "\n",
    "X_all_img = test_img[\"feats\"]         \n",
    "ids_all_img = test_img[\"post_id\"]     \n",
    "\n",
    "\n",
    "mask_img = np.isin(ids_all_img, sample_ids)\n",
    "X_img_filt = X_all_img[mask_img]\n",
    "ids_img_filt = ids_all_img[mask_img]\n",
    "\n",
    "df_img = pd.DataFrame({\n",
    "    \"post_id\": ids_img_filt,\n",
    "    \"emb_img\": list(X_img_filt)\n",
    "})\n",
    "\n",
    "agg = df_img.groupby(\"post_id\")[\"emb_img\"].apply(lambda s: np.mean(np.vstack(s.values), axis=0))\n",
    "\n",
    "df_img_agg = agg.reset_index()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4480726c-ba27-43f8-97b0-397a5de58fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta rows after filter: 5000\n"
     ]
    }
   ],
   "source": [
    "meta = pd.read_csv(\"D:/dataset/meta_classification/meta_test_final.csv\")\n",
    "\n",
    "meta = meta[meta[\"post_id\"].isin(sample_ids)].copy()\n",
    "print(\"Meta rows after filter:\", len(meta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5ca27841-07d4-4718-9214-3437d07ddd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alignment\n",
    "aligned = (\n",
    "    sample_df[[\"post_id\"]]\n",
    "    .merge(df_text, on=\"post_id\", how=\"left\")\n",
    "    .merge(df_img_agg, on=\"post_id\", how=\"left\")\n",
    "    .merge(meta, on=\"post_id\", how=\"left\")\n",
    ")\n",
    "\n",
    "assert aligned[\"emb_text\"].notna().all()\n",
    "assert aligned[\"emb_img\"].notna().all()\n",
    "\n",
    "X_text = np.stack(aligned[\"emb_text\"].to_numpy())\n",
    "X_img  = np.stack(aligned[\"emb_img\"].to_numpy())\n",
    "\n",
    "meta_cols = meta.columns.drop(\"post_id\")\n",
    "X_meta = aligned[meta_cols].to_numpy(np.float32)\n",
    "\n",
    "X_test = np.hstack([X_text, X_img, X_meta])\n",
    "ids_test = aligned[\"post_id\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "633ac44c-f45c-4526-a88a-c96fb00f693c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 512) (5000, 512) (5000, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_text.shape, X_img.shape, X_meta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4b52e1d7-0461-40d9-adca-e4e9c6be407a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"D:/dataset/restricted_clip/X_te\", X_test)\n",
    "np.save(\"D:/dataset/restricted_clip/ids_te\", ids_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8813ba-f898-495a-b1fa-22c595112000",
   "metadata": {},
   "source": [
    "# TARGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "af784166-4053-4f5b-9351-63c3ba72ff0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_tr_common = np.load(\"D:/dataset/restricted_clip/ids_train.npy\", allow_pickle = True)\n",
    "\n",
    "y_df = con.execute(\"\"\"\n",
    "    SELECT post_id, er_bins, er_bins3, er_bins2\n",
    "    FROM clip_full_sample25\n",
    "    WHERE split = 'train'\"\"\").df()\n",
    "\n",
    "\n",
    "y_tr_aligned5 = (\n",
    "    y_df.set_index(\"post_id\")\n",
    "        .loc[ids_tr_common, \"er_bins\"]\n",
    "        .to_numpy()\n",
    ")\n",
    "\n",
    "y_tr_aligned3 = (\n",
    "    y_df.set_index(\"post_id\")\n",
    "        .loc[ids_tr_common, \"er_bins3\"]\n",
    "        .to_numpy()\n",
    ")\n",
    "\n",
    "y_tr_aligned2 = (\n",
    "    y_df.set_index(\"post_id\")\n",
    "        .loc[ids_tr_common, \"er_bins2\"]\n",
    "        .to_numpy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a30adca8-efb6-4c93-a4cc-ca7ca921ff79",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"D:/dataset/restricted_clip/y_tr_5.npy\", y_tr_aligned5)\n",
    "np.save(\"D:/dataset/restricted_clip/y_tr_3.npy\", y_tr_aligned3)\n",
    "np.save(\"D:/dataset/restricted_clip/y_tr_2.npy\", y_tr_aligned2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d291a8c1-3f20-4edd-a7c8-3ef34be41619",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_va_common = np.load(\"D:/dataset/restricted_clip/ids_va.npy\", allow_pickle = True)\n",
    "\n",
    "y_df = con.execute(\"\"\"\n",
    "    SELECT post_id, er_bins, er_bins3, er_bins2\n",
    "    FROM clip_full_sample\n",
    "    WHERE split = 'validation'\"\"\").df()\n",
    "\n",
    "\n",
    "y_va_aligned5 = (\n",
    "    y_df.set_index(\"post_id\")\n",
    "        .loc[ids_va_common, \"er_bins\"]\n",
    "        .to_numpy()\n",
    ")\n",
    "\n",
    "y_va_aligned3 = (\n",
    "    y_df.set_index(\"post_id\")\n",
    "        .loc[ids_va_common, \"er_bins3\"]\n",
    "        .to_numpy()\n",
    ")\n",
    "\n",
    "y_va_aligned2 = (\n",
    "    y_df.set_index(\"post_id\")\n",
    "        .loc[ids_va_common, \"er_bins2\"]\n",
    "        .to_numpy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a44bb6aa-4dfe-448a-9b61-1aa0853d505f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"D:/dataset/restricted_clip/y_va_5.npy\", y_va_aligned5)\n",
    "np.save(\"D:/dataset/restricted_clip/y_va_3.npy\", y_va_aligned3)\n",
    "np.save(\"D:/dataset/restricted_clip/y_va_2.npy\", y_va_aligned2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ccb4fec6-1442-4c06-a8a6-2c4123ff31c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_te_common = np.load(\"D:/dataset/restricted_clip/ids_te.npy\", allow_pickle = True)\n",
    "\n",
    "y_df = con.execute(\"\"\"\n",
    "    SELECT post_id, er_bins, er_bins3, er_bins2\n",
    "    FROM clip_full_sample\n",
    "    WHERE split = 'test'\"\"\").df()\n",
    "\n",
    "\n",
    "y_te_aligned5 = (\n",
    "    y_df.set_index(\"post_id\")\n",
    "        .loc[ids_te_common, \"er_bins\"]\n",
    "        .to_numpy()\n",
    ")\n",
    "\n",
    "y_te_aligned3 = (\n",
    "    y_df.set_index(\"post_id\")\n",
    "        .loc[ids_te_common, \"er_bins3\"]\n",
    "        .to_numpy()\n",
    ")\n",
    "\n",
    "y_te_aligned2 = (\n",
    "    y_df.set_index(\"post_id\")\n",
    "        .loc[ids_te_common, \"er_bins2\"]\n",
    "        .to_numpy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8774b15c-e5fc-4058-bc19-32710e526c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"D:/dataset/restricted_clip/y_te_5.npy\", y_te_aligned5)\n",
    "np.save(\"D:/dataset/restricted_clip/y_te_3.npy\", y_te_aligned3)\n",
    "np.save(\"D:/dataset/restricted_clip/y_te_2.npy\", y_te_aligned2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaecd49-2587-425d-9bb0-39f77ebbf7c7",
   "metadata": {},
   "source": [
    "# CLASSIFICATION 5 CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c174436c-bcc2-4862-861b-6f17f5d4a15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = np.load(\"D:/dataset/restricted_clip/X_tr.npy\", allow_pickle = True).astype(np.float32)\n",
    "X_va = np.load(\"D:/dataset/restricted_clip/X_va.npy\", allow_pickle = True).astype(np.float32)\n",
    "\n",
    "y_tr = np.load(\"D:/dataset/restricted_clip/y_tr_5.npy\", allow_pickle = True)\n",
    "y_va = np.load(\"D:/dataset/restricted_clip/y_va_5.npy\", allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63b4e697-96b8-42a0-8949-b698e1205b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24993, 1052) (5000, 1052) (24993,) (5000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_tr.shape, X_va.shape, y_tr.shape, y_va.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1827079-cdb4-4038-bfba-ed2d94e67461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination: {'alpha': 1e-05, 'class_weight': None}\n",
      "macro-F1 (val): 0.3168640479518058 | accuracy (val): 0.3264\n",
      "\n",
      "Combination: {'alpha': 1e-05, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.29921306397152864 | accuracy (val): 0.3296\n",
      "\n",
      "Combination: {'alpha': 0.0001, 'class_weight': None}\n",
      "macro-F1 (val): 0.31753262873448834 | accuracy (val): 0.334\n",
      "\n",
      "Combination: {'alpha': 0.0001, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.3087302193220355 | accuracy (val): 0.337\n",
      "\n",
      "Combination: {'alpha': 0.001, 'class_weight': None}\n",
      "macro-F1 (val): 0.32094997804774406 | accuracy (val): 0.3436\n",
      "\n",
      "Combination: {'alpha': 0.001, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.2944115215974648 | accuracy (val): 0.3378\n",
      "\n",
      "Combination: {'alpha': 0.01, 'class_weight': None}\n",
      "macro-F1 (val): 0.3097367452213542 | accuracy (val): 0.333\n",
      "\n",
      "Combination: {'alpha': 0.01, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.2886819017410057 | accuracy (val): 0.3332\n",
      "\n",
      "Best hyperparameter configuration:\n",
      "{'alpha': 0.001, 'class_weight': None}\n",
      "Validation macro-F1: 0.32094997804774406\n",
      "\n",
      "Ordered results by macro-F1 (validation):\n",
      "     alpha class_weight  val_macro_f1  val_accuracy\n",
      "4  0.00100         None      0.320950        0.3436\n",
      "2  0.00010         None      0.317533        0.3340\n",
      "0  0.00001         None      0.316864        0.3264\n",
      "6  0.01000         None      0.309737        0.3330\n",
      "3  0.00010     balanced      0.308730        0.3370\n",
      "1  0.00001     balanced      0.299213        0.3296\n",
      "5  0.00100     balanced      0.294412        0.3378\n",
      "7  0.01000     balanced      0.288682        0.3332\n"
     ]
    }
   ],
   "source": [
    "# SGD\n",
    "param_grid = {\n",
    "    \"alpha\": [1e-5, 1e-4, 1e-3, 1e-2],\n",
    "    \"class_weight\": [None, \"balanced\"],\n",
    "}\n",
    "\n",
    "results = []\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    print(f\"\\nCombination: {params}\")\n",
    "\n",
    "    clf = SGDClassifier(\n",
    "        loss=\"hinge\",            \n",
    "        penalty=\"l2\",            \n",
    "        **params,\n",
    "        average = True,\n",
    "        random_state=42,\n",
    "        max_iter=1000,\n",
    "        tol=1e-3,\n",
    "    )\n",
    "\n",
    "    clf.fit(X_tr, y_tr)\n",
    "\n",
    "    y_val_pred = clf.predict(X_va)\n",
    "\n",
    "    macro_f1 = f1_score(y_va, y_val_pred, average=\"macro\")\n",
    "    acc = accuracy_score(y_va, y_val_pred)\n",
    "\n",
    "    print(f\"macro-F1 (val): {macro_f1} | accuracy (val): {acc}\")\n",
    "\n",
    "    results.append({\n",
    "        \"alpha\": params[\"alpha\"],\n",
    "        \"class_weight\": params[\"class_weight\"],\n",
    "        \"val_macro_f1\": macro_f1,\n",
    "        \"val_accuracy\": acc,\n",
    "    })\n",
    "\n",
    "    if macro_f1 > best_score:\n",
    "        best_score = macro_f1\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\nBest hyperparameter configuration:\")\n",
    "print(best_params)\n",
    "print(\"Validation macro-F1:\", best_score)\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(\"val_macro_f1\", ascending=False)\n",
    "print(\"\\nOrdered results by macro-F1 (validation):\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f049210-b353-4d2f-9745-fb0e596220ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination: {'var_smoothing': 1e-09}\n",
      "macro-F1 (val): 0.2642 | accuracy (val): 0.2938\n",
      "\n",
      "Combination: {'var_smoothing': 1e-08}\n",
      "macro-F1 (val): 0.2642 | accuracy (val): 0.2938\n",
      "\n",
      "Combination: {'var_smoothing': 1e-07}\n",
      "macro-F1 (val): 0.2642 | accuracy (val): 0.2938\n",
      "\n",
      "Combination: {'var_smoothing': 1e-06}\n",
      "macro-F1 (val): 0.2648 | accuracy (val): 0.2946\n",
      "\n",
      "Best hyperparameter configuration:\n",
      "{'var_smoothing': 1e-06}\n",
      "Validation macro-F1: 0.26484311840960306\n",
      "\n",
      "Ordered results by macro-F1 (validation):\n",
      "   var_smoothing  val_macro_f1  val_accuracy\n",
      "3   1.000000e-06      0.264843        0.2946\n",
      "2   1.000000e-07      0.264247        0.2938\n",
      "1   1.000000e-08      0.264233        0.2938\n",
      "0   1.000000e-09      0.264233        0.2938\n"
     ]
    }
   ],
   "source": [
    "# NAIVE BAYES - GAUSSIAN\n",
    "param_grid_nb = {\n",
    "    \"var_smoothing\": [1e-9, 1e-8, 1e-7, 1e-6]\n",
    "}\n",
    "\n",
    "results = []\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "for params in ParameterGrid(param_grid_nb):\n",
    "    print(f\"\\nCombination: {params}\")\n",
    "\n",
    "    clf = GaussianNB(**params)\n",
    "\n",
    "    # Fit su TRAIN\n",
    "    clf.fit(X_tr, y_tr)\n",
    "\n",
    "    # Valutazione su VALIDATION\n",
    "    y_val_pred = clf.predict(X_va)\n",
    "\n",
    "    macro_f1 = f1_score(y_va, y_val_pred, average=\"macro\")\n",
    "    acc = accuracy_score(y_va, y_val_pred)\n",
    "\n",
    "    print(f\"macro-F1 (val): {macro_f1:.4f} | accuracy (val): {acc:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        \"var_smoothing\": params[\"var_smoothing\"],\n",
    "        \"val_macro_f1\": macro_f1,\n",
    "        \"val_accuracy\": acc,\n",
    "    })\n",
    "\n",
    "    # Aggiorno il best model in base alla macro-F1\n",
    "    if macro_f1 > best_score:\n",
    "        best_score = macro_f1\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\nBest hyperparameter configuration:\")\n",
    "print(best_params)\n",
    "print(\"Validation macro-F1:\", best_score)\n",
    "\n",
    "# Metto i risultati in un DataFrame per ispezionarli meglio\n",
    "results_df = pd.DataFrame(results).sort_values(\"val_macro_f1\", ascending=False)\n",
    "print(\"\\nOrdered results by macro-F1 (validation):\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d2aba22-27ed-4f1e-af0f-9f03f31aad04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.2946 | accuracy (val): 0.2900\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.2956 | accuracy (val): 0.2910\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.2941 | accuracy (val): 0.2902\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.2945 | accuracy (val): 0.2894\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.2847 | accuracy (val): 0.2820\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.2821 | accuracy (val): 0.2786\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.2861 | accuracy (val): 0.2820\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.2947 | accuracy (val): 0.2898\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.2917 | accuracy (val): 0.2878\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.2841 | accuracy (val): 0.2792\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.2906 | accuracy (val): 0.2862\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.2940 | accuracy (val): 0.2896\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.2868 | accuracy (val): 0.2828\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.2883 | accuracy (val): 0.2840\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.2787 | accuracy (val): 0.2744\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.2790 | accuracy (val): 0.2746\n",
      "\n",
      "Best hyperparameter configuration (Random Forest):\n",
      "{'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "Validation macro-F1: 0.2955942837540287\n",
      "\n",
      "Ordered results by macro-F1 (validation):\n",
      "    n_estimators  max_depth  min_samples_leaf max_features  val_macro_f1  \\\n",
      "1             80         10                 2         0.05      0.295594   \n",
      "7             80         10                 5         sqrt      0.294718   \n",
      "0             50         10                 2         0.05      0.294619   \n",
      "3             80         10                 5         0.05      0.294452   \n",
      "2             50         10                 5         0.05      0.294070   \n",
      "11            80         12                 5         0.05      0.294037   \n",
      "8             50         12                 2         0.05      0.291654   \n",
      "10            50         12                 5         0.05      0.290600   \n",
      "13            80         12                 2         sqrt      0.288320   \n",
      "12            50         12                 2         sqrt      0.286773   \n",
      "6             50         10                 5         sqrt      0.286050   \n",
      "4             50         10                 2         sqrt      0.284690   \n",
      "9             80         12                 2         0.05      0.284094   \n",
      "5             80         10                 2         sqrt      0.282069   \n",
      "15            80         12                 5         sqrt      0.278957   \n",
      "14            50         12                 5         sqrt      0.278727   \n",
      "\n",
      "    val_accuracy  \n",
      "1         0.2910  \n",
      "7         0.2898  \n",
      "0         0.2900  \n",
      "3         0.2894  \n",
      "2         0.2902  \n",
      "11        0.2896  \n",
      "8         0.2878  \n",
      "10        0.2862  \n",
      "13        0.2840  \n",
      "12        0.2828  \n",
      "6         0.2820  \n",
      "4         0.2820  \n",
      "9         0.2792  \n",
      "5         0.2786  \n",
      "15        0.2746  \n",
      "14        0.2744  \n"
     ]
    }
   ],
   "source": [
    "# RANDOM FOREST\n",
    "param_grid_rf = {\n",
    "    \"n_estimators\": [50, 80],\n",
    "    \"max_depth\": [10, 12],\n",
    "    \"min_samples_leaf\": [2, 5],\n",
    "    \"max_features\": [0.05, \"sqrt\"],\n",
    "}\n",
    "\n",
    "results = []\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "for params in ParameterGrid(param_grid_rf):\n",
    "    print(f\"\\nCombination: {params}\")\n",
    "\n",
    "    clf = RandomForestClassifier(\n",
    "        **params,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Fit su TRAIN\n",
    "    clf.fit(X_tr, y_tr)\n",
    "\n",
    "    # Valutazione su VALIDATION\n",
    "    y_val_pred = clf.predict(X_va)\n",
    "\n",
    "    macro_f1 = f1_score(y_va, y_val_pred, average=\"macro\")\n",
    "    acc = accuracy_score(y_va, y_val_pred)\n",
    "\n",
    "    print(f\"macro-F1 (val): {macro_f1:.4f} | accuracy (val): {acc:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        \"n_estimators\": params[\"n_estimators\"],\n",
    "        \"max_depth\": params[\"max_depth\"],\n",
    "        \"min_samples_leaf\": params[\"min_samples_leaf\"],\n",
    "        \"max_features\": params[\"max_features\"],\n",
    "        \"val_macro_f1\": macro_f1,\n",
    "        \"val_accuracy\": acc,\n",
    "    })\n",
    "\n",
    "    # Aggiorno il best model in base alla macro-F1\n",
    "    if macro_f1 > best_score:\n",
    "        best_score = macro_f1\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\nBest hyperparameter configuration (Random Forest):\")\n",
    "print(best_params)\n",
    "print(\"Validation macro-F1:\", best_score)\n",
    "\n",
    "# Metto i risultati in un DataFrame per ispezionarli meglio\n",
    "results_df_rf = pd.DataFrame(results).sort_values(\"val_macro_f1\", ascending=False)\n",
    "print(\"\\nOrdered results by macro-F1 (validation):\")\n",
    "print(results_df_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73452edd-967b-46e5-9c70-1c04ae7f84bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.3230 | accuracy (val): 0.3292\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 150, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.3257 | accuracy (val): 0.3322\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.3251 | accuracy (val): 0.3284\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 150, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.3208 | accuracy (val): 0.3224\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.3254 | accuracy (val): 0.3330\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 150, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.3240 | accuracy (val): 0.3298\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.3248 | accuracy (val): 0.3284\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 150, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.3239 | accuracy (val): 0.3254\n",
      "\n",
      "Best hyperparameter configuration (XGBoost):\n",
      "{'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 150, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "Validation macro-F1: 0.32570164679370917\n",
      "\n",
      "Ordered results:\n",
      "   colsample_bytree  gamma  learning_rate  max_depth  n_estimators  \\\n",
      "1               0.5      0            0.1          4           150   \n",
      "4               0.5      1            0.1          4           100   \n",
      "2               0.5      0            0.1          6           100   \n",
      "6               0.5      1            0.1          6           100   \n",
      "5               0.5      1            0.1          4           150   \n",
      "7               0.5      1            0.1          6           150   \n",
      "0               0.5      0            0.1          4           100   \n",
      "3               0.5      0            0.1          6           150   \n",
      "\n",
      "   reg_lambda  subsample  val_macro_f1  val_accuracy  \n",
      "1           1        0.8      0.325702        0.3322  \n",
      "4           1        0.8      0.325397        0.3330  \n",
      "2           1        0.8      0.325092        0.3284  \n",
      "6           1        0.8      0.324848        0.3284  \n",
      "5           1        0.8      0.323986        0.3298  \n",
      "7           1        0.8      0.323885        0.3254  \n",
      "0           1        0.8      0.322980        0.3292  \n",
      "3           1        0.8      0.320805        0.3224  \n"
     ]
    }
   ],
   "source": [
    "# XGBOOST\n",
    "\n",
    "# Convert the labels into numbers\n",
    "le = LabelEncoder()\n",
    "y_tr_enc = le.fit_transform(y_tr)\n",
    "y_val_enc = le.transform(y_va)\n",
    "\n",
    "\n",
    "param_grid_xgb = {\n",
    "    \"n_estimators\": [100, 150],\n",
    "    \"max_depth\": [4, 6],\n",
    "    \"learning_rate\": [0.1],\n",
    "    \"subsample\": [0.8],\n",
    "    \"colsample_bytree\": [0.5], \n",
    "    \"gamma\": [0, 1], \n",
    "    \"reg_lambda\": [1], \n",
    "}\n",
    "\n",
    "results = []\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "for params in ParameterGrid(param_grid_xgb):\n",
    "    print(f\"\\nCombination: {params}\")\n",
    "\n",
    "    clf = XGBClassifier(\n",
    "        **params,\n",
    "        objective=\"multi:softmax\",\n",
    "        num_class=len(np.unique(y_tr_enc)),\n",
    "        tree_method=\"hist\",\n",
    "        eval_metric=\"mlogloss\",\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        verbosity=0,\n",
    "    )\n",
    "\n",
    "    # Fit\n",
    "    clf.fit(X_tr, y_tr_enc)\n",
    "\n",
    "    # Validation\n",
    "    y_val_pred = clf.predict(X_va)\n",
    "\n",
    "    macro_f1 = f1_score(y_val_enc, y_val_pred, average=\"macro\")\n",
    "    acc = accuracy_score(y_val_enc, y_val_pred)\n",
    "\n",
    "    print(f\"macro-F1 (val): {macro_f1:.4f} | accuracy (val): {acc:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        **params,\n",
    "        \"val_macro_f1\": macro_f1,\n",
    "        \"val_accuracy\": acc,\n",
    "    })\n",
    "\n",
    "    if macro_f1 > best_score:\n",
    "        best_score = macro_f1\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\nBest hyperparameter configuration (XGBoost):\")\n",
    "print(best_params)\n",
    "print(\"Validation macro-F1:\", best_score)\n",
    "\n",
    "results_df_xgb = pd.DataFrame(results).sort_values(\"val_macro_f1\", ascending=False)\n",
    "print(\"\\nOrdered results:\")\n",
    "print(results_df_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "384fd7e4-fe7b-4a28-b388-2aa67a4e7999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "283"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del X_tr, X_va, y_tr, y_va\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe87bb14-a04c-4f91-8df1-275f684bc35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PERFORMANCE ON TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d47a4e2-da70-4479-b321-9f6179bf80d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr = np.load(\"D:/dataset/restricted_clip/X_tr.npy\", allow_pickle = True)\n",
    "X_va = np.load(\"D:/dataset/restricted_clip/X_va.npy\", allow_pickle = True)\n",
    "X_te = np.load(\"D:/dataset/restricted_clip/X_te.npy\", allow_pickle = True)\n",
    "\n",
    "\n",
    "y_tr = np.load(\"D:/dataset/restricted_clip/y_tr_5.npy\", allow_pickle = True)\n",
    "y_va = np.load(\"D:/dataset/restricted_clip/y_va_5.npy\", allow_pickle = True)\n",
    "y_te = np.load(\"D:/dataset/restricted_clip/y_te_5.npy\", allow_pickle = True)\n",
    "\n",
    "X_trva = np.concatenate((X_tr, X_va), axis = 0)\n",
    "y_trva = np.concatenate((y_tr, y_va), axis = 0)\n",
    "\n",
    "del X_tr, X_va, y_tr, y_va\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "068fbb05-53c4-4ed6-abe7-35f8eb67072d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configuration: GaussianNB(var_smoothing=1e-06)\n",
      "macro-F1 (train): 0.2671 | accuracy (train): 0.2964\n",
      "\n",
      "Configuration: RandomForestClassifier(max_depth=10, max_features=0.05, min_samples_leaf=2,\n",
      "                       n_estimators=80, n_jobs=-1, random_state=42)\n",
      "macro-F1 (train): 0.3016 | accuracy (train): 0.2996\n",
      "\n",
      "Configuration: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.5, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric='mlogloss',\n",
      "              feature_types=None, feature_weights=None, gamma=0,\n",
      "              grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=150, n_jobs=-1, num_class=5, ...)\n",
      "macro-F1 (train): 0.3255 | accuracy (train): 0.3412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1188"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y_trva_enc = le.fit_transform(y_trva)\n",
    "y_te_enc = le.transform(y_te)\n",
    "\n",
    "cfgs = [\n",
    "    GaussianNB(var_smoothing = 1e-06),\n",
    "    RandomForestClassifier(\n",
    "        max_depth=10, max_features=0.05, min_samples_leaf=2, n_estimators=80, n_jobs=-1, random_state=42\n",
    "    ),\n",
    "    XGBClassifier(colsample_bytree = 0.5, gamma = 0, learning_rate = 0.1, max_depth= 4, n_estimators= 150, reg_lambda= 1, subsample= 0.8,\n",
    "        objective=\"multi:softmax\",\n",
    "        num_class=len(np.unique(y_trva_enc)),\n",
    "        tree_method=\"hist\", eval_metric=\"mlogloss\",\n",
    "        n_jobs=-1, random_state=42, verbosity=0\n",
    "    )\n",
    "]\n",
    "\n",
    "for cfg in cfgs:\n",
    "    print(f\"\\nConfiguration: {cfg}\")\n",
    "\n",
    "    # XGB requires a numerical target\n",
    "    if isinstance(cfg, XGBClassifier):\n",
    "        cfg.fit(X_trva, y_trva_enc)\n",
    "        y_te_pred = cfg.predict(X_te)\n",
    "        macro_f1 = f1_score(y_te_enc, y_te_pred, average=\"macro\")\n",
    "        acc = accuracy_score(y_te_enc, y_te_pred)\n",
    "\n",
    "    else:\n",
    "        cfg.fit(X_trva, y_trva)\n",
    "        y_te_pred = cfg.predict(X_te)\n",
    "        macro_f1 = f1_score(y_te, y_te_pred, average=\"macro\")\n",
    "        acc = accuracy_score(y_te, y_te_pred)\n",
    "\n",
    "    print(f\"macro-F1 (train): {macro_f1:.4f} | accuracy (train): {acc:.4f}\")\n",
    "\n",
    "del X_trva, X_te, y_trva, y_te\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4658ee7-47d4-41e6-8fe6-104385800cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macro-F1 (test): 0.2989 | accuracy (test): 0.3396\n"
     ]
    }
   ],
   "source": [
    "cfg = SGDClassifier(\n",
    "        loss=\"hinge\",\n",
    "        penalty=\"l2\",\n",
    "        alpha = 0.001,\n",
    "        average = True,\n",
    "        class_weight = None,\n",
    "        random_state=42,\n",
    "        max_iter=1000,\n",
    "        tol=1e-3,\n",
    "    )\n",
    "\n",
    "\n",
    "cfg.fit(X_trva, y_trva)\n",
    "y_te_pred = cfg.predict(X_te)\n",
    "macro_f1 = f1_score(y_te, y_te_pred, average=\"macro\")\n",
    "acc = accuracy_score(y_te, y_te_pred)\n",
    "\n",
    "print(f\"macro-F1 (test): {macro_f1:.4f} | accuracy (test): {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc7a005-fe3a-4d86-966d-603ba0ab63f8",
   "metadata": {},
   "source": [
    "# CLASSIFICATION 3 CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5899f555-dc13-4a06-b979-02ffbb980b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = np.load(\"D:/dataset/restricted_clip/X_tr.npy\", allow_pickle = True).astype(np.float32)\n",
    "X_va = np.load(\"D:/dataset/restricted_clip/X_va.npy\", allow_pickle = True).astype(np.float32)\n",
    "\n",
    "y_tr = np.load(\"D:/dataset/restricted_clip/y_tr_3.npy\", allow_pickle = True)\n",
    "y_va = np.load(\"D:/dataset/restricted_clip/y_va_3.npy\", allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9de1c73-16e9-4e6e-96d7-31cf98ce2cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination: {'alpha': 1e-05, 'class_weight': None}\n",
      "macro-F1 (val): 0.4933558139185065 | accuracy (val): 0.508\n",
      "\n",
      "Combination: {'alpha': 1e-05, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.4839664913056942 | accuracy (val): 0.5046\n",
      "\n",
      "Combination: {'alpha': 0.0001, 'class_weight': None}\n",
      "macro-F1 (val): 0.4866906282058006 | accuracy (val): 0.5158\n",
      "\n",
      "Combination: {'alpha': 0.0001, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.47427631658995945 | accuracy (val): 0.5158\n",
      "\n",
      "Combination: {'alpha': 0.001, 'class_weight': None}\n",
      "macro-F1 (val): 0.4357226241556084 | accuracy (val): 0.513\n",
      "\n",
      "Combination: {'alpha': 0.001, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.41993172267960593 | accuracy (val): 0.5104\n",
      "\n",
      "Combination: {'alpha': 0.01, 'class_weight': None}\n",
      "macro-F1 (val): 0.4107064490657348 | accuracy (val): 0.5062\n",
      "\n",
      "Combination: {'alpha': 0.01, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.4029048638703829 | accuracy (val): 0.5048\n",
      "\n",
      "Best hyperparameter configuration:\n",
      "{'alpha': 1e-05, 'class_weight': None}\n",
      "Validation macro-F1: 0.4933558139185065\n",
      "\n",
      "Ordered results by macro-F1 (validation):\n",
      "     alpha class_weight  val_macro_f1  val_accuracy\n",
      "0  0.00001         None      0.493356        0.5080\n",
      "2  0.00010         None      0.486691        0.5158\n",
      "1  0.00001     balanced      0.483966        0.5046\n",
      "3  0.00010     balanced      0.474276        0.5158\n",
      "4  0.00100         None      0.435723        0.5130\n",
      "5  0.00100     balanced      0.419932        0.5104\n",
      "6  0.01000         None      0.410706        0.5062\n",
      "7  0.01000     balanced      0.402905        0.5048\n"
     ]
    }
   ],
   "source": [
    "# SGD\n",
    "param_grid = {\n",
    "    \"alpha\": [1e-5, 1e-4, 1e-3, 1e-2],\n",
    "    \"class_weight\": [None, \"balanced\"],\n",
    "}\n",
    "\n",
    "results = []\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    print(f\"\\nCombination: {params}\")\n",
    "\n",
    "    clf = SGDClassifier(\n",
    "        loss=\"hinge\",            \n",
    "        penalty=\"l2\",            \n",
    "        **params,\n",
    "        average = True,\n",
    "        random_state=42,\n",
    "        max_iter=1000,\n",
    "        tol=1e-3,\n",
    "    )\n",
    "\n",
    "    clf.fit(X_tr, y_tr)\n",
    "\n",
    "    y_val_pred = clf.predict(X_va)\n",
    "\n",
    "    macro_f1 = f1_score(y_va, y_val_pred, average=\"macro\")\n",
    "    acc = accuracy_score(y_va, y_val_pred)\n",
    "\n",
    "    print(f\"macro-F1 (val): {macro_f1} | accuracy (val): {acc}\")\n",
    "\n",
    "    results.append({\n",
    "        \"alpha\": params[\"alpha\"],\n",
    "        \"class_weight\": params[\"class_weight\"],\n",
    "        \"val_macro_f1\": macro_f1,\n",
    "        \"val_accuracy\": acc,\n",
    "    })\n",
    "\n",
    "    if macro_f1 > best_score:\n",
    "        best_score = macro_f1\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\nBest hyperparameter configuration:\")\n",
    "print(best_params)\n",
    "print(\"Validation macro-F1:\", best_score)\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(\"val_macro_f1\", ascending=False)\n",
    "print(\"\\nOrdered results by macro-F1 (validation):\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f71e6ed-6d23-4388-80f5-5139959551f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination: {'var_smoothing': 1e-09}\n",
      "macro-F1 (val): 0.4373 | accuracy (val): 0.4592\n",
      "\n",
      "Combination: {'var_smoothing': 1e-08}\n",
      "macro-F1 (val): 0.4373 | accuracy (val): 0.4592\n",
      "\n",
      "Combination: {'var_smoothing': 1e-07}\n",
      "macro-F1 (val): 0.4373 | accuracy (val): 0.4592\n",
      "\n",
      "Combination: {'var_smoothing': 1e-06}\n",
      "macro-F1 (val): 0.4369 | accuracy (val): 0.4588\n",
      "\n",
      "Best hyperparameter configuration:\n",
      "{'var_smoothing': 1e-09}\n",
      "Validation macro-F1: 0.43731666035865174\n",
      "\n",
      "Ordered results by macro-F1 (validation):\n",
      "   var_smoothing  val_macro_f1  val_accuracy\n",
      "0   1.000000e-09      0.437317        0.4592\n",
      "1   1.000000e-08      0.437317        0.4592\n",
      "2   1.000000e-07      0.437317        0.4592\n",
      "3   1.000000e-06      0.436897        0.4588\n"
     ]
    }
   ],
   "source": [
    "# NAIVE BAYES - GAUSSIAN\n",
    "param_grid_nb = {\n",
    "    \"var_smoothing\": [1e-9, 1e-8, 1e-7, 1e-6]\n",
    "}\n",
    "\n",
    "results = []\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "for params in ParameterGrid(param_grid_nb):\n",
    "    print(f\"\\nCombination: {params}\")\n",
    "\n",
    "    clf = GaussianNB(**params)\n",
    "\n",
    "    # Fit su TRAIN\n",
    "    clf.fit(X_tr, y_tr)\n",
    "\n",
    "    # Valutazione su VALIDATION\n",
    "    y_val_pred = clf.predict(X_va)\n",
    "\n",
    "    macro_f1 = f1_score(y_va, y_val_pred, average=\"macro\")\n",
    "    acc = accuracy_score(y_va, y_val_pred)\n",
    "\n",
    "    print(f\"macro-F1 (val): {macro_f1:.4f} | accuracy (val): {acc:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        \"var_smoothing\": params[\"var_smoothing\"],\n",
    "        \"val_macro_f1\": macro_f1,\n",
    "        \"val_accuracy\": acc,\n",
    "    })\n",
    "\n",
    "    # Aggiorno il best model in base alla macro-F1\n",
    "    if macro_f1 > best_score:\n",
    "        best_score = macro_f1\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\nBest hyperparameter configuration:\")\n",
    "print(best_params)\n",
    "print(\"Validation macro-F1:\", best_score)\n",
    "\n",
    "# Metto i risultati in un DataFrame per ispezionarli meglio\n",
    "results_df = pd.DataFrame(results).sort_values(\"val_macro_f1\", ascending=False)\n",
    "print(\"\\nOrdered results by macro-F1 (validation):\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5e851e4-a44e-4d6b-b52c-ac32f0197aad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.4626 | accuracy (val): 0.4604\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.4724 | accuracy (val): 0.4702\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.4719 | accuracy (val): 0.4698\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.4739 | accuracy (val): 0.4716\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.4697 | accuracy (val): 0.4668\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.4726 | accuracy (val): 0.4692\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.4586 | accuracy (val): 0.4550\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.4631 | accuracy (val): 0.4592\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.4614 | accuracy (val): 0.4610\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.4734 | accuracy (val): 0.4718\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.4681 | accuracy (val): 0.4660\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.4714 | accuracy (val): 0.4692\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.4668 | accuracy (val): 0.4642\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.4697 | accuracy (val): 0.4670\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.4642 | accuracy (val): 0.4616\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.4710 | accuracy (val): 0.4684\n",
      "\n",
      "Best hyperparameter configuration (Random Forest):\n",
      "{'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "Validation macro-F1: 0.4739082782227236\n",
      "\n",
      "Ordered results by macro-F1 (validation):\n",
      "    n_estimators  max_depth  min_samples_leaf max_features  val_macro_f1  \\\n",
      "3             80         10                 5         0.05      0.473908   \n",
      "9             80         12                 2         0.05      0.473408   \n",
      "5             80         10                 2         sqrt      0.472562   \n",
      "1             80         10                 2         0.05      0.472365   \n",
      "2             50         10                 5         0.05      0.471869   \n",
      "11            80         12                 5         0.05      0.471358   \n",
      "15            80         12                 5         sqrt      0.471018   \n",
      "13            80         12                 2         sqrt      0.469700   \n",
      "4             50         10                 2         sqrt      0.469655   \n",
      "10            50         12                 5         0.05      0.468120   \n",
      "12            50         12                 2         sqrt      0.466833   \n",
      "14            50         12                 5         sqrt      0.464211   \n",
      "7             80         10                 5         sqrt      0.463130   \n",
      "0             50         10                 2         0.05      0.462619   \n",
      "8             50         12                 2         0.05      0.461443   \n",
      "6             50         10                 5         sqrt      0.458608   \n",
      "\n",
      "    val_accuracy  \n",
      "3         0.4716  \n",
      "9         0.4718  \n",
      "5         0.4692  \n",
      "1         0.4702  \n",
      "2         0.4698  \n",
      "11        0.4692  \n",
      "15        0.4684  \n",
      "13        0.4670  \n",
      "4         0.4668  \n",
      "10        0.4660  \n",
      "12        0.4642  \n",
      "14        0.4616  \n",
      "7         0.4592  \n",
      "0         0.4604  \n",
      "8         0.4610  \n",
      "6         0.4550  \n"
     ]
    }
   ],
   "source": [
    "# RANDOM FOREST\n",
    "param_grid_rf = {\n",
    "    \"n_estimators\": [50, 80],\n",
    "    \"max_depth\": [10, 12],\n",
    "    \"min_samples_leaf\": [2, 5],\n",
    "    \"max_features\": [0.05, \"sqrt\"],\n",
    "}\n",
    "\n",
    "results = []\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "for params in ParameterGrid(param_grid_rf):\n",
    "    print(f\"\\nCombination: {params}\")\n",
    "\n",
    "    clf = RandomForestClassifier(\n",
    "        **params,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Fit su TRAIN\n",
    "    clf.fit(X_tr, y_tr)\n",
    "\n",
    "    # Valutazione su VALIDATION\n",
    "    y_val_pred = clf.predict(X_va)\n",
    "\n",
    "    macro_f1 = f1_score(y_va, y_val_pred, average=\"macro\")\n",
    "    acc = accuracy_score(y_va, y_val_pred)\n",
    "\n",
    "    print(f\"macro-F1 (val): {macro_f1:.4f} | accuracy (val): {acc:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        \"n_estimators\": params[\"n_estimators\"],\n",
    "        \"max_depth\": params[\"max_depth\"],\n",
    "        \"min_samples_leaf\": params[\"min_samples_leaf\"],\n",
    "        \"max_features\": params[\"max_features\"],\n",
    "        \"val_macro_f1\": macro_f1,\n",
    "        \"val_accuracy\": acc,\n",
    "    })\n",
    "\n",
    "    # Aggiorno il best model in base alla macro-F1\n",
    "    if macro_f1 > best_score:\n",
    "        best_score = macro_f1\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\nBest hyperparameter configuration (Random Forest):\")\n",
    "print(best_params)\n",
    "print(\"Validation macro-F1:\", best_score)\n",
    "\n",
    "# Metto i risultati in un DataFrame per ispezionarli meglio\n",
    "results_df_rf = pd.DataFrame(results).sort_values(\"val_macro_f1\", ascending=False)\n",
    "print(\"\\nOrdered results by macro-F1 (validation):\")\n",
    "print(results_df_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92e51c9b-03f6-405b-83e1-83b6eb019efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.5029 | accuracy (val): 0.5074\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 150, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.5063 | accuracy (val): 0.5096\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.4964 | accuracy (val): 0.5000\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 150, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.4970 | accuracy (val): 0.4996\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.5074 | accuracy (val): 0.5116\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 150, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.5006 | accuracy (val): 0.5044\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.4992 | accuracy (val): 0.5026\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 150, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.5006 | accuracy (val): 0.5036\n",
      "\n",
      "Best hyperparameter configuration (XGBoost):\n",
      "{'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "Validation macro-F1: 0.507438774533056\n",
      "\n",
      "Ordered results:\n",
      "   colsample_bytree  gamma  learning_rate  max_depth  n_estimators  \\\n",
      "4               0.5      1            0.1          4           100   \n",
      "1               0.5      0            0.1          4           150   \n",
      "0               0.5      0            0.1          4           100   \n",
      "7               0.5      1            0.1          6           150   \n",
      "5               0.5      1            0.1          4           150   \n",
      "6               0.5      1            0.1          6           100   \n",
      "3               0.5      0            0.1          6           150   \n",
      "2               0.5      0            0.1          6           100   \n",
      "\n",
      "   reg_lambda  subsample  val_macro_f1  val_accuracy  \n",
      "4           1        0.8      0.507439        0.5116  \n",
      "1           1        0.8      0.506251        0.5096  \n",
      "0           1        0.8      0.502907        0.5074  \n",
      "7           1        0.8      0.500596        0.5036  \n",
      "5           1        0.8      0.500562        0.5044  \n",
      "6           1        0.8      0.499225        0.5026  \n",
      "3           1        0.8      0.496950        0.4996  \n",
      "2           1        0.8      0.496444        0.5000  \n"
     ]
    }
   ],
   "source": [
    "# XGBOOST\n",
    "\n",
    "# Convert the labels into numbers\n",
    "le = LabelEncoder()\n",
    "y_tr_enc = le.fit_transform(y_tr)\n",
    "y_val_enc = le.transform(y_va)\n",
    "\n",
    "\n",
    "param_grid_xgb = {\n",
    "    \"n_estimators\": [100, 150],\n",
    "    \"max_depth\": [4, 6],\n",
    "    \"learning_rate\": [0.1],\n",
    "    \"subsample\": [0.8],\n",
    "    \"colsample_bytree\": [0.5], \n",
    "    \"gamma\": [0, 1], \n",
    "    \"reg_lambda\": [1], \n",
    "}\n",
    "\n",
    "results = []\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "for params in ParameterGrid(param_grid_xgb):\n",
    "    print(f\"\\nCombination: {params}\")\n",
    "\n",
    "    clf = XGBClassifier(\n",
    "        **params,\n",
    "        objective=\"multi:softmax\",\n",
    "        num_class=len(np.unique(y_tr_enc)),\n",
    "        tree_method=\"hist\",\n",
    "        eval_metric=\"mlogloss\",\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        verbosity=0,\n",
    "    )\n",
    "\n",
    "    # Fit\n",
    "    clf.fit(X_tr, y_tr_enc)\n",
    "\n",
    "    # Validation\n",
    "    y_val_pred = clf.predict(X_va)\n",
    "\n",
    "    macro_f1 = f1_score(y_val_enc, y_val_pred, average=\"macro\")\n",
    "    acc = accuracy_score(y_val_enc, y_val_pred)\n",
    "\n",
    "    print(f\"macro-F1 (val): {macro_f1:.4f} | accuracy (val): {acc:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        **params,\n",
    "        \"val_macro_f1\": macro_f1,\n",
    "        \"val_accuracy\": acc,\n",
    "    })\n",
    "\n",
    "    if macro_f1 > best_score:\n",
    "        best_score = macro_f1\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\nBest hyperparameter configuration (XGBoost):\")\n",
    "print(best_params)\n",
    "print(\"Validation macro-F1:\", best_score)\n",
    "\n",
    "results_df_xgb = pd.DataFrame(results).sort_values(\"val_macro_f1\", ascending=False)\n",
    "print(\"\\nOrdered results:\")\n",
    "print(results_df_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f132a0fb-054c-4fe1-b6b7-261e032b4a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PERFORMANCE ON TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8818c003-fe00-4224-8776-321bdbc4f42b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr = np.load(\"D:/dataset/restricted_clip/X_tr.npy\", allow_pickle = True)\n",
    "X_va = np.load(\"D:/dataset/restricted_clip/X_va.npy\", allow_pickle = True)\n",
    "X_te = np.load(\"D:/dataset/restricted_clip/X_te.npy\", allow_pickle = True)\n",
    "\n",
    "\n",
    "y_tr = np.load(\"D:/dataset/restricted_clip/y_tr_3.npy\", allow_pickle = True)\n",
    "y_va = np.load(\"D:/dataset/restricted_clip/y_va_3.npy\", allow_pickle = True)\n",
    "y_te = np.load(\"D:/dataset/restricted_clip/y_te_3.npy\", allow_pickle = True)\n",
    "\n",
    "X_trva = np.concatenate((X_tr, X_va), axis = 0)\n",
    "y_trva = np.concatenate((y_tr, y_va), axis = 0)\n",
    "\n",
    "del X_tr, X_va, y_tr, y_va\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adf15360-48e1-4cb1-afc4-afffc64c437c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configuration: GaussianNB()\n",
      "macro-F1 (train): 0.4382 | accuracy (train): 0.4580\n",
      "\n",
      "Configuration: RandomForestClassifier(max_depth=10, max_features=0.05, min_samples_leaf=5,\n",
      "                       n_estimators=80, n_jobs=-1, random_state=42)\n",
      "macro-F1 (train): 0.4850 | accuracy (train): 0.4860\n",
      "\n",
      "Configuration: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.5, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric='mlogloss',\n",
      "              feature_types=None, feature_weights=None, gamma=1,\n",
      "              grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=100, n_jobs=-1, num_class=3, ...)\n",
      "macro-F1 (train): 0.4954 | accuracy (train): 0.5044\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1581"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y_trva_enc = le.fit_transform(y_trva)\n",
    "y_te_enc = le.transform(y_te)\n",
    "\n",
    "cfgs = [\n",
    "    GaussianNB(var_smoothing = 1e-09),\n",
    "    RandomForestClassifier(\n",
    "        max_depth=10, max_features=0.05, min_samples_leaf=5, n_estimators=80, n_jobs=-1, random_state=42\n",
    "    ),\n",
    "    XGBClassifier(colsample_bytree = 0.5, gamma = 1, learning_rate = 0.1, max_depth= 4, n_estimators= 100, reg_lambda= 1, subsample= 0.8,\n",
    "        objective=\"multi:softmax\",\n",
    "        num_class=len(np.unique(y_trva_enc)),\n",
    "        tree_method=\"hist\", eval_metric=\"mlogloss\",\n",
    "        n_jobs=-1, random_state=42, verbosity=0\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "for cfg in cfgs:\n",
    "    print(f\"\\nConfiguration: {cfg}\")\n",
    "\n",
    "    # XGB requires a numerical target\n",
    "    if isinstance(cfg, XGBClassifier):\n",
    "        cfg.fit(X_trva, y_trva_enc)\n",
    "        y_te_pred = cfg.predict(X_te)\n",
    "        macro_f1 = f1_score(y_te_enc, y_te_pred, average=\"macro\")\n",
    "        acc = accuracy_score(y_te_enc, y_te_pred)\n",
    "\n",
    "    else:\n",
    "        cfg.fit(X_trva, y_trva)\n",
    "        y_te_pred = cfg.predict(X_te)\n",
    "        macro_f1 = f1_score(y_te, y_te_pred, average=\"macro\")\n",
    "        acc = accuracy_score(y_te, y_te_pred)\n",
    "\n",
    "    print(f\"macro-F1 (train): {macro_f1:.4f} | accuracy (train): {acc:.4f}\")\n",
    "\n",
    "del X_trva, X_te, y_trva, y_te\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac382550-9cd3-47b9-8675-e6f098bc31f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macro-F1 (test): 0.4782 | accuracy (test): 0.5028\n"
     ]
    }
   ],
   "source": [
    "cfg = SGDClassifier(\n",
    "        loss=\"hinge\",\n",
    "        penalty=\"l2\",\n",
    "        alpha = 1e-5,\n",
    "        average = True,\n",
    "        class_weight = None,\n",
    "        random_state=42,\n",
    "        max_iter=1000,\n",
    "        tol=1e-3,\n",
    "    )\n",
    "\n",
    "\n",
    "cfg.fit(X_trva, y_trva)\n",
    "y_te_pred = cfg.predict(X_te)\n",
    "macro_f1 = f1_score(y_te, y_te_pred, average=\"macro\")\n",
    "acc = accuracy_score(y_te, y_te_pred)\n",
    "\n",
    "print(f\"macro-F1 (test): {macro_f1:.4f} | accuracy (test): {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42659e30-fb90-413a-b8b0-1f503f462d8c",
   "metadata": {},
   "source": [
    "# CLASSIFICATION 2 CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12d362ea-a77a-4ee5-b0b7-b08b98ba4ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = np.load(\"D:/dataset/restricted_clip/X_tr.npy\", allow_pickle = True).astype(np.float32)\n",
    "X_va = np.load(\"D:/dataset/restricted_clip/X_va.npy\", allow_pickle = True).astype(np.float32)\n",
    "\n",
    "y_tr = np.load(\"D:/dataset/restricted_clip/y_tr_2.npy\", allow_pickle = True)\n",
    "y_va = np.load(\"D:/dataset/restricted_clip/y_va_2.npy\", allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16701535-b458-46ad-b925-2ba1e9445d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination: {'alpha': 1e-05, 'class_weight': None}\n",
      "macro-F1 (val): 0.6724385728162641 | accuracy (val): 0.673\n",
      "\n",
      "Combination: {'alpha': 1e-05, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.6750198902644489 | accuracy (val): 0.6754\n",
      "\n",
      "Combination: {'alpha': 0.0001, 'class_weight': None}\n",
      "macro-F1 (val): 0.6750097416832987 | accuracy (val): 0.676\n",
      "\n",
      "Combination: {'alpha': 0.0001, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.6759236976785228 | accuracy (val): 0.6768\n",
      "\n",
      "Combination: {'alpha': 0.001, 'class_weight': None}\n",
      "macro-F1 (val): 0.674530230596537 | accuracy (val): 0.676\n",
      "\n",
      "Combination: {'alpha': 0.001, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.6741876522540373 | accuracy (val): 0.6754\n",
      "\n",
      "Combination: {'alpha': 0.01, 'class_weight': None}\n",
      "macro-F1 (val): 0.6588612838041854 | accuracy (val): 0.6616\n",
      "\n",
      "Combination: {'alpha': 0.01, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.6594766911895806 | accuracy (val): 0.6618\n",
      "\n",
      "Best hyperparameter configuration:\n",
      "{'alpha': 0.0001, 'class_weight': 'balanced'}\n",
      "Validation macro-F1: 0.6759236976785228\n",
      "\n",
      "Ordered results by macro-F1 (validation):\n",
      "     alpha class_weight  val_macro_f1  val_accuracy\n",
      "3  0.00010     balanced      0.675924        0.6768\n",
      "1  0.00001     balanced      0.675020        0.6754\n",
      "2  0.00010         None      0.675010        0.6760\n",
      "4  0.00100         None      0.674530        0.6760\n",
      "5  0.00100     balanced      0.674188        0.6754\n",
      "0  0.00001         None      0.672439        0.6730\n",
      "7  0.01000     balanced      0.659477        0.6618\n",
      "6  0.01000         None      0.658861        0.6616\n"
     ]
    }
   ],
   "source": [
    "# SGD\n",
    "param_grid = {\n",
    "    \"alpha\": [1e-5, 1e-4, 1e-3, 1e-2],\n",
    "    \"class_weight\": [None, \"balanced\"],\n",
    "}\n",
    "\n",
    "results = []\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    print(f\"\\nCombination: {params}\")\n",
    "\n",
    "    clf = SGDClassifier(\n",
    "        loss=\"hinge\",            \n",
    "        penalty=\"l2\",            \n",
    "        **params,\n",
    "        average = True,\n",
    "        random_state=42,\n",
    "        max_iter=1000,\n",
    "        tol=1e-3,\n",
    "    )\n",
    "\n",
    "    clf.fit(X_tr, y_tr)\n",
    "\n",
    "    y_val_pred = clf.predict(X_va)\n",
    "\n",
    "    macro_f1 = f1_score(y_va, y_val_pred, average=\"macro\")\n",
    "    acc = accuracy_score(y_va, y_val_pred)\n",
    "\n",
    "    print(f\"macro-F1 (val): {macro_f1} | accuracy (val): {acc}\")\n",
    "\n",
    "    results.append({\n",
    "        \"alpha\": params[\"alpha\"],\n",
    "        \"class_weight\": params[\"class_weight\"],\n",
    "        \"val_macro_f1\": macro_f1,\n",
    "        \"val_accuracy\": acc,\n",
    "    })\n",
    "\n",
    "    if macro_f1 > best_score:\n",
    "        best_score = macro_f1\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\nBest hyperparameter configuration:\")\n",
    "print(best_params)\n",
    "print(\"Validation macro-F1:\", best_score)\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(\"val_macro_f1\", ascending=False)\n",
    "print(\"\\nOrdered results by macro-F1 (validation):\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a07105d1-266c-491a-b0b5-1995b8ea688f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination: {'var_smoothing': 1e-09}\n",
      "macro-F1 (val): 0.6305 | accuracy (val): 0.6306\n",
      "\n",
      "Combination: {'var_smoothing': 1e-08}\n",
      "macro-F1 (val): 0.6305 | accuracy (val): 0.6306\n",
      "\n",
      "Combination: {'var_smoothing': 1e-07}\n",
      "macro-F1 (val): 0.6305 | accuracy (val): 0.6306\n",
      "\n",
      "Combination: {'var_smoothing': 1e-06}\n",
      "macro-F1 (val): 0.6305 | accuracy (val): 0.6306\n",
      "\n",
      "Best hyperparameter configuration:\n",
      "{'var_smoothing': 1e-09}\n",
      "Validation macro-F1: 0.6305485575811576\n",
      "\n",
      "Ordered results by macro-F1 (validation):\n",
      "   var_smoothing  val_macro_f1  val_accuracy\n",
      "0   1.000000e-09      0.630549        0.6306\n",
      "1   1.000000e-08      0.630549        0.6306\n",
      "2   1.000000e-07      0.630549        0.6306\n",
      "3   1.000000e-06      0.630549        0.6306\n"
     ]
    }
   ],
   "source": [
    "# NAIVE BAYES - GAUSSIAN\n",
    "param_grid_nb = {\n",
    "    \"var_smoothing\": [1e-9, 1e-8, 1e-7, 1e-6]\n",
    "}\n",
    "\n",
    "results = []\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "for params in ParameterGrid(param_grid_nb):\n",
    "    print(f\"\\nCombination: {params}\")\n",
    "\n",
    "    clf = GaussianNB(**params)\n",
    "\n",
    "    # Fit su TRAIN\n",
    "    clf.fit(X_tr, y_tr)\n",
    "\n",
    "    # Valutazione su VALIDATION\n",
    "    y_val_pred = clf.predict(X_va)\n",
    "\n",
    "    macro_f1 = f1_score(y_va, y_val_pred, average=\"macro\")\n",
    "    acc = accuracy_score(y_va, y_val_pred)\n",
    "\n",
    "    print(f\"macro-F1 (val): {macro_f1:.4f} | accuracy (val): {acc:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        \"var_smoothing\": params[\"var_smoothing\"],\n",
    "        \"val_macro_f1\": macro_f1,\n",
    "        \"val_accuracy\": acc,\n",
    "    })\n",
    "\n",
    "    # Aggiorno il best model in base alla macro-F1\n",
    "    if macro_f1 > best_score:\n",
    "        best_score = macro_f1\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\nBest hyperparameter configuration:\")\n",
    "print(best_params)\n",
    "print(\"Validation macro-F1:\", best_score)\n",
    "\n",
    "# Metto i risultati in un DataFrame per ispezionarli meglio\n",
    "results_df = pd.DataFrame(results).sort_values(\"val_macro_f1\", ascending=False)\n",
    "print(\"\\nOrdered results by macro-F1 (validation):\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37870253-2eb8-4878-b329-9eb5061e54a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.6538 | accuracy (val): 0.6546\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.6562 | accuracy (val): 0.6568\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.6474 | accuracy (val): 0.6482\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.6542 | accuracy (val): 0.6550\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.6454 | accuracy (val): 0.6458\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.6450 | accuracy (val): 0.6454\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.6357 | accuracy (val): 0.6358\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.6464 | accuracy (val): 0.6466\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.6467 | accuracy (val): 0.6474\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.6567 | accuracy (val): 0.6572\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.6511 | accuracy (val): 0.6516\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.6502 | accuracy (val): 0.6508\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.6353 | accuracy (val): 0.6354\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.6468 | accuracy (val): 0.6470\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.6483 | accuracy (val): 0.6486\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.6527 | accuracy (val): 0.6528\n",
      "\n",
      "Best hyperparameter configuration (Random Forest):\n",
      "{'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "Validation macro-F1: 0.6566724291214852\n",
      "\n",
      "Ordered results by macro-F1 (validation):\n",
      "    n_estimators  max_depth  min_samples_leaf max_features  val_macro_f1  \\\n",
      "9             80         12                 2         0.05      0.656672   \n",
      "1             80         10                 2         0.05      0.656205   \n",
      "3             80         10                 5         0.05      0.654249   \n",
      "0             50         10                 2         0.05      0.653796   \n",
      "15            80         12                 5         sqrt      0.652655   \n",
      "10            50         12                 5         0.05      0.651053   \n",
      "11            80         12                 5         0.05      0.650195   \n",
      "14            50         12                 5         sqrt      0.648296   \n",
      "2             50         10                 5         0.05      0.647381   \n",
      "13            80         12                 2         sqrt      0.646793   \n",
      "8             50         12                 2         0.05      0.646747   \n",
      "7             80         10                 5         sqrt      0.646438   \n",
      "4             50         10                 2         sqrt      0.645404   \n",
      "5             80         10                 2         sqrt      0.645004   \n",
      "6             50         10                 5         sqrt      0.635690   \n",
      "12            50         12                 2         sqrt      0.635257   \n",
      "\n",
      "    val_accuracy  \n",
      "9         0.6572  \n",
      "1         0.6568  \n",
      "3         0.6550  \n",
      "0         0.6546  \n",
      "15        0.6528  \n",
      "10        0.6516  \n",
      "11        0.6508  \n",
      "14        0.6486  \n",
      "2         0.6482  \n",
      "13        0.6470  \n",
      "8         0.6474  \n",
      "7         0.6466  \n",
      "4         0.6458  \n",
      "5         0.6454  \n",
      "6         0.6358  \n",
      "12        0.6354  \n"
     ]
    }
   ],
   "source": [
    "# RANDOM FOREST\n",
    "param_grid_rf = {\n",
    "    \"n_estimators\": [50, 80],\n",
    "    \"max_depth\": [10, 12],\n",
    "    \"min_samples_leaf\": [2, 5],\n",
    "    \"max_features\": [0.05, \"sqrt\"],\n",
    "}\n",
    "\n",
    "results = []\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "for params in ParameterGrid(param_grid_rf):\n",
    "    print(f\"\\nCombination: {params}\")\n",
    "\n",
    "    clf = RandomForestClassifier(\n",
    "        **params,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Fit su TRAIN\n",
    "    clf.fit(X_tr, y_tr)\n",
    "\n",
    "    # Valutazione su VALIDATION\n",
    "    y_val_pred = clf.predict(X_va)\n",
    "\n",
    "    macro_f1 = f1_score(y_va, y_val_pred, average=\"macro\")\n",
    "    acc = accuracy_score(y_va, y_val_pred)\n",
    "\n",
    "    print(f\"macro-F1 (val): {macro_f1:.4f} | accuracy (val): {acc:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        \"n_estimators\": params[\"n_estimators\"],\n",
    "        \"max_depth\": params[\"max_depth\"],\n",
    "        \"min_samples_leaf\": params[\"min_samples_leaf\"],\n",
    "        \"max_features\": params[\"max_features\"],\n",
    "        \"val_macro_f1\": macro_f1,\n",
    "        \"val_accuracy\": acc,\n",
    "    })\n",
    "\n",
    "    # Aggiorno il best model in base alla macro-F1\n",
    "    if macro_f1 > best_score:\n",
    "        best_score = macro_f1\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\nBest hyperparameter configuration (Random Forest):\")\n",
    "print(best_params)\n",
    "print(\"Validation macro-F1:\", best_score)\n",
    "\n",
    "# Metto i risultati in un DataFrame per ispezionarli meglio\n",
    "results_df_rf = pd.DataFrame(results).sort_values(\"val_macro_f1\", ascending=False)\n",
    "print(\"\\nOrdered results by macro-F1 (validation):\")\n",
    "print(results_df_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c803085-1b15-44af-900e-eae402545a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.6771 | accuracy (val): 0.6774\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 150, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.6798 | accuracy (val): 0.6800\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.6770 | accuracy (val): 0.6774\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 150, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.6758 | accuracy (val): 0.6762\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.6775 | accuracy (val): 0.6778\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 150, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.6784 | accuracy (val): 0.6786\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.6794 | accuracy (val): 0.6798\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 150, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.6754 | accuracy (val): 0.6758\n",
      "\n",
      "Best hyperparameter configuration (XGBoost):\n",
      "{'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 150, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "Validation macro-F1: 0.6798030660777605\n",
      "\n",
      "Ordered results:\n",
      "   colsample_bytree  gamma  learning_rate  max_depth  n_estimators  \\\n",
      "1               0.5      0            0.1          4           150   \n",
      "6               0.5      1            0.1          6           100   \n",
      "5               0.5      1            0.1          4           150   \n",
      "4               0.5      1            0.1          4           100   \n",
      "0               0.5      0            0.1          4           100   \n",
      "2               0.5      0            0.1          6           100   \n",
      "3               0.5      0            0.1          6           150   \n",
      "7               0.5      1            0.1          6           150   \n",
      "\n",
      "   reg_lambda  subsample  val_macro_f1  val_accuracy  \n",
      "1           1        0.8      0.679803        0.6800  \n",
      "6           1        0.8      0.679442        0.6798  \n",
      "5           1        0.8      0.678424        0.6786  \n",
      "4           1        0.8      0.677466        0.6778  \n",
      "0           1        0.8      0.677090        0.6774  \n",
      "2           1        0.8      0.677013        0.6774  \n",
      "3           1        0.8      0.675830        0.6762  \n",
      "7           1        0.8      0.675365        0.6758  \n"
     ]
    }
   ],
   "source": [
    "# XGBOOST\n",
    "\n",
    "# Convert the labels into numbers\n",
    "le = LabelEncoder()\n",
    "y_tr_enc = le.fit_transform(y_tr)\n",
    "y_val_enc = le.transform(y_va)\n",
    "\n",
    "\n",
    "param_grid_xgb = {\n",
    "    \"n_estimators\": [100, 150],\n",
    "    \"max_depth\": [4, 6],\n",
    "    \"learning_rate\": [0.1],\n",
    "    \"subsample\": [0.8],\n",
    "    \"colsample_bytree\": [0.5], \n",
    "    \"gamma\": [0, 1], \n",
    "    \"reg_lambda\": [1], \n",
    "}\n",
    "\n",
    "results = []\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "for params in ParameterGrid(param_grid_xgb):\n",
    "    print(f\"\\nCombination: {params}\")\n",
    "\n",
    "    clf = XGBClassifier(\n",
    "        **params,\n",
    "        objective=\"multi:softmax\",\n",
    "        num_class=len(np.unique(y_tr_enc)),\n",
    "        tree_method=\"hist\",\n",
    "        eval_metric=\"mlogloss\",\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        verbosity=0,\n",
    "    )\n",
    "\n",
    "    # Fit\n",
    "    clf.fit(X_tr, y_tr_enc)\n",
    "\n",
    "    # Validation\n",
    "    y_val_pred = clf.predict(X_va)\n",
    "\n",
    "    macro_f1 = f1_score(y_val_enc, y_val_pred, average=\"macro\")\n",
    "    acc = accuracy_score(y_val_enc, y_val_pred)\n",
    "\n",
    "    print(f\"macro-F1 (val): {macro_f1:.4f} | accuracy (val): {acc:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        **params,\n",
    "        \"val_macro_f1\": macro_f1,\n",
    "        \"val_accuracy\": acc,\n",
    "    })\n",
    "\n",
    "    if macro_f1 > best_score:\n",
    "        best_score = macro_f1\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\nBest hyperparameter configuration (XGBoost):\")\n",
    "print(best_params)\n",
    "print(\"Validation macro-F1:\", best_score)\n",
    "\n",
    "results_df_xgb = pd.DataFrame(results).sort_values(\"val_macro_f1\", ascending=False)\n",
    "print(\"\\nOrdered results:\")\n",
    "print(results_df_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664d5313-4ef8-4d45-b0c2-d85e36567a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PERFORMANCE ON TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cb28103-3d1a-441f-b1b2-ec725bb83304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr = np.load(\"D:/dataset/restricted_clip/X_tr.npy\", allow_pickle = True)\n",
    "X_va = np.load(\"D:/dataset/restricted_clip/X_va.npy\", allow_pickle = True)\n",
    "X_te = np.load(\"D:/dataset/restricted_clip/X_te.npy\", allow_pickle = True)\n",
    "\n",
    "\n",
    "y_tr = np.load(\"D:/dataset/restricted_clip/y_tr_2.npy\", allow_pickle = True)\n",
    "y_va = np.load(\"D:/dataset/restricted_clip/y_va_2.npy\", allow_pickle = True)\n",
    "y_te = np.load(\"D:/dataset/restricted_clip/y_te_2.npy\", allow_pickle = True)\n",
    "\n",
    "X_trva = np.concatenate((X_tr, X_va), axis = 0)\n",
    "y_trva = np.concatenate((y_tr, y_va), axis = 0)\n",
    "\n",
    "del X_tr, X_va, y_tr, y_va\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98076fe8-b83a-4a14-bb3a-193cea46f33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configuration: GaussianNB()\n",
      "macro-F1 (train): 0.6273 | accuracy (train): 0.6274\n",
      "\n",
      "Configuration: RandomForestClassifier(max_depth=12, max_features=0.05, min_samples_leaf=2,\n",
      "                       n_estimators=80, n_jobs=-1, random_state=42)\n",
      "macro-F1 (train): 0.6531 | accuracy (train): 0.6538\n",
      "\n",
      "Configuration: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.5, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric='mlogloss',\n",
      "              feature_types=None, feature_weights=None, gamma=0,\n",
      "              grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=150, n_jobs=-1, num_class=2, ...)\n",
      "macro-F1 (train): 0.6846 | accuracy (train): 0.6848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y_trva_enc = le.fit_transform(y_trva)\n",
    "y_te_enc = le.transform(y_te)\n",
    "\n",
    "cfgs = [\n",
    "    GaussianNB(var_smoothing = 1e-09),\n",
    "    RandomForestClassifier(\n",
    "        max_depth=12, max_features=0.05, min_samples_leaf=2, n_estimators=80, n_jobs=-1, random_state=42\n",
    "    ),\n",
    "    XGBClassifier(colsample_bytree = 0.5, gamma = 0, learning_rate = 0.1, max_depth= 4, n_estimators= 150, reg_lambda= 1, subsample= 0.8,\n",
    "        objective=\"multi:softmax\",\n",
    "        num_class=len(np.unique(y_trva_enc)),\n",
    "        tree_method=\"hist\", eval_metric=\"mlogloss\",\n",
    "        n_jobs=-1, random_state=42, verbosity=0\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "for cfg in cfgs:\n",
    "    print(f\"\\nConfiguration: {cfg}\")\n",
    "\n",
    "    # XGB requires a numerical target\n",
    "    if isinstance(cfg, XGBClassifier):\n",
    "        cfg.fit(X_trva, y_trva_enc)\n",
    "        y_te_pred = cfg.predict(X_te)\n",
    "        macro_f1 = f1_score(y_te_enc, y_te_pred, average=\"macro\")\n",
    "        acc = accuracy_score(y_te_enc, y_te_pred)\n",
    "\n",
    "    else:\n",
    "        cfg.fit(X_trva, y_trva)\n",
    "        y_te_pred = cfg.predict(X_te)\n",
    "        macro_f1 = f1_score(y_te, y_te_pred, average=\"macro\")\n",
    "        acc = accuracy_score(y_te, y_te_pred)\n",
    "\n",
    "    print(f\"macro-F1 (train): {macro_f1:.4f} | accuracy (train): {acc:.4f}\")\n",
    "\n",
    "del X_trva, X_te, y_trva, y_te\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cdc75ee-4f25-4f5d-8c9a-e58a8bcc47a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macro-F1 (test): 0.6778 | accuracy (test): 0.6782\n"
     ]
    }
   ],
   "source": [
    "cfg = SGDClassifier(\n",
    "        loss=\"hinge\",\n",
    "        penalty=\"l2\",\n",
    "        alpha = 0.0001,\n",
    "        average = True,\n",
    "        class_weight = 'balanced',\n",
    "        random_state=42,\n",
    "        max_iter=1000,\n",
    "        tol=1e-3,\n",
    "    )\n",
    "\n",
    "\n",
    "cfg.fit(X_trva, y_trva)\n",
    "y_te_pred = cfg.predict(X_te)\n",
    "macro_f1 = f1_score(y_te, y_te_pred, average=\"macro\")\n",
    "acc = accuracy_score(y_te, y_te_pred)\n",
    "\n",
    "print(f\"macro-F1 (test): {macro_f1:.4f} | accuracy (test): {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85604d82-4ac6-4991-807b-5ad3e7ad3d71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (CLIP Env)",
   "language": "python",
   "name": "clip_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
