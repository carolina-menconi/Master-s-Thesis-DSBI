{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e58ade61-60e0-4fbc-8500-7af2d5cff3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, duckdb, joblib, gc, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import save_npz, load_npz, vstack, csr_matrix, hstack\n",
    "import time\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a73a373-ddec-431b-be1b-fc1bdb370b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up ready\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "\n",
    "DB_PATH   = r\"D:/db/meta.duckdb\"\n",
    "OUT_DIR   = r\"D:/dataset/text_features/tfidf_v2\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "   \n",
    "table = \"md1718\"\n",
    "\n",
    "# Connection\n",
    "con = duckdb.connect(DB_PATH)\n",
    "try:\n",
    "    con.execute(\"PRAGMA threads=8;\")\n",
    "except duckdb.InvalidInputException:\n",
    "    pass\n",
    "\n",
    "print(\"Set up ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f4ad5f7-310f-43d7-879e-48b642bf72f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_DIR = r\"D:/dataset/text_features/tfidf_v3\"\n",
    "\n",
    "tr_ids = np.load(os.path.join(OUT_DIR, \"tfidf_train_post_ids.npy\"), allow_pickle=True)\n",
    "va_ids = np.load(os.path.join(OUT_DIR, \"tfidf_val_post_ids.npy\"), allow_pickle=True)\n",
    "te_ids = np.load(os.path.join(OUT_DIR, \"tfidf_test_post_ids.npy\"), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9abe0be3-a8fd-4430-9853-bc09f59e4a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT post_id, er_bins3\n",
    "FROM md1718\n",
    "WHERE er_bins3 IS NOT NULL\n",
    "\"\"\"\n",
    "\n",
    "df_labels = con.execute(query).df()\n",
    "\n",
    "id2y = dict(zip(df_labels[\"post_id\"], df_labels[\"er_bins3\"]))\n",
    "\n",
    "y_tr = np.array([id2y[pid] for pid in tr_ids], dtype='object')\n",
    "y_va = np.array([id2y[pid] for pid in va_ids], dtype='object')\n",
    "y_te = np.array([id2y[pid] for pid in te_ids], dtype='object')\n",
    "\n",
    "np.save(\"D:/dataset/text_features/tfidf_v3/tfidf_y_train_3.npy\", y_tr)\n",
    "np.save(\"D:/dataset/text_features/tfidf_v3/tfidf_y_val_3.npy\", y_va)\n",
    "np.save(\"D:/dataset/text_features/tfidf_v3/tfidf_y_test_3.npy\", y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2558648-2c2d-44c2-90e9-239dda7d63dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_DIR = r\"D:/dataset/text_features/tfidf_v3\"\n",
    "\n",
    "Xtr_full = load_npz(f\"{OUT_DIR}/tfidf_topwords_train.npz\").astype(np.float32)\n",
    "Xva_full = load_npz(f\"{OUT_DIR}/tfidf_topwords_val.npz\").astype(np.float32)\n",
    "# Xte_full = load_npz(f\"{OUT_DIR}/tfidf_topwords_test.npz\")\n",
    "\n",
    "tr_ids = np.load(os.path.join(OUT_DIR, \"tfidf_train_post_ids.npy\"), allow_pickle=True)\n",
    "va_ids = np.load(os.path.join(OUT_DIR, \"tfidf_val_post_ids.npy\"), allow_pickle=True)\n",
    "# te_ids = np.load(os.path.join(OUT_DIR, \"tfidf_test_post_ids.npy\"), allow_pickle=True)\n",
    "\n",
    "y_tr = np.load(\"D:/dataset/text_features/tfidf_v3/tfidf_y_train_3.npy\", allow_pickle = True)\n",
    "y_va = np.load(\"D:/dataset/text_features/tfidf_v3/tfidf_y_val_3.npy\", allow_pickle = True)\n",
    "# y_te = np.load(\"D:/dataset/text_features/tfidf_v3/tfidf_y_test_3.npy\", allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14dd28cb-4e2d-4dfe-adb3-ee28c2aeb5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination: {'alpha': 1e-05, 'average': False, 'class_weight': None}\n",
      "macro-F1 (val): 0.40679655232785955 | accuracy (val): 0.41656702843630633\n",
      "\n",
      "Combination: {'alpha': 1e-05, 'average': False, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.4038220676065618 | accuracy (val): 0.418938943794337\n",
      "\n",
      "Combination: {'alpha': 1e-05, 'average': True, 'class_weight': None}\n",
      "macro-F1 (val): 0.41163660706615973 | accuracy (val): 0.4206851391499424\n",
      "\n",
      "Combination: {'alpha': 1e-05, 'average': True, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.40633572483151803 | accuracy (val): 0.421483053416601\n",
      "\n",
      "Combination: {'alpha': 0.0001, 'average': False, 'class_weight': None}\n",
      "macro-F1 (val): 0.4106078321603677 | accuracy (val): 0.41618868610925847\n",
      "\n",
      "Combination: {'alpha': 0.0001, 'average': False, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.40523333062239364 | accuracy (val): 0.4190044261201722\n",
      "\n",
      "Combination: {'alpha': 0.0001, 'average': True, 'class_weight': None}\n",
      "macro-F1 (val): 0.4078070386532328 | accuracy (val): 0.4184490389862366\n",
      "\n",
      "Combination: {'alpha': 0.0001, 'average': True, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.3978725149623222 | accuracy (val): 0.42081610380161283\n",
      "\n",
      "Combination: {'alpha': 0.001, 'average': False, 'class_weight': None}\n",
      "macro-F1 (val): 0.4050293291039253 | accuracy (val): 0.4158394470381374\n",
      "\n",
      "Combination: {'alpha': 0.001, 'average': False, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.3949982870144133 | accuracy (val): 0.4177699630146123\n",
      "\n",
      "Combination: {'alpha': 0.001, 'average': True, 'class_weight': None}\n",
      "macro-F1 (val): 0.40751382314174345 | accuracy (val): 0.4171296913842236\n",
      "\n",
      "Combination: {'alpha': 0.001, 'average': True, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.3968564932823109 | accuracy (val): 0.4196083186806524\n",
      "\n",
      "Combination: {'alpha': 0.01, 'average': False, 'class_weight': None}\n",
      "macro-F1 (val): 0.4032767746445208 | accuracy (val): 0.41596798641848054\n",
      "\n",
      "Combination: {'alpha': 0.01, 'average': False, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.394178825890775 | accuracy (val): 0.41613290486873217\n",
      "\n",
      "Combination: {'alpha': 0.01, 'average': True, 'class_weight': None}\n",
      "macro-F1 (val): 0.402367764438281 | accuracy (val): 0.4046007397077548\n",
      "\n",
      "Combination: {'alpha': 0.01, 'average': True, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.40495998910978775 | accuracy (val): 0.41248529679257867\n",
      "\n",
      "Best hyperparameter configuration:\n",
      "{'alpha': 1e-05, 'average': True, 'class_weight': None}\n",
      "Validation macro-F1: 0.41163660706615973\n",
      "\n",
      "Ordered results by macro-F1 (validation):\n",
      "      alpha class_weight  average  val_macro_f1  val_accuracy\n",
      "2   0.00001         None     True      0.411637      0.420685\n",
      "4   0.00010         None    False      0.410608      0.416189\n",
      "6   0.00010         None     True      0.407807      0.418449\n",
      "10  0.00100         None     True      0.407514      0.417130\n",
      "0   0.00001         None    False      0.406797      0.416567\n",
      "3   0.00001     balanced     True      0.406336      0.421483\n",
      "5   0.00010     balanced    False      0.405233      0.419004\n",
      "8   0.00100         None    False      0.405029      0.415839\n",
      "15  0.01000     balanced     True      0.404960      0.412485\n",
      "1   0.00001     balanced    False      0.403822      0.418939\n",
      "12  0.01000         None    False      0.403277      0.415968\n",
      "14  0.01000         None     True      0.402368      0.404601\n",
      "7   0.00010     balanced     True      0.397873      0.420816\n",
      "11  0.00100     balanced     True      0.396856      0.419608\n",
      "9   0.00100     balanced    False      0.394998      0.417770\n",
      "13  0.01000     balanced    False      0.394179      0.416133\n"
     ]
    }
   ],
   "source": [
    "# SGD\n",
    "param_grid = {\n",
    "    \"alpha\": [1e-5, 1e-4, 1e-3, 1e-2],\n",
    "    \"class_weight\": [None, \"balanced\"],\n",
    "}\n",
    "\n",
    "results = []\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    print(f\"\\nCombination: {params}\")\n",
    "\n",
    "    clf = SGDClassifier(\n",
    "        loss=\"hinge\",            \n",
    "        penalty=\"l2\",            \n",
    "        **params,\n",
    "        average = True\n",
    "        random_state=42,\n",
    "        max_iter=1000,\n",
    "        tol=1e-3,\n",
    "    )\n",
    "\n",
    "    clf.fit(Xtr_full, y_tr)\n",
    "\n",
    "    y_val_pred = clf.predict(Xva_full)\n",
    "\n",
    "    macro_f1 = f1_score(y_va, y_val_pred, average=\"macro\")\n",
    "    acc = accuracy_score(y_va, y_val_pred)\n",
    "\n",
    "    print(f\"macro-F1 (val): {macro_f1} | accuracy (val): {acc}\")\n",
    "\n",
    "    results.append({\n",
    "        \"alpha\": params[\"alpha\"],\n",
    "        \"class_weight\": params[\"class_weight\"],\n",
    "        \"val_macro_f1\": macro_f1,\n",
    "        \"val_accuracy\": acc,\n",
    "    })\n",
    "\n",
    "    if macro_f1 > best_score:\n",
    "        best_score = macro_f1\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\nBest hyperparameter configuration:\")\n",
    "print(best_params)\n",
    "print(\"Validation macro-F1:\", best_score)\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(\"val_macro_f1\", ascending=False)\n",
    "print(\"\\nOrdered results by macro-F1 (validation):\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa6f1b69-790a-49d9-9e94-0442d0517965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination: {'var_smoothing': 1e-09}\n",
      "macro-F1 (val): 0.3169 | accuracy (val): 0.3788\n",
      "\n",
      "Combination: {'var_smoothing': 1e-08}\n",
      "macro-F1 (val): 0.3245 | accuracy (val): 0.3802\n",
      "\n",
      "Combination: {'var_smoothing': 1e-07}\n",
      "macro-F1 (val): 0.3342 | accuracy (val): 0.3825\n",
      "\n",
      "Combination: {'var_smoothing': 1e-06}\n",
      "macro-F1 (val): 0.3467 | accuracy (val): 0.3862\n",
      "\n",
      "Best hyperparameter configuration:\n",
      "{'var_smoothing': 1e-06}\n",
      "Validation macro-F1: 0.34671625646927323\n",
      "\n",
      "Ordered results by macro-F1 (validation):\n",
      "   var_smoothing  val_macro_f1  val_accuracy\n",
      "3   1.000000e-06      0.346716      0.386166\n",
      "2   1.000000e-07      0.334155      0.382536\n",
      "1   1.000000e-08      0.324452      0.380217\n",
      "0   1.000000e-09      0.316885      0.378796\n"
     ]
    }
   ],
   "source": [
    "# NAIVE BAYES\n",
    "\n",
    "param_grid = {\n",
    "    \"var_smoothing\": [1e-9, 1e-8, 1e-7, 1e-6]\n",
    "}\n",
    "\n",
    "results = []\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "batch_size = 256\n",
    "classes = np.unique(y_tr)\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    print(f\"\\nCombination: {params}\")\n",
    "\n",
    "    clf = GaussianNB(**params)\n",
    "\n",
    "    # Fit the model using minibatch for memory\n",
    "    for start in range(0, Xtr_full.shape[0], batch_size):\n",
    "        # print(f\"Batch {start} fit\")\n",
    "        end = min(start + batch_size, Xtr_full.shape[0])\n",
    "\n",
    "        Xb = Xtr_full[start:end].toarray()\n",
    "        yb = y_tr[start:end]\n",
    "\n",
    "        if start == 0:\n",
    "            clf.partial_fit(Xb, yb, classes=classes)\n",
    "        else:\n",
    "            clf.partial_fit(Xb, yb)\n",
    "\n",
    "        del Xb, yb\n",
    "        gc.collect()\n",
    "\n",
    "    # Predict using minibatches\n",
    "    y_val_pred = []\n",
    "\n",
    "    for start in range(0, Xva_full.shape[0], batch_size):\n",
    "        # print(f\"Batch {start} predict\")\n",
    "        end = min(start + batch_size, Xva_full.shape[0])\n",
    "\n",
    "        Xb = Xva_full[start:end].toarray()\n",
    "        y_val_pred.append(clf.predict(Xb))\n",
    "\n",
    "        del Xb\n",
    "        gc.collect()\n",
    "\n",
    "    y_val_pred = np.concatenate(y_val_pred)\n",
    "\n",
    "    macro_f1 = f1_score(y_va, y_val_pred, average=\"macro\")\n",
    "    acc = accuracy_score(y_va, y_val_pred)\n",
    "\n",
    "    print(f\"macro-F1 (val): {macro_f1:.4f} | accuracy (val): {acc:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        \"var_smoothing\": params[\"var_smoothing\"],\n",
    "        \"val_macro_f1\": macro_f1,\n",
    "        \"val_accuracy\": acc,\n",
    "    })\n",
    "\n",
    "    if macro_f1 > best_score:\n",
    "        best_score = macro_f1\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\nBest hyperparameter configuration:\")\n",
    "print(best_params)\n",
    "print(\"Validation macro-F1:\", best_score)\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(\n",
    "    \"val_macro_f1\", ascending=False\n",
    ")\n",
    "print(\"\\nOrdered results by macro-F1 (validation):\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1bb0083-5090-4bf3-bd7f-cf0e096a6ee1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.2302 | accuracy (val): 0.3408\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.2316 | accuracy (val): 0.3412\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.2320 | accuracy (val): 0.3413\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.2304 | accuracy (val): 0.3409\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.2319 | accuracy (val): 0.3415\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.2323 | accuracy (val): 0.3413\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.1841 | accuracy (val): 0.3310\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.1813 | accuracy (val): 0.3306\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.1803 | accuracy (val): 0.3303\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.1828 | accuracy (val): 0.3307\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.1808 | accuracy (val): 0.3304\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.1803 | accuracy (val): 0.3304\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.2413 | accuracy (val): 0.3441\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.2426 | accuracy (val): 0.3446\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.2440 | accuracy (val): 0.3448\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.2381 | accuracy (val): 0.3427\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.2398 | accuracy (val): 0.3438\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.2437 | accuracy (val): 0.3447\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.1893 | accuracy (val): 0.3320\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.1861 | accuracy (val): 0.3318\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.1857 | accuracy (val): 0.3320\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.1898 | accuracy (val): 0.3322\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.1856 | accuracy (val): 0.3317\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.1860 | accuracy (val): 0.3320\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.2526 | accuracy (val): 0.3459\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.2515 | accuracy (val): 0.3462\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.2531 | accuracy (val): 0.3469\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.2497 | accuracy (val): 0.3460\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.2532 | accuracy (val): 0.3472\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.2534 | accuracy (val): 0.3472\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.1949 | accuracy (val): 0.3334\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.1915 | accuracy (val): 0.3331\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.1912 | accuracy (val): 0.3334\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.1944 | accuracy (val): 0.3332\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.1910 | accuracy (val): 0.3329\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.1909 | accuracy (val): 0.3332\n",
      "\n",
      "Best hyperparameter configuration (Random Forest):\n",
      "{'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "Validation macro-F1: 0.2533944465653015\n",
      "\n",
      "Ordered results by macro-F1 (validation):\n",
      "    n_estimators  max_depth  min_samples_leaf max_features  val_macro_f1  \\\n",
      "29            80         12                 5         0.05      0.253394   \n",
      "28            50         12                 5         0.05      0.253162   \n",
      "26            80         12                 2         0.05      0.253056   \n",
      "24            30         12                 2         0.05      0.252607   \n",
      "25            50         12                 2         0.05      0.251469   \n",
      "27            30         12                 5         0.05      0.249679   \n",
      "14            80         10                 2         0.05      0.243977   \n",
      "17            80         10                 5         0.05      0.243670   \n",
      "13            50         10                 2         0.05      0.242595   \n",
      "12            30         10                 2         0.05      0.241337   \n",
      "16            50         10                 5         0.05      0.239785   \n",
      "15            30         10                 5         0.05      0.238137   \n",
      "5             80          8                 5         0.05      0.232295   \n",
      "2             80          8                 2         0.05      0.232023   \n",
      "4             50          8                 5         0.05      0.231891   \n",
      "1             50          8                 2         0.05      0.231645   \n",
      "3             30          8                 5         0.05      0.230351   \n",
      "0             30          8                 2         0.05      0.230175   \n",
      "30            30         12                 2         sqrt      0.194913   \n",
      "33            30         12                 5         sqrt      0.194351   \n",
      "31            50         12                 2         sqrt      0.191508   \n",
      "32            80         12                 2         sqrt      0.191237   \n",
      "34            50         12                 5         sqrt      0.191040   \n",
      "35            80         12                 5         sqrt      0.190872   \n",
      "21            30         10                 5         sqrt      0.189836   \n",
      "18            30         10                 2         sqrt      0.189301   \n",
      "19            50         10                 2         sqrt      0.186053   \n",
      "23            80         10                 5         sqrt      0.186032   \n",
      "20            80         10                 2         sqrt      0.185719   \n",
      "22            50         10                 5         sqrt      0.185604   \n",
      "6             30          8                 2         sqrt      0.184082   \n",
      "9             30          8                 5         sqrt      0.182766   \n",
      "7             50          8                 2         sqrt      0.181330   \n",
      "10            50          8                 5         sqrt      0.180841   \n",
      "8             80          8                 2         sqrt      0.180338   \n",
      "11            80          8                 5         sqrt      0.180263   \n",
      "\n",
      "    val_accuracy  \n",
      "29      0.347170  \n",
      "28      0.347238  \n",
      "26      0.346906  \n",
      "24      0.345885  \n",
      "25      0.346229  \n",
      "27      0.346013  \n",
      "14      0.344789  \n",
      "17      0.344650  \n",
      "13      0.344609  \n",
      "12      0.344088  \n",
      "16      0.343811  \n",
      "15      0.342674  \n",
      "5       0.341340  \n",
      "2       0.341289  \n",
      "4       0.341502  \n",
      "1       0.341228  \n",
      "3       0.340889  \n",
      "0       0.340836  \n",
      "30      0.333409  \n",
      "33      0.333223  \n",
      "31      0.333118  \n",
      "32      0.333385  \n",
      "34      0.332852  \n",
      "35      0.333191  \n",
      "21      0.332223  \n",
      "18      0.331961  \n",
      "19      0.331823  \n",
      "23      0.332029  \n",
      "20      0.332032  \n",
      "22      0.331692  \n",
      "6       0.330999  \n",
      "9       0.330712  \n",
      "7       0.330591  \n",
      "10      0.330387  \n",
      "8       0.330324  \n",
      "11      0.330421  \n"
     ]
    }
   ],
   "source": [
    "# RANDOM FOREST \n",
    "param_grid_rf = {\n",
    "    \"n_estimators\": [30, 50, 80],\n",
    "    \"max_depth\": [8, 10, 12],\n",
    "    \"min_samples_leaf\": [2, 5],\n",
    "    \"max_features\": [0.05, \"sqrt\"],\n",
    "}\n",
    "\n",
    "results = []\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "for params in ParameterGrid(param_grid_rf):\n",
    "    print(f\"\\nCombination: {params}\")\n",
    "\n",
    "    clf = RandomForestClassifier(\n",
    "        **params,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    clf.fit(Xtr_full, y_tr)\n",
    "\n",
    "    y_val_pred = clf.predict(Xva_full)\n",
    "\n",
    "    macro_f1 = f1_score(y_va, y_val_pred, average=\"macro\")\n",
    "    acc = accuracy_score(y_va, y_val_pred)\n",
    "\n",
    "    print(f\"macro-F1 (val): {macro_f1:.4f} | accuracy (val): {acc:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        \"n_estimators\": params[\"n_estimators\"],\n",
    "        \"max_depth\": params[\"max_depth\"],\n",
    "        \"min_samples_leaf\": params[\"min_samples_leaf\"],\n",
    "        \"max_features\": params[\"max_features\"],\n",
    "        \"val_macro_f1\": macro_f1,\n",
    "        \"val_accuracy\": acc,\n",
    "    })\n",
    "\n",
    "    if macro_f1 > best_score:\n",
    "        best_score = macro_f1\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\nBest hyperparameter configuration (Random Forest):\")\n",
    "print(best_params)\n",
    "print(\"Validation macro-F1:\", best_score)\n",
    "\n",
    "results_df_rf = pd.DataFrame(results).sort_values(\"val_macro_f1\", ascending=False)\n",
    "print(\"\\nOrdered results by macro-F1 (validation):\")\n",
    "print(results_df_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1d377fc-b92f-4329-bf2e-85133b1db3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.2838 | accuracy (val): 0.3536\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 150, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.2959 | accuracy (val): 0.3582\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.2964 | accuracy (val): 0.3586\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 150, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.3095 | accuracy (val): 0.3636\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.2786 | accuracy (val): 0.3537\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 150, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.2916 | accuracy (val): 0.3581\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.2977 | accuracy (val): 0.3589\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 150, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.3067 | accuracy (val): 0.3634\n",
      "\n",
      "Best hyperparameter configuration (XGBoost):\n",
      "{'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 150, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "Validation macro-F1: 0.3094941047409317\n",
      "\n",
      "Ordered results:\n",
      "   colsample_bytree  gamma  learning_rate  max_depth  n_estimators  \\\n",
      "3               0.5      0            0.1          6           150   \n",
      "7               0.5      1            0.1          6           150   \n",
      "6               0.5      1            0.1          6           100   \n",
      "2               0.5      0            0.1          6           100   \n",
      "1               0.5      0            0.1          4           150   \n",
      "5               0.5      1            0.1          4           150   \n",
      "0               0.5      0            0.1          4           100   \n",
      "4               0.5      1            0.1          4           100   \n",
      "\n",
      "   reg_lambda  subsample  val_macro_f1  val_accuracy  \n",
      "3           1        0.8      0.309494      0.363597  \n",
      "7           1        0.8      0.306715      0.363434  \n",
      "6           1        0.8      0.297731      0.358947  \n",
      "2           1        0.8      0.296381      0.358642  \n",
      "1           1        0.8      0.295932      0.358162  \n",
      "5           1        0.8      0.291638      0.358072  \n",
      "0           1        0.8      0.283755      0.353588  \n",
      "4           1        0.8      0.278555      0.353677  \n"
     ]
    }
   ],
   "source": [
    "# XGBOOST\n",
    "\n",
    "# Convert the labels into numbers\n",
    "le = LabelEncoder()\n",
    "y_tr_enc = le.fit_transform(y_tr)\n",
    "y_val_enc = le.transform(y_va)\n",
    "\n",
    "\n",
    "param_grid_xgb = {\n",
    "    \"n_estimators\": [100, 150],\n",
    "    \"max_depth\": [4, 6],\n",
    "    \"learning_rate\": [0.1],\n",
    "    \"subsample\": [0.8],\n",
    "    \"colsample_bytree\": [0.5],\n",
    "    \"gamma\": [0, 1],\n",
    "    \"reg_lambda\": [1],\n",
    "}\n",
    "\n",
    "results = []\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "for params in ParameterGrid(param_grid_xgb):\n",
    "    print(f\"\\nCombination: {params}\")\n",
    "\n",
    "    clf = XGBClassifier(\n",
    "        **params,\n",
    "        objective=\"multi:softmax\",\n",
    "        num_class=len(np.unique(y_tr_enc)),\n",
    "        tree_method=\"hist\",\n",
    "        eval_metric=\"mlogloss\",\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        verbosity=0,\n",
    "    )\n",
    "\n",
    "    # Fit\n",
    "    clf.fit(Xtr_full, y_tr_enc)\n",
    "\n",
    "    # Validation\n",
    "    y_val_pred = clf.predict(Xva_full)\n",
    "\n",
    "    macro_f1 = f1_score(y_val_enc, y_val_pred, average=\"macro\")\n",
    "    acc = accuracy_score(y_val_enc, y_val_pred)\n",
    "\n",
    "    print(f\"macro-F1 (val): {macro_f1:.4f} | accuracy (val): {acc:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        **params,\n",
    "        \"val_macro_f1\": macro_f1,\n",
    "        \"val_accuracy\": acc,\n",
    "    })\n",
    "\n",
    "    if macro_f1 > best_score:\n",
    "        best_score = macro_f1\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\nBest hyperparameter configuration (XGBoost):\")\n",
    "print(best_params)\n",
    "print(\"Validation macro-F1:\", best_score)\n",
    "\n",
    "results_df_xgb = pd.DataFrame(results).sort_values(\"val_macro_f1\", ascending=False)\n",
    "print(\"\\nOrdered results:\")\n",
    "print(results_df_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884b9fe8-14cd-4214-8702-6c180b4da5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PERFORMANCE ON TEST SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c5e00cb-8043-4b86-a375-540dacb1cfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_DIR = r\"D:/dataset/text_features/tfidf_v3\"\n",
    "\n",
    "Xtr_full = load_npz(f\"{OUT_DIR}/tfidf_topwords_train.npz\").astype(np.float32)\n",
    "Xva_full = load_npz(f\"{OUT_DIR}/tfidf_topwords_val.npz\").astype(np.float32)\n",
    "Xte_full = load_npz(f\"{OUT_DIR}/tfidf_topwords_test.npz\").astype(np.float32)\n",
    "\n",
    "tr_ids = np.load(os.path.join(OUT_DIR, \"tfidf_train_post_ids.npy\"), allow_pickle=True)\n",
    "va_ids = np.load(os.path.join(OUT_DIR, \"tfidf_val_post_ids.npy\"), allow_pickle=True)\n",
    "te_ids = np.load(os.path.join(OUT_DIR, \"tfidf_test_post_ids.npy\"), allow_pickle=True)\n",
    "\n",
    "y_tr = np.load(\"D:/dataset/text_features/tfidf_v3/tfidf_y_train_3.npy\", allow_pickle = True)\n",
    "y_va = np.load(\"D:/dataset/text_features/tfidf_v3/tfidf_y_val_3.npy\", allow_pickle = True)\n",
    "y_te = np.load(\"D:/dataset/text_features/tfidf_v3/tfidf_y_test_3.npy\", allow_pickle = True)\n",
    "\n",
    "X_full = vstack([Xtr_full, Xva_full])\n",
    "y_full = np.concatenate([y_tr, y_va])\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_full_enc = le.fit_transform(y_full)\n",
    "y_te_enc = le.transform(y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55ba7a02-184c-449f-9cec-a0d40823e7f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "476"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del Xtr_full, Xva_full, tr_ids, va_ids, y_tr, y_va\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "552f2044-f6ec-4bde-b85f-5df5f7818350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macro-F1 (test): 0.4348 | accuracy (test): 0.4510\n"
     ]
    }
   ],
   "source": [
    "cfg = SGDClassifier(\n",
    "        loss=\"hinge\",\n",
    "        penalty=\"l2\",\n",
    "        alpha = 1e-05,\n",
    "        average = True,\n",
    "        class_weight = None,\n",
    "        random_state=42,\n",
    "        max_iter=1000,\n",
    "        tol=1e-3,\n",
    "    )\n",
    "\n",
    "\n",
    "cfg.fit(X_full, y_full)\n",
    "y_te_pred = cfg.predict(Xte_full)\n",
    "macro_f1 = f1_score(y_te, y_te_pred, average=\"macro\")\n",
    "acc = accuracy_score(y_te, y_te_pred)\n",
    "\n",
    "print(f\"macro-F1 (test): {macro_f1:.4f} | accuracy (test): {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70430b87-5468-4b19-b6df-ce1f58238818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configuration: LinearSVC(C=0.01, max_iter=2000, random_state=42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mimox\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macro-F1 (test): 0.4406 | accuracy (test): 0.4468\n",
      "\n",
      "Configuration: RandomForestClassifier(max_depth=12, max_features=0.05, min_samples_leaf=5,\n",
      "                       n_estimators=80, n_jobs=-1, random_state=42)\n",
      "macro-F1 (test): 0.2906 | accuracy (test): 0.3547\n",
      "\n",
      "Configuration: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.5, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric='mlogloss',\n",
      "              feature_types=None, feature_weights=None, gamma=0,\n",
      "              grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=150, n_jobs=-1, num_class=3, ...)\n",
      "macro-F1 (test): 0.3493 | accuracy (test): 0.3801\n"
     ]
    }
   ],
   "source": [
    "cfgs = [\n",
    "    RandomForestClassifier(\n",
    "        max_depth=12, max_features=0.05, min_samples_leaf=5, n_estimators=80, n_jobs=-1, random_state=42\n",
    "    ),\n",
    "    XGBClassifier(colsample_bytree = 0.5, gamma = 0, learning_rate = 0.1, max_depth= 6, n_estimators= 150, reg_lambda= 1, subsample= 0.8,\n",
    "        objective=\"multi:softmax\",\n",
    "        num_class=len(np.unique(y_full_enc)),\n",
    "        tree_method=\"hist\", eval_metric=\"mlogloss\",\n",
    "        n_jobs=-1, random_state=42, verbosity=0\n",
    "    ),\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "for cfg in cfgs:\n",
    "    print(f\"\\nConfiguration: {cfg}\")\n",
    "\n",
    "    # XGB requires a numerical target\n",
    "    if isinstance(cfg, XGBClassifier):\n",
    "        cfg.fit(X_full, y_full_enc)\n",
    "        y_te_pred = cfg.predict(Xte_full)\n",
    "        macro_f1 = f1_score(y_te_enc, y_te_pred, average=\"macro\")\n",
    "        acc = accuracy_score(y_te_enc, y_te_pred)\n",
    "\n",
    "    else:\n",
    "        cfg.fit(X_full, y_full)\n",
    "        y_te_pred = cfg.predict(Xte_full)\n",
    "        macro_f1 = f1_score(y_te, y_te_pred, average=\"macro\")\n",
    "        acc = accuracy_score(y_te, y_te_pred)\n",
    "\n",
    "    print(f\"macro-F1 (test): {macro_f1:.4f} | accuracy (test): {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c29106cb-68ce-4da1-8ad3-3f54a6b74453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macro-F1 (test): 0.3596 | accuracy (test): 0.4104\n"
     ]
    }
   ],
   "source": [
    "# TEST SU GAUSSIAN NAIVE BAYES\n",
    "\n",
    "batch_size = 256\n",
    "classes = np.unique(y_full)\n",
    "\n",
    "clf = GaussianNB(var_smoothing = 1e-06)\n",
    "\n",
    "\n",
    "# Fit the model using minibatch for memory\n",
    "for start in range(0, X_full.shape[0], batch_size):\n",
    "    # print(f\"Batch {start} fit\")\n",
    "    end = min(start + batch_size, X_full.shape[0])\n",
    "\n",
    "    Xb = X_full[start:end].toarray()\n",
    "    yb = y_full[start:end]\n",
    "\n",
    "    if start == 0:\n",
    "        clf.partial_fit(Xb, yb, classes=classes)\n",
    "    else:\n",
    "        clf.partial_fit(Xb, yb)\n",
    "\n",
    "    del Xb, yb\n",
    "    gc.collect()\n",
    "\n",
    "# Predict using minibatches\n",
    "y_te_pred = []\n",
    "\n",
    "for start in range(0, Xte_full.shape[0], batch_size):\n",
    "    # print(f\"Batch {start} predict\")\n",
    "    end = min(start + batch_size, Xte_full.shape[0])\n",
    "\n",
    "    Xb = Xte_full[start:end].toarray()\n",
    "    y_te_pred.append(clf.predict(Xb))\n",
    "\n",
    "    del Xb\n",
    "    gc.collect()\n",
    "\n",
    "y_te_pred = np.concatenate(y_te_pred)\n",
    "\n",
    "macro_f1 = f1_score(y_te, y_te_pred, average=\"macro\")\n",
    "acc = accuracy_score(y_te, y_te_pred)\n",
    "\n",
    "print(f\"macro-F1 (test): {macro_f1:.4f} | accuracy (test): {acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (CLIP Env)",
   "language": "python",
   "name": "clip_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
