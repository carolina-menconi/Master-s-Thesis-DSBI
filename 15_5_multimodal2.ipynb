{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5768fecc-29eb-45f7-8424-bc406a5fb00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "from sklearn.model_selection import train_test_split\n",
    "import duckdb, torch, time, os, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from scipy.sparse import load_npz, hstack, save_npz\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "377a2cef-b9c7-443d-8537-057a338ca8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up ready\n"
     ]
    }
   ],
   "source": [
    "DB_PATH = \"D:/db/meta.duckdb\"\n",
    "con = duckdb.connect(DB_PATH)\n",
    "try:\n",
    "    con.execute(\"PRAGMA threads=8;\")\n",
    "except duckdb.InvalidInputException:\n",
    "    pass\n",
    "\n",
    "print(\"Set up ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e2ecc9-3aea-4853-bb7e-d624fb847245",
   "metadata": {},
   "source": [
    "# METADATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b8cafe-ef4c-4d80-b374-1a31302c7f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_tr = con.sql(\"\"\"SELECT * FROM md1718 WHERE split = 'train'\"\"\").df()\n",
    "metadata_val = con.sql(\"\"\"SELECT * FROM md1718 WHERE split = 'validation'\"\"\").df()\n",
    "metadata_te = con.sql(\"\"\"SELECT * FROM md1718 WHERE split = 'test'\"\"\").df()\n",
    "\n",
    "col_to_exclude = ['filename', 'username', 'like_count', 'comment_count', 'caption', 'followers', 'engagement_rate', 'er_log', 'caption_language', 'caption_tfidf', 'caption_bert_clip',\n",
    "                  'er_bins', 'split', 'in_train_balanced', 'time_utc', 'date_day', 'caption_lang', 'caption_clean']\n",
    "\n",
    "feature_columns = [col for col in metadata_tr.columns if col not in col_to_exclude]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c83b18-4147-49d0-b1d3-e164ed86836a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "y_tr = metadata_tr[['post_id', 'er_bins']]\n",
    "y_val = metadata_val[['post_id', 'er_bins']]\n",
    "y_te = metadata_te[['post_id', 'er_bins']]\n",
    "\n",
    "meta_tr = metadata_tr[feature_columns]\n",
    "meta_val = metadata_val[feature_columns] \n",
    "meta_te = metadata_te[feature_columns] \n",
    "\n",
    "# One hot encoding for orientation and category\n",
    "cat_cols = ['orientation', 'category']\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "meta_train_encoded = encoder.fit_transform(meta_tr[cat_cols])\n",
    "meta_val_encoded = encoder.transform(meta_val[cat_cols])\n",
    "meta_test_encoded = encoder.transform(meta_te[cat_cols])\n",
    "\n",
    "encoded_cols = encoder.get_feature_names_out(cat_cols)\n",
    "meta_train_encoded = pd.DataFrame(meta_train_encoded, columns=encoded_cols, index=meta_tr.index)\n",
    "meta_val_encoded = pd.DataFrame(meta_val_encoded, columns=encoded_cols, index=meta_val.index)\n",
    "meta_test_encoded = pd.DataFrame(meta_test_encoded, columns=encoded_cols, index=meta_te.index)\n",
    "\n",
    "meta_tr['caption_len_char'] = meta_tr['caption_len_char'].fillna(0)\n",
    "meta_val['caption_len_char'] = meta_val['caption_len_char'].fillna(0)\n",
    "meta_te['caption_len_char'] = meta_te['caption_len_char'].fillna(0)\n",
    "\n",
    "# Scaling numerical variables\n",
    "scaler = StandardScaler()\n",
    "num_cols = [\n",
    "    'width', 'height', 'aspect_ratio', 'area',\n",
    "    'dow', 'hour_utc', 'month', 'year', 'caption_len_char',\n",
    "    'n_hashtags', 'n_mentions', 'n_urls', 'n_emojis',\n",
    "    'followees', 'posts'\n",
    "]\n",
    "\n",
    "bin_cols = ['has_caption'] \n",
    "\n",
    "meta_train_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(meta_tr[num_cols]),\n",
    "    columns=num_cols,\n",
    "    index=meta_tr.index\n",
    ")\n",
    "meta_val_scaled = pd.DataFrame(\n",
    "    scaler.transform(meta_val[num_cols]),\n",
    "    columns=num_cols,\n",
    "    index=meta_val.index\n",
    ")\n",
    "meta_test_scaled = pd.DataFrame(\n",
    "    scaler.transform(meta_te[num_cols]),\n",
    "    columns=num_cols,\n",
    "    index=meta_te.index\n",
    ")\n",
    "\n",
    "meta_train_bin = meta_tr[bin_cols].astype(int)\n",
    "meta_val_bin = meta_val[bin_cols].astype(int)\n",
    "meta_test_bin = meta_te[bin_cols].astype(int)\n",
    "\n",
    "# Merge all: scaled numeric + boolean + one-hot\n",
    "meta_train_final = pd.concat([meta_train_scaled, meta_train_bin, meta_train_encoded], axis=1)\n",
    "meta_val_final = pd.concat([meta_val_scaled, meta_val_bin, meta_val_encoded], axis=1)\n",
    "meta_test_final = pd.concat([meta_test_scaled, meta_test_bin, meta_test_encoded], axis=1)\n",
    "# Add post_id\n",
    "meta_train_final.insert(0, 'post_id', metadata_tr['post_id'].values)\n",
    "meta_val_final.insert(0, 'post_id', metadata_val['post_id'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eff22d71-5d7c-4057-8fc3-40ff32bc02fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_test_final.insert(0, 'post_id', metadata_te['post_id'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f41f9446-b82d-43b2-ad92-475fbc79e0a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>aspect_ratio</th>\n",
       "      <th>area</th>\n",
       "      <th>dow</th>\n",
       "      <th>hour_utc</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>caption_len_char</th>\n",
       "      <th>...</th>\n",
       "      <th>orientation_square</th>\n",
       "      <th>category_beauty</th>\n",
       "      <th>category_family</th>\n",
       "      <th>category_fashion</th>\n",
       "      <th>category_fitness</th>\n",
       "      <th>category_food</th>\n",
       "      <th>category_interior</th>\n",
       "      <th>category_other</th>\n",
       "      <th>category_pet</th>\n",
       "      <th>category_travel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>la.brandon-1936393348858127807</td>\n",
       "      <td>0.281866</td>\n",
       "      <td>1.081142</td>\n",
       "      <td>-0.912237</td>\n",
       "      <td>0.986369</td>\n",
       "      <td>-1.006889</td>\n",
       "      <td>0.241193</td>\n",
       "      <td>1.780745</td>\n",
       "      <td>0.665162</td>\n",
       "      <td>-0.303090</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>la.brandon-1937213763687991478</td>\n",
       "      <td>0.281866</td>\n",
       "      <td>1.090130</td>\n",
       "      <td>-0.912237</td>\n",
       "      <td>0.993974</td>\n",
       "      <td>-0.494989</td>\n",
       "      <td>0.649684</td>\n",
       "      <td>1.780745</td>\n",
       "      <td>0.665162</td>\n",
       "      <td>-0.039784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>la.brandon-1937218941271111413</td>\n",
       "      <td>0.281866</td>\n",
       "      <td>-0.123249</td>\n",
       "      <td>0.095960</td>\n",
       "      <td>-0.032801</td>\n",
       "      <td>-0.494989</td>\n",
       "      <td>0.649684</td>\n",
       "      <td>1.780745</td>\n",
       "      <td>0.665162</td>\n",
       "      <td>-0.665522</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>la.brandon-1938181925006920700</td>\n",
       "      <td>0.281866</td>\n",
       "      <td>-0.123249</td>\n",
       "      <td>0.095960</td>\n",
       "      <td>-0.032801</td>\n",
       "      <td>0.528810</td>\n",
       "      <td>-1.528935</td>\n",
       "      <td>1.780745</td>\n",
       "      <td>0.665162</td>\n",
       "      <td>0.362919</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>la.brandon-1938620907515771752</td>\n",
       "      <td>0.281866</td>\n",
       "      <td>1.090130</td>\n",
       "      <td>-0.912237</td>\n",
       "      <td>0.993974</td>\n",
       "      <td>0.528810</td>\n",
       "      <td>0.513520</td>\n",
       "      <td>1.780745</td>\n",
       "      <td>0.665162</td>\n",
       "      <td>0.706765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          post_id     width    height  aspect_ratio      area  \\\n",
       "0  la.brandon-1936393348858127807  0.281866  1.081142     -0.912237  0.986369   \n",
       "1  la.brandon-1937213763687991478  0.281866  1.090130     -0.912237  0.993974   \n",
       "2  la.brandon-1937218941271111413  0.281866 -0.123249      0.095960 -0.032801   \n",
       "3  la.brandon-1938181925006920700  0.281866 -0.123249      0.095960 -0.032801   \n",
       "4  la.brandon-1938620907515771752  0.281866  1.090130     -0.912237  0.993974   \n",
       "\n",
       "        dow  hour_utc     month      year  caption_len_char  ...  \\\n",
       "0 -1.006889  0.241193  1.780745  0.665162         -0.303090  ...   \n",
       "1 -0.494989  0.649684  1.780745  0.665162         -0.039784  ...   \n",
       "2 -0.494989  0.649684  1.780745  0.665162         -0.665522  ...   \n",
       "3  0.528810 -1.528935  1.780745  0.665162          0.362919  ...   \n",
       "4  0.528810  0.513520  1.780745  0.665162          0.706765  ...   \n",
       "\n",
       "   orientation_square  category_beauty  category_family  category_fashion  \\\n",
       "0                 0.0              0.0              0.0               1.0   \n",
       "1                 0.0              0.0              0.0               1.0   \n",
       "2                 1.0              0.0              0.0               1.0   \n",
       "3                 1.0              0.0              0.0               1.0   \n",
       "4                 0.0              0.0              0.0               1.0   \n",
       "\n",
       "   category_fitness  category_food  category_interior  category_other  \\\n",
       "0               0.0            0.0                0.0             0.0   \n",
       "1               0.0            0.0                0.0             0.0   \n",
       "2               0.0            0.0                0.0             0.0   \n",
       "3               0.0            0.0                0.0             0.0   \n",
       "4               0.0            0.0                0.0             0.0   \n",
       "\n",
       "   category_pet  category_travel  \n",
       "0           0.0              0.0  \n",
       "1           0.0              0.0  \n",
       "2           0.0              0.0  \n",
       "3           0.0              0.0  \n",
       "4           0.0              0.0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_test_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1897ad9-5d53-4ab9-9f03-8229282f830e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(773497, 29) (412325, 29) (423604, 29)\n"
     ]
    }
   ],
   "source": [
    "print(meta_train_final.shape, meta_val_final.shape, meta_test_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17353821-6095-4340-ad26-f8aa11ffc466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2094"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Free memory\n",
    "del metadata_tr, metadata_val\n",
    "del meta_tr, meta_val\n",
    "del meta_train_scaled, meta_val_scaled\n",
    "del meta_train_encoded, meta_val_encoded\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2d80d28-2386-44ef-b795-281f0b23e161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 773497 entries, 0 to 773496\n",
      "Data columns (total 29 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   post_id                773497 non-null  object \n",
      " 1   width                  773497 non-null  float64\n",
      " 2   height                 773497 non-null  float64\n",
      " 3   aspect_ratio           773497 non-null  float64\n",
      " 4   area                   773497 non-null  float64\n",
      " 5   dow                    773497 non-null  float64\n",
      " 6   hour_utc               773497 non-null  float64\n",
      " 7   month                  773497 non-null  float64\n",
      " 8   year                   773497 non-null  float64\n",
      " 9   caption_len_char       773497 non-null  float64\n",
      " 10  n_hashtags             773497 non-null  float64\n",
      " 11  n_mentions             773497 non-null  float64\n",
      " 12  n_urls                 773497 non-null  float64\n",
      " 13  n_emojis               773497 non-null  float64\n",
      " 14  followees              773497 non-null  float64\n",
      " 15  posts                  773497 non-null  float64\n",
      " 16  has_caption            773497 non-null  int32  \n",
      " 17  orientation_landscape  773497 non-null  float64\n",
      " 18  orientation_portrait   773497 non-null  float64\n",
      " 19  orientation_square     773497 non-null  float64\n",
      " 20  category_beauty        773497 non-null  float64\n",
      " 21  category_family        773497 non-null  float64\n",
      " 22  category_fashion       773497 non-null  float64\n",
      " 23  category_fitness       773497 non-null  float64\n",
      " 24  category_food          773497 non-null  float64\n",
      " 25  category_interior      773497 non-null  float64\n",
      " 26  category_other         773497 non-null  float64\n",
      " 27  category_pet           773497 non-null  float64\n",
      " 28  category_travel        773497 non-null  float64\n",
      "dtypes: float64(27), int32(1), object(1)\n",
      "memory usage: 168.2+ MB\n"
     ]
    }
   ],
   "source": [
    "meta_train_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52499789-919c-4cfc-820c-bce400a95d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_train_final.to_csv(\"D:/dataset/meta_classification/meta_train_final.csv\", index=False)\n",
    "meta_val_final.to_csv(\"D:/dataset/meta_classification/meta_val_final.csv\", index=False)\n",
    "meta_test_final.to_csv(\"D:/dataset/meta_classification/meta_test_final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26e0b825-93f3-4b47-8af9-86cd59f8ceca",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr.to_csv(\"D:/dataset/meta_classification/y_tr.csv\", index=False)\n",
    "y_val.to_csv(\"D:/dataset/meta_classification/y_va.csv\", index=False)\n",
    "y_te.to_csv(\"D:/dataset/meta_classification/y_te.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a5e9de3-8444-417e-93ca-0e8beaab351a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up ready\n"
     ]
    }
   ],
   "source": [
    "DB_PATH = \"D:/db/meta.duckdb\"\n",
    "con = duckdb.connect(DB_PATH)\n",
    "try:\n",
    "    con.execute(\"PRAGMA threads=8;\")\n",
    "except duckdb.InvalidInputException:\n",
    "    pass\n",
    "\n",
    "print(\"Set up ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f23dac4-3654-4462-8759-bd580d6a4fd0",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d80d70fb-2439-4d90-8485-dfd588b0c092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# METADATA\n",
    "meta_train_final = pd.read_csv(\"D:/dataset/meta_classification/meta_train_final.csv\")\n",
    "\n",
    "# SBERT\n",
    "train = np.load(\"D:/dataset/sbert_emb/paraphrase-MiniLM-L6-v2_train_ids_y.npz\", allow_pickle=True)\n",
    "SB_tr = train[\"embeddings\"]\n",
    "SB_ids_tr = train[\"ids\"]\n",
    "\n",
    "# EFFICIENT NET\n",
    "EN_tr_data = np.load(\"D:/dataset/efficientnetb0_emb/train_data.npz\", allow_pickle=True)\n",
    "EN_tr = EN_tr_data[\"X\"]\n",
    "EN_tr_ids = EN_tr_data[\"ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d3bd123-1f1c-4221-a12d-8c13471f8937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALIGN THE THREE SETS\n",
    "meta_tr = meta_train_final.sort_values(\"post_id\").reset_index(drop=True)\n",
    "tr_ids_ord = meta_tr[\"post_id\"].values\n",
    "\n",
    "SB_ids_tr = SB_ids_tr.astype(str)\n",
    "EN_tr_ids = EN_tr_ids.astype(str)\n",
    "tr_ids_ord = tr_ids_ord.astype(str)\n",
    "\n",
    "metadata_tr = con.sql(\"\"\"\n",
    "    SELECT post_id, er_bins FROM md1718\n",
    "    WHERE split = 'train'\n",
    "\"\"\").df().set_index('post_id')\n",
    "\n",
    "y_tr = metadata_tr.loc[tr_ids_ord, 'er_bins'].values\n",
    "assert len(y_tr) == len(tr_ids_ord)\n",
    "\n",
    "# SBERT -> DataFrame indicizzato\n",
    "df_sbert = pd.DataFrame(SB_tr, index=SB_ids_tr)\n",
    "df_sbert.index.name = \"post_id\"\n",
    "\n",
    "# EfficientNet -> DataFrame indicizzato\n",
    "df_eff = pd.DataFrame(EN_tr, index=EN_tr_ids)\n",
    "df_eff.index.name = \"post_id\"\n",
    "\n",
    "df_sbert.index = df_sbert.index.astype(str)\n",
    "df_eff.index   = df_eff.index.astype(str)\n",
    "metadata_tr.index = metadata_tr.index.astype(str)\n",
    "\n",
    "# Allineamento perfetto tramite reindex\n",
    "SBERT_tr_aligned = df_sbert.reindex(tr_ids_ord).values\n",
    "EN_tr_aligned = df_eff.reindex(tr_ids_ord).values\n",
    "\n",
    "# Metadata numerici\n",
    "meta_tr_np = meta_tr.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47ba75ba-5256-450a-9f5f-5261667bfeeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID jaxedup_-1661166768121876485 -> SBERT label: very_high, aligned label: very_high\n",
      "ID kathypatalsky-1828618111151180132 -> SBERT label: low, aligned label: low\n",
      "ID jennydinhofficial-1726460627143991097 -> SBERT label: low, aligned label: low\n",
      "ID empressdshenna-1752915371617655852 -> SBERT label: very_high, aligned label: very_high\n",
      "ID thebeauparlour-1778381395752840551 -> SBERT label: high, aligned label: high\n",
      "ID tiny_house_ideas-1879917602862398442 -> SBERT label: medium, aligned label: medium\n",
      "ID pencilandpaperco-1887071511689775340 -> SBERT label: very_low, aligned label: very_low\n",
      "ID savy.jean-1582021008067721506 -> SBERT label: high, aligned label: high\n",
      "ID joshmair96-1592269944325578069 -> SBERT label: very_low, aligned label: very_low\n",
      "ID pia.falbo-1757290049832401947 -> SBERT label: high, aligned label: high\n"
     ]
    }
   ],
   "source": [
    "for idx in np.random.choice(len(tr_ids_ord), 10, replace=False):\n",
    "    pid = tr_ids_ord[idx]  # the ID used for alignment\n",
    "    \n",
    "    # Extract SBERT original label for that post_id\n",
    "    original_label_sbert = train[\"y\"][np.where(SB_ids_tr == pid)[0][0]]\n",
    "    \n",
    "    # Our final label\n",
    "    aligned_label = y_tr[idx]\n",
    "\n",
    "    print(f\"ID {pid} -> SBERT label: {original_label_sbert}, aligned label: {aligned_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e27e795-2ec3-4536-a5fa-988f59ab7bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID the_hungrybeast-1599673526892457200 -> EN label: medium, aligned label: medium\n",
      "ID alexajeanfitness-1561113583289511037 -> EN label: low, aligned label: low\n",
      "ID realtgallagher-1780030529388508217 -> EN label: very_high, aligned label: very_high\n",
      "ID xoxokrispin-1792488909834724604 -> EN label: medium, aligned label: medium\n",
      "ID dearestmercy-1583443501966678421 -> EN label: low, aligned label: low\n",
      "ID canary_jane-1769294641598957093 -> EN label: medium, aligned label: medium\n",
      "ID aaron_wylie10-1746730557322241542 -> EN label: very_high, aligned label: very_high\n",
      "ID camillelolafit-1691265434270409474 -> EN label: high, aligned label: high\n",
      "ID mazroudecouvre-1514612765611665859 -> EN label: very_low, aligned label: very_low\n",
      "ID colourmehappydecorating-1839884047491065851 -> EN label: very_low, aligned label: very_low\n"
     ]
    }
   ],
   "source": [
    "for idx in np.random.choice(len(tr_ids_ord), 10, replace=False):\n",
    "    pid = tr_ids_ord[idx]\n",
    "    \n",
    "    # EN original label for that post_id\n",
    "    original_label_en = EN_tr_data[\"y\"][np.where(EN_tr_ids == pid)[0][0]]\n",
    "    \n",
    "    aligned_label = y_tr[idx]\n",
    "\n",
    "    print(f\"ID {pid} -> EN label: {original_label_en}, aligned label: {aligned_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6490e3c6-bd4c-4648-9fac-ab7472d61086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SBERT alignment OK: True\n",
      "EN alignment OK: True\n",
      "Label alignment OK: True\n"
     ]
    }
   ],
   "source": [
    "def check_alignment(idx):\n",
    "    pid = tr_ids_ord[idx]\n",
    "    sbert_ok = np.allclose(SBERT_tr_aligned[idx], df_sbert.loc[pid].values)\n",
    "    en_ok = np.allclose(EN_tr_aligned[idx], df_eff.loc[pid].values)\n",
    "    label_ok = (y_tr[idx] == metadata_tr.loc[pid, 'er_bins'])\n",
    "    return sbert_ok, en_ok, label_ok\n",
    "\n",
    "results = np.array([check_alignment(i) for i in range(200)])  # check first 200 rows\n",
    "\n",
    "print(\"SBERT alignment OK:\", results[:,0].all())\n",
    "print(\"EN alignment OK:\", results[:,1].all())\n",
    "print(\"Label alignment OK:\", results[:,2].all())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a503ee88-219a-44e4-bc16-eea6d35af05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['100pintas-1769662389073991144' '100pintas-1782702664733979876'\n",
      " '100pintas-1797067212467389817' '100pintas-1807955339238986900'\n",
      " '100pintas-1808039696742034708']\n",
      "Index(['100pintas-1769662389073991144', '100pintas-1782702664733979876',\n",
      "       '100pintas-1797067212467389817', '100pintas-1807955339238986900',\n",
      "       '100pintas-1808039696742034708'],\n",
      "      dtype='object', name='post_id')\n",
      "Index(['100pintas-1769662389073991144', '100pintas-1782702664733979876',\n",
      "       '100pintas-1797067212467389817', '100pintas-1807955339238986900',\n",
      "       '100pintas-1808039696742034708'],\n",
      "      dtype='object', name='post_id')\n",
      "773497 773497 773497 773497 773497\n"
     ]
    }
   ],
   "source": [
    "# Checks\n",
    "assert SBERT_tr_aligned.shape[0] == len(meta_tr)\n",
    "assert EN_tr_aligned.shape[0] == len(meta_tr)\n",
    "\n",
    "print(tr_ids_ord[:5])\n",
    "print(df_sbert.reindex(tr_ids_ord).index[:5])\n",
    "print(df_eff.reindex(tr_ids_ord).index[:5])\n",
    "print(len(tr_ids_ord), SBERT_tr_aligned.shape[0], EN_tr_aligned.shape[0], meta_tr_np.shape[0], len(y_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00b15a35-38d7-4ee9-8201-6b50c48aec4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SBERT missing: 0\n",
      "EN missing: 0\n"
     ]
    }
   ],
   "source": [
    "assert (meta_tr[\"post_id\"].values == tr_ids_ord).all()\n",
    "\n",
    "# Per SBERT\n",
    "assert (df_sbert.loc[tr_ids_ord].index.values == tr_ids_ord).all()\n",
    "\n",
    "# Per EfficientNet\n",
    "assert (df_eff.loc[tr_ids_ord].index.values == tr_ids_ord).all()\n",
    "\n",
    "print(\"SBERT missing:\", df_sbert.reindex(tr_ids_ord).isna().any(axis=1).sum())\n",
    "print(\"EN missing:\", df_eff.reindex(tr_ids_ord).isna().any(axis=1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af8ab22a-fa29-4506-b4c7-ff2f7592bbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_id_tr = meta_train_final['post_id'].values\n",
    "meta_tr_num = meta_train_final.drop(columns=['post_id']).values\n",
    "\n",
    "meta_tr_num = meta_tr_num.astype('float32')\n",
    "SBERT_tr_aligned = SBERT_tr_aligned.astype('float32')\n",
    "EN_tr_aligned = EN_tr_aligned.astype('float32')\n",
    "\n",
    "X_tr = np.concatenate((meta_tr_num, SBERT_tr_aligned, EN_tr_aligned), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9f3e1be-8301-41c9-91f3-5633de47b488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(773497, 1692) (773497, 28) (773497, 384) (773497, 1280)\n"
     ]
    }
   ],
   "source": [
    "print(X_tr.shape, meta_tr_num.shape, SBERT_tr_aligned.shape, EN_tr_aligned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c1f9bf1-920c-4466-a708-6a02b8145d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"D:/dataset/multimodal2/X_train.npy\", X_tr)\n",
    "np.save(\"D:/dataset/multimodal2/y_tr_5.npy\", y_tr)\n",
    "np.save(\"D:/dataset/multimodal2/post_id_tr.npy\", post_id_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7f5eae-f043-4afa-a7b7-dbf265d19d56",
   "metadata": {},
   "source": [
    "# VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fc56900-d4f4-4f30-8e3b-65ab5145de44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# METADATA\n",
    "meta_val_final = pd.read_csv(\"D:/dataset/meta_classification/meta_val_final.csv\")\n",
    "\n",
    "# SBERT\n",
    "val = np.load(\"D:/dataset/sbert_emb/paraphrase-MiniLM-L6-v2_val_ids_y.npz\", allow_pickle=True)\n",
    "SB_va = val[\"embeddings\"]\n",
    "SB_ids_va = val[\"ids\"]\n",
    "\n",
    "# EFFICIENT NET\n",
    "EN_va_data = np.load(\"D:/dataset/efficientnetb0_emb/val_data.npz\", allow_pickle=True)\n",
    "EN_va = EN_va_data[\"X\"]\n",
    "EN_va_ids = EN_va_data[\"ids\"]\n",
    "\n",
    "# ALIGN THE THREE SETS\n",
    "meta_va = meta_val_final.sort_values(\"post_id\").reset_index(drop=True)\n",
    "val_ids_ord = meta_va[\"post_id\"].values\n",
    "\n",
    "SB_ids_va = SB_ids_va.astype(str)\n",
    "EN_va_ids = EN_va_ids.astype(str)\n",
    "val_ids_ord = val_ids_ord.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c810a0c-42e3-4f86-a2e4-af5e63897605",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_va = con.sql(\"\"\"\n",
    "    SELECT post_id, er_bins FROM md1718\n",
    "    WHERE split = 'validation'\n",
    "\"\"\").df().set_index('post_id')\n",
    "\n",
    "# allineamento diretto ai post_id in X\n",
    "y_va = metadata_va.loc[val_ids_ord, 'er_bins'].values\n",
    "assert len(y_va) == len(val_ids_ord)\n",
    "\n",
    "# SBERT -> DataFrame indicizzato\n",
    "df_sbert = pd.DataFrame(SB_va, index=SB_ids_va)\n",
    "df_sbert.index.name = \"post_id\"\n",
    "\n",
    "# EfficientNet -> DataFrame indicizzato\n",
    "df_eff = pd.DataFrame(EN_va, index=EN_va_ids)\n",
    "df_eff.index.name = \"post_id\"\n",
    "\n",
    "df_sbert.index = df_sbert.index.astype(str)\n",
    "df_eff.index   = df_eff.index.astype(str)\n",
    "metadata_va.index = metadata_va.index.astype(str)\n",
    "\n",
    "# Allineamento perfetto tramite reindex\n",
    "SBERT_va_aligned = df_sbert.reindex(val_ids_ord).values\n",
    "EN_va_aligned = df_eff.reindex(val_ids_ord).values\n",
    "\n",
    "# Metadata numerici\n",
    "meta_va_np = meta_va.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81fda5c5-9194-4659-b6c1-48e3a315d31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00_rocketgirl-1905372469183881641' '00_rocketgirl-1905378100137554269'\n",
      " '00_rocketgirl-1906985289541418664' '00_rocketgirl-1912887291135668511'\n",
      " '00_rocketgirl-1913179760499084122']\n",
      "Index(['00_rocketgirl-1905372469183881641',\n",
      "       '00_rocketgirl-1905378100137554269',\n",
      "       '00_rocketgirl-1906985289541418664',\n",
      "       '00_rocketgirl-1912887291135668511',\n",
      "       '00_rocketgirl-1913179760499084122'],\n",
      "      dtype='object', name='post_id')\n",
      "Index(['00_rocketgirl-1905372469183881641',\n",
      "       '00_rocketgirl-1905378100137554269',\n",
      "       '00_rocketgirl-1906985289541418664',\n",
      "       '00_rocketgirl-1912887291135668511',\n",
      "       '00_rocketgirl-1913179760499084122'],\n",
      "      dtype='object', name='post_id')\n",
      "412325 412325 412325 412325 412325\n"
     ]
    }
   ],
   "source": [
    "# Checks\n",
    "assert SBERT_va_aligned.shape[0] == len(meta_va)\n",
    "assert EN_va_aligned.shape[0] == len(meta_va)\n",
    "\n",
    "print(val_ids_ord[:5])\n",
    "print(df_sbert.reindex(val_ids_ord).index[:5])\n",
    "print(df_eff.reindex(val_ids_ord).index[:5])\n",
    "print(len(val_ids_ord), SBERT_va_aligned.shape[0], EN_va_aligned.shape[0], meta_va_np.shape[0], len(y_va))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "276efa89-44f9-42ec-a4e9-8fabd9251d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SBERT missing: 0\n",
      "EN missing: 0\n"
     ]
    }
   ],
   "source": [
    "assert (meta_va[\"post_id\"].values == val_ids_ord).all()\n",
    "\n",
    "# Per SBERT\n",
    "assert (df_sbert.loc[val_ids_ord].index.values == val_ids_ord).all()\n",
    "\n",
    "# Per EfficientNet\n",
    "assert (df_eff.loc[val_ids_ord].index.values == val_ids_ord).all()\n",
    "\n",
    "print(\"SBERT missing:\", df_sbert.reindex(val_ids_ord).isna().any(axis=1).sum())\n",
    "print(\"EN missing:\", df_eff.reindex(val_ids_ord).isna().any(axis=1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a8bbb93-ef6c-44b4-a31a-9955e9e66382",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_id_va = meta_val_final['post_id'].values\n",
    "meta_va_num = meta_val_final.drop(columns=['post_id']).values\n",
    "\n",
    "meta_va_num = meta_va_num.astype('float32')\n",
    "SBERT_va_aligned = SBERT_va_aligned.astype('float32')\n",
    "EN_va_aligned = EN_va_aligned.astype('float32')\n",
    "\n",
    "X_va = np.concatenate((meta_va_num, SBERT_va_aligned, EN_va_aligned), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f3aff35-9f15-4ffe-9243-7e0c0a2e661c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(412325, 1692) (412325, 28) (412325, 384) (412325, 1280)\n"
     ]
    }
   ],
   "source": [
    "print(X_va.shape, meta_va_num.shape, SBERT_va_aligned.shape, EN_va_aligned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa1a55a9-4819-4697-a123-3e09e28c55cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"D:/dataset/multimodal2/X_val.npy\", X_va)\n",
    "np.save(\"D:/dataset/multimodal2/y_va_5.npy\", y_va)\n",
    "np.save(\"D:/dataset/multimodal2/post_id_va.npy\", post_id_va)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d8a474-f3c7-4d10-be25-94095d149f5c",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f90cd8fc-67e8-4bab-b112-084c85882ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# METADATA\n",
    "meta_test_final = pd.read_csv(\"D:/dataset/meta_classification/meta_test_final.csv\")\n",
    "\n",
    "# SBERT\n",
    "test = np.load(\"D:/dataset/sbert_emb/paraphrase-MiniLM-L6-v2_test_ids_y.npz\", allow_pickle=True)\n",
    "SB_te = test[\"embeddings\"]\n",
    "SB_ids_te = test[\"ids\"]\n",
    "\n",
    "# EFFICIENT NET\n",
    "\n",
    "EN_te_data = np.load(\"D:/dataset/efficientnetb0_emb/test_data.npz\", allow_pickle=True)\n",
    "EN_te = EN_te_data[\"X\"]\n",
    "EN_te_ids = EN_te_data[\"ids\"]\n",
    "\n",
    "# ALIGN THE THREE SETS\n",
    "meta_te = meta_test_final.sort_values(\"post_id\").reset_index(drop=True)\n",
    "te_ids_ord = meta_te[\"post_id\"].values\n",
    "\n",
    "\n",
    "SB_ids_te = SB_ids_te.astype(str)\n",
    "EN_te_ids = EN_te_ids.astype(str)\n",
    "te_ids_ord = te_ids_ord.astype(str)\n",
    "\n",
    "# Recupero le label y\n",
    "metadata_te = con.sql(\"\"\"\n",
    "    SELECT post_id, er_bins FROM md1718\n",
    "    WHERE split = 'test'\n",
    "\"\"\").df().set_index('post_id')\n",
    "\n",
    "y_te = metadata_te.loc[te_ids_ord, 'er_bins'].values\n",
    "assert len(y_te) == len(te_ids_ord)\n",
    "\n",
    "\n",
    "# SBERT -> DataFrame indicizzato\n",
    "df_sbert = pd.DataFrame(SB_te, index=SB_ids_te)\n",
    "df_sbert.index.name = \"post_id\"\n",
    "\n",
    "# EfficientNet -> DataFrame indicizzato\n",
    "df_eff = pd.DataFrame(EN_te, index=EN_te_ids)\n",
    "df_eff.index.name = \"post_id\"\n",
    "\n",
    "df_sbert.index = df_sbert.index.astype(str)\n",
    "df_eff.index   = df_eff.index.astype(str)\n",
    "metadata_te.index = metadata_te.index.astype(str)\n",
    "\n",
    "# Allineamento perfetto tramite reindex\n",
    "SBERT_te_aligned = df_sbert.reindex(te_ids_ord).values\n",
    "EN_te_aligned = df_eff.reindex(te_ids_ord).values\n",
    "\n",
    "# Metadata numerici\n",
    "meta_te_np = meta_te.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2843efad-eebe-44df-b666-24b86544d521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00_rocketgirl-1924887425826593106' '00_rocketgirl-1926960433592504542'\n",
      " '00_rocketgirl-1931680985582309140' '00_rocketgirl-1936081881737003967'\n",
      " '00_rocketgirl-1942428720468033285']\n",
      "Index(['00_rocketgirl-1924887425826593106',\n",
      "       '00_rocketgirl-1926960433592504542',\n",
      "       '00_rocketgirl-1931680985582309140',\n",
      "       '00_rocketgirl-1936081881737003967',\n",
      "       '00_rocketgirl-1942428720468033285'],\n",
      "      dtype='object', name='post_id')\n",
      "Index(['00_rocketgirl-1924887425826593106',\n",
      "       '00_rocketgirl-1926960433592504542',\n",
      "       '00_rocketgirl-1931680985582309140',\n",
      "       '00_rocketgirl-1936081881737003967',\n",
      "       '00_rocketgirl-1942428720468033285'],\n",
      "      dtype='object', name='post_id')\n",
      "423604 423604 423604 423604 423604\n"
     ]
    }
   ],
   "source": [
    "# Checks\n",
    "assert SBERT_te_aligned.shape[0] == len(meta_te)\n",
    "assert EN_te_aligned.shape[0] == len(meta_te)\n",
    "\n",
    "print(te_ids_ord[:5])\n",
    "print(df_sbert.reindex(te_ids_ord).index[:5])\n",
    "print(df_eff.reindex(te_ids_ord).index[:5])\n",
    "print(len(te_ids_ord), SBERT_te_aligned.shape[0], EN_te_aligned.shape[0], meta_te_np.shape[0], len(y_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0810ccfd-9143-4f04-932e-d687f144173e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SBERT missing: 0\n",
      "EN missing: 0\n"
     ]
    }
   ],
   "source": [
    "assert (meta_te[\"post_id\"].values == te_ids_ord).all()\n",
    "\n",
    "# Per SBERT\n",
    "assert (df_sbert.loc[te_ids_ord].index.values == te_ids_ord).all()\n",
    "\n",
    "# Per EfficientNet\n",
    "assert (df_eff.loc[te_ids_ord].index.values == te_ids_ord).all()\n",
    "\n",
    "print(\"SBERT missing:\", df_sbert.reindex(te_ids_ord).isna().any(axis=1).sum())\n",
    "print(\"EN missing:\", df_eff.reindex(te_ids_ord).isna().any(axis=1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20bff3b8-deca-4be3-a6cd-6cc2f691e4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_id_te = meta_test_final['post_id'].values\n",
    "meta_te_num = meta_test_final.drop(columns=['post_id']).values\n",
    "\n",
    "meta_te_num = meta_te_num.astype('float32')\n",
    "SBERT_te_aligned = SBERT_te_aligned.astype('float32')\n",
    "EN_te_aligned = EN_te_aligned.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56028625-05ef-45c7-bdb8-fb875c5aef6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_te = np.concatenate((meta_te_num, SBERT_te_aligned, EN_te_aligned), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb6fe9ab-7750-429f-a646-abc2d9c80853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(423604, 1692) (423604, 28) (423604, 384) (423604, 1280)\n"
     ]
    }
   ],
   "source": [
    "print(X_te.shape, meta_te_num.shape, SBERT_te_aligned.shape, EN_te_aligned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe610384-7c7f-4ff6-850f-4740459de36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"D:/dataset/multimodal2/X_test.npy\", X_te)\n",
    "np.save(\"D:/dataset/multimodal2/y_te_5.npy\", y_te)\n",
    "np.save(\"D:/dataset/multimodal2/post_id_te.npy\", post_id_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c6f07f-f884-42ba-97f1-1b8960567706",
   "metadata": {},
   "source": [
    "# LOAD FUSED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d56e7045-8581-47ea-a66d-86d2aa72cc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = np.load(\"D:/dataset/multimodal2/X_train.npy\", allow_pickle = True).astype(np.float32)\n",
    "y_tr = np.load(\"D:/dataset/multimodal2/y_tr_5.npy\", allow_pickle = True)\n",
    "\n",
    "X_va = np.load(\"D:/dataset/multimodal2/X_val.npy\", allow_pickle = True).astype(np.float32)\n",
    "y_va = np.load(\"D:/dataset/multimodal2/y_va_5.npy\", allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87c736e9-c672-46d5-be2c-8a568c8ef560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination: {'alpha': 1e-05, 'class_weight': None}\n",
      "macro-F1 (val): 0.2536337075796995 | accuracy (val): 0.2643836779239677\n",
      "\n",
      "Combination: {'alpha': 1e-05, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.17629061546710947 | accuracy (val): 0.2447559570726975\n",
      "\n",
      "Combination: {'alpha': 0.0001, 'class_weight': None}\n",
      "macro-F1 (val): 0.2374582312180352 | accuracy (val): 0.2547965803674286\n",
      "\n",
      "Combination: {'alpha': 0.0001, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.24654819957809387 | accuracy (val): 0.2649827199417935\n",
      "\n",
      "Combination: {'alpha': 0.001, 'class_weight': None}\n",
      "macro-F1 (val): 0.25663301285392937 | accuracy (val): 0.2616212938822531\n",
      "\n",
      "Combination: {'alpha': 0.001, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.25604943095129123 | accuracy (val): 0.266602801188383\n",
      "\n",
      "Best hyperparameter configuration:\n",
      "{'alpha': 0.001, 'class_weight': None}\n",
      "Validation macro-F1: 0.25663301285392937\n",
      "\n",
      "Ordered results by macro-F1 (validation):\n",
      "     alpha class_weight  val_macro_f1  val_accuracy\n",
      "4  0.00100         None      0.256633      0.261621\n",
      "5  0.00100     balanced      0.256049      0.266603\n",
      "0  0.00001         None      0.253634      0.264384\n",
      "3  0.00010     balanced      0.246548      0.264983\n",
      "2  0.00010         None      0.237458      0.254797\n",
      "1  0.00001     balanced      0.176291      0.244756\n"
     ]
    }
   ],
   "source": [
    "# SGD\n",
    "param_grid = {\n",
    "    \"alpha\": [1e-5, 1e-4, 1e-3],\n",
    "    \"class_weight\": [None, \"balanced\"],\n",
    "    }\n",
    "\n",
    "results = []\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    print(f\"\\nCombination: {params}\")\n",
    "\n",
    "    clf = SGDClassifier(\n",
    "        loss=\"hinge\",            \n",
    "        penalty=\"l2\",            \n",
    "        **params,\n",
    "        average = True,\n",
    "        random_state=42,\n",
    "        max_iter=200,\n",
    "        tol=1e-3,\n",
    "        early_stopping = True\n",
    "    )\n",
    "\n",
    "    clf.fit(X_tr, y_tr)\n",
    "\n",
    "    y_val_pred = clf.predict(X_va)\n",
    "\n",
    "    macro_f1 = f1_score(y_va, y_val_pred, average=\"macro\")\n",
    "    acc = accuracy_score(y_va, y_val_pred)\n",
    "\n",
    "    print(f\"macro-F1 (val): {macro_f1} | accuracy (val): {acc}\")\n",
    "\n",
    "    results.append({\n",
    "        \"alpha\": params[\"alpha\"],\n",
    "        \"class_weight\": params[\"class_weight\"],\n",
    "        \"val_macro_f1\": macro_f1,\n",
    "        \"val_accuracy\": acc,\n",
    "    })\n",
    "\n",
    "    if macro_f1 > best_score:\n",
    "        best_score = macro_f1\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\nBest hyperparameter configuration:\")\n",
    "print(best_params)\n",
    "print(\"Validation macro-F1:\", best_score)\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(\"val_macro_f1\", ascending=False)\n",
    "print(\"\\nOrdered results by macro-F1 (validation):\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd804494-246a-4762-add2-02711c6fb493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination: {'var_smoothing': 1e-09}\n",
      "macro-F1 (val): 0.2132 | accuracy (val): 0.2643\n",
      "\n",
      "Combination: {'var_smoothing': 1e-08}\n",
      "macro-F1 (val): 0.2132 | accuracy (val): 0.2643\n",
      "\n",
      "Combination: {'var_smoothing': 1e-07}\n",
      "macro-F1 (val): 0.2132 | accuracy (val): 0.2643\n",
      "\n",
      "Combination: {'var_smoothing': 1e-06}\n",
      "macro-F1 (val): 0.2132 | accuracy (val): 0.2643\n",
      "\n",
      "Best hyperparameter configuration:\n",
      "{'var_smoothing': 1e-09}\n",
      "Validation macro-F1: 0.21320636225167475\n",
      "\n",
      "Ordered results by macro-F1 (validation):\n",
      "   var_smoothing  val_macro_f1  val_accuracy\n",
      "0   1.000000e-09      0.213206      0.264328\n",
      "1   1.000000e-08      0.213205      0.264325\n",
      "2   1.000000e-07      0.213203      0.264323\n",
      "3   1.000000e-06      0.213188      0.264306\n"
     ]
    }
   ],
   "source": [
    "# NAIVE BAYES - GAUSSIAN\n",
    "\n",
    "param_grid_nb = {\n",
    "    \"var_smoothing\": [1e-9, 1e-8, 1e-7, 1e-6]\n",
    "}\n",
    "\n",
    "results = []\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "for params in ParameterGrid(param_grid_nb):\n",
    "    print(f\"\\nCombination: {params}\")\n",
    "\n",
    "    clf = GaussianNB(**params)\n",
    "\n",
    "    # Fit su TRAIN\n",
    "    clf.fit(X_tr, y_tr)\n",
    "\n",
    "    # Valutazione su VALIDATION\n",
    "    y_val_pred = clf.predict(X_va)\n",
    "\n",
    "    macro_f1 = f1_score(y_va, y_val_pred, average=\"macro\")\n",
    "    acc = accuracy_score(y_va, y_val_pred)\n",
    "\n",
    "    print(f\"macro-F1 (val): {macro_f1:.4f} | accuracy (val): {acc:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        \"var_smoothing\": params[\"var_smoothing\"],\n",
    "        \"val_macro_f1\": macro_f1,\n",
    "        \"val_accuracy\": acc,\n",
    "    })\n",
    "\n",
    "    # Aggiorno il best model in base alla macro-F1\n",
    "    if macro_f1 > best_score:\n",
    "        best_score = macro_f1\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\nBest hyperparameter configuration:\")\n",
    "print(best_params)\n",
    "print(\"Validation macro-F1:\", best_score)\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(\"val_macro_f1\", ascending=False)\n",
    "print(\"\\nOrdered results by macro-F1 (validation):\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc5d2f1b-90d5-48cb-aa65-5b9225398272",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.2068 | accuracy (val): 0.2385\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.2046 | accuracy (val): 0.2387\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.2034 | accuracy (val): 0.2387\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.2077 | accuracy (val): 0.2384\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.2052 | accuracy (val): 0.2385\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.2029 | accuracy (val): 0.2383\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.2009 | accuracy (val): 0.2354\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.1985 | accuracy (val): 0.2356\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.1976 | accuracy (val): 0.2364\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.2015 | accuracy (val): 0.2364\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.1985 | accuracy (val): 0.2364\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.1970 | accuracy (val): 0.2364\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.2233 | accuracy (val): 0.2413\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.2205 | accuracy (val): 0.2421\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.2181 | accuracy (val): 0.2422\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.2244 | accuracy (val): 0.2418\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.2212 | accuracy (val): 0.2422\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.2184 | accuracy (val): 0.2417\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.2144 | accuracy (val): 0.2376\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.2125 | accuracy (val): 0.2386\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.2106 | accuracy (val): 0.2391\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.2156 | accuracy (val): 0.2378\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.2124 | accuracy (val): 0.2385\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.2110 | accuracy (val): 0.2392\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 30}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 22\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCombination: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m clf \u001b[38;5;241m=\u001b[39m RandomForestClassifier(\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m     18\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     19\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[0;32m     20\u001b[0m )\n\u001b[1;32m---> 22\u001b[0m clf\u001b[38;5;241m.\u001b[39mfit(X_tr, y_tr)\n\u001b[0;32m     24\u001b[0m y_val_pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_va)\n\u001b[0;32m     26\u001b[0m macro_f1 \u001b[38;5;241m=\u001b[39m f1_score(y_va, y_val_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1358\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1361\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1362\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1363\u001b[0m     )\n\u001b[0;32m   1364\u001b[0m ):\n\u001b[1;32m-> 1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:486\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    475\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    476\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    478\u001b[0m ]\n\u001b[0;32m    480\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    481\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 486\u001b[0m trees \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[0;32m    487\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[0;32m    488\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    489\u001b[0m     prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    490\u001b[0m )(\n\u001b[0;32m    491\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    492\u001b[0m         t,\n\u001b[0;32m    493\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbootstrap,\n\u001b[0;32m    494\u001b[0m         X,\n\u001b[0;32m    495\u001b[0m         y,\n\u001b[0;32m    496\u001b[0m         sample_weight,\n\u001b[0;32m    497\u001b[0m         i,\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28mlen\u001b[39m(trees),\n\u001b[0;32m    499\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    500\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[0;32m    501\u001b[0m         n_samples_bootstrap\u001b[38;5;241m=\u001b[39mn_samples_bootstrap,\n\u001b[0;32m    502\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    503\u001b[0m     )\n\u001b[0;32m    504\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[0;32m    505\u001b[0m )\n\u001b[0;32m    507\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     73\u001b[0m warning_filters \u001b[38;5;241m=\u001b[39m warnings\u001b[38;5;241m.\u001b[39mfilters\n\u001b[0;32m     74\u001b[0m iterable_with_config_and_warning_filters \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     75\u001b[0m     (\n\u001b[0;32m     76\u001b[0m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     81\u001b[0m )\n\u001b[1;32m---> 82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config_and_warning_filters)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# RANDOM FOREST\n",
    "param_grid_rf = {\n",
    "    \"n_estimators\": [30, 50, 80],\n",
    "    \"max_depth\": [8, 10, 12],\n",
    "    \"min_samples_leaf\": [2, 5],\n",
    "    \"max_features\": [0.05, \"sqrt\"],\n",
    "}\n",
    "\n",
    "results = []\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "for params in ParameterGrid(param_grid_rf):\n",
    "    print(f\"\\nCombination: {params}\")\n",
    "\n",
    "    clf = RandomForestClassifier(\n",
    "        **params,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    clf.fit(X_tr, y_tr)\n",
    "\n",
    "    y_val_pred = clf.predict(X_va)\n",
    "\n",
    "    macro_f1 = f1_score(y_va, y_val_pred, average=\"macro\")\n",
    "    acc = accuracy_score(y_va, y_val_pred)\n",
    "\n",
    "    print(f\"macro-F1 (val): {macro_f1:.4f} | accuracy (val): {acc:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        \"n_estimators\": params[\"n_estimators\"],\n",
    "        \"max_depth\": params[\"max_depth\"],\n",
    "        \"min_samples_leaf\": params[\"min_samples_leaf\"],\n",
    "        \"max_features\": params[\"max_features\"],\n",
    "        \"val_macro_f1\": macro_f1,\n",
    "        \"val_accuracy\": acc,\n",
    "    })\n",
    "\n",
    "    if macro_f1 > best_score:\n",
    "        best_score = macro_f1\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\nBest hyperparameter configuration (Random Forest):\")\n",
    "print(best_params)\n",
    "print(\"Validation macro-F1:\", best_score)\n",
    "\n",
    "results_df_rf = pd.DataFrame(results).sort_values(\"val_macro_f1\", ascending=False)\n",
    "print(\"\\nOrdered results by macro-F1 (validation):\")\n",
    "print(results_df_rf)\n",
    "\n",
    "# Among these the best is \n",
    "# Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 30}\n",
    "# macro-F1 (val): 0.2244 | accuracy (val): 0.2418"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "902b51de-d191-4666-9ffe-9e9b9069f3fb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.2349 | accuracy (val): 0.2422\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.2325 | accuracy (val): 0.2429\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.2309 | accuracy (val): 0.2437\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.2320 | accuracy (val): 0.2407\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.2318 | accuracy (val): 0.2427\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.2306 | accuracy (val): 0.2443\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.2281 | accuracy (val): 0.2389\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.2261 | accuracy (val): 0.2405\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.2241 | accuracy (val): 0.2412\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.2284 | accuracy (val): 0.2392\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.2257 | accuracy (val): 0.2399\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.2241 | accuracy (val): 0.2416\n",
      "\n",
      "Best hyperparameter configuration (Random Forest):\n",
      "{'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 30}\n",
      "Validation macro-F1: 0.23491321496671014\n",
      "\n",
      "Ordered results by macro-F1 (validation):\n",
      "    n_estimators  max_depth  min_samples_leaf max_features  val_macro_f1  \\\n",
      "0             30         12                 2         0.05      0.234913   \n",
      "1             50         12                 2         0.05      0.232461   \n",
      "3             30         12                 5         0.05      0.231952   \n",
      "4             50         12                 5         0.05      0.231773   \n",
      "2             80         12                 2         0.05      0.230931   \n",
      "5             80         12                 5         0.05      0.230583   \n",
      "9             30         12                 5         sqrt      0.228378   \n",
      "6             30         12                 2         sqrt      0.228061   \n",
      "7             50         12                 2         sqrt      0.226134   \n",
      "10            50         12                 5         sqrt      0.225678   \n",
      "11            80         12                 5         sqrt      0.224109   \n",
      "8             80         12                 2         sqrt      0.224075   \n",
      "\n",
      "    val_accuracy  \n",
      "0       0.242217  \n",
      "1       0.242852  \n",
      "3       0.240737  \n",
      "4       0.242736  \n",
      "2       0.243708  \n",
      "5       0.244310  \n",
      "9       0.239246  \n",
      "6       0.238909  \n",
      "7       0.240500  \n",
      "10      0.239949  \n",
      "11      0.241649  \n",
      "8       0.241188  \n"
     ]
    }
   ],
   "source": [
    "# RANDOM FOREST\n",
    "param_grid_rf = {\n",
    "    \"n_estimators\": [30, 50, 80],\n",
    "    \"max_depth\": [12],\n",
    "    \"min_samples_leaf\": [2, 5],\n",
    "    \"max_features\": [0.05, \"sqrt\"],\n",
    "}\n",
    "\n",
    "results = []\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "for params in ParameterGrid(param_grid_rf):\n",
    "    print(f\"\\nCombination: {params}\")\n",
    "\n",
    "    clf = RandomForestClassifier(\n",
    "        **params,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    clf.fit(X_tr, y_tr)\n",
    "\n",
    "    y_val_pred = clf.predict(X_va)\n",
    "\n",
    "    macro_f1 = f1_score(y_va, y_val_pred, average=\"macro\")\n",
    "    acc = accuracy_score(y_va, y_val_pred)\n",
    "\n",
    "    print(f\"macro-F1 (val): {macro_f1:.4f} | accuracy (val): {acc:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        \"n_estimators\": params[\"n_estimators\"],\n",
    "        \"max_depth\": params[\"max_depth\"],\n",
    "        \"min_samples_leaf\": params[\"min_samples_leaf\"],\n",
    "        \"max_features\": params[\"max_features\"],\n",
    "        \"val_macro_f1\": macro_f1,\n",
    "        \"val_accuracy\": acc,\n",
    "    })\n",
    "\n",
    "    if macro_f1 > best_score:\n",
    "        best_score = macro_f1\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\nBest hyperparameter configuration (Random Forest):\")\n",
    "print(best_params)\n",
    "print(\"Validation macro-F1:\", best_score)\n",
    "\n",
    "results_df_rf = pd.DataFrame(results).sort_values(\"val_macro_f1\", ascending=False)\n",
    "print(\"\\nOrdered results by macro-F1 (validation):\")\n",
    "print(results_df_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c45a7e48-aad8-4eaf-bd2e-6e83ee1941c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.2504 | accuracy (val): 0.2576\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 150, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.2549 | accuracy (val): 0.2626\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.2584 | accuracy (val): 0.2639\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 150, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.2621 | accuracy (val): 0.2687\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.2504 | accuracy (val): 0.2576\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 150, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.2549 | accuracy (val): 0.2626\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.2587 | accuracy (val): 0.2637\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 150, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.2620 | accuracy (val): 0.2687\n",
      "\n",
      "Best hyperparameter configuration (XGBoost):\n",
      "{'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 150, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "Validation macro-F1: 0.26212961394290935\n",
      "\n",
      "Ordered results:\n",
      "   colsample_bytree  gamma  learning_rate  max_depth  n_estimators  \\\n",
      "3               0.5      0            0.1          6           150   \n",
      "7               0.5      1            0.1          6           150   \n",
      "6               0.5      1            0.1          6           100   \n",
      "2               0.5      0            0.1          6           100   \n",
      "5               0.5      1            0.1          4           150   \n",
      "1               0.5      0            0.1          4           150   \n",
      "0               0.5      0            0.1          4           100   \n",
      "4               0.5      1            0.1          4           100   \n",
      "\n",
      "   reg_lambda  subsample  val_macro_f1  val_accuracy  \n",
      "3           1        0.8      0.262130      0.268689  \n",
      "7           1        0.8      0.261955      0.268676  \n",
      "6           1        0.8      0.258710      0.263651  \n",
      "2           1        0.8      0.258397      0.263860  \n",
      "5           1        0.8      0.254944      0.262582  \n",
      "1           1        0.8      0.254944      0.262582  \n",
      "0           1        0.8      0.250417      0.257598  \n",
      "4           1        0.8      0.250417      0.257598  \n"
     ]
    }
   ],
   "source": [
    "# XGBOOST\n",
    "\n",
    "# Convert the labels into numbers\n",
    "le = LabelEncoder()\n",
    "y_tr_enc = le.fit_transform(y_tr)\n",
    "y_val_enc = le.transform(y_va)\n",
    "\n",
    "\n",
    "param_grid_xgb = {\n",
    "    \"n_estimators\": [100, 150], \n",
    "    \"max_depth\": [4, 6], \n",
    "    \"learning_rate\": [0.1], \n",
    "    \"subsample\": [0.8], \n",
    "    \"colsample_bytree\": [0.5], \n",
    "    \"gamma\": [0, 1], \n",
    "    \"reg_lambda\": [1], \n",
    "}\n",
    "\n",
    "results = []\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "for params in ParameterGrid(param_grid_xgb):\n",
    "    print(f\"\\nCombination: {params}\")\n",
    "\n",
    "    clf = XGBClassifier(\n",
    "        **params,\n",
    "        objective=\"multi:softmax\",\n",
    "        num_class=len(np.unique(y_tr_enc)),\n",
    "        tree_method=\"hist\",\n",
    "        eval_metric=\"mlogloss\",\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        verbosity=0,\n",
    "    )\n",
    "\n",
    "    clf.fit(X_tr, y_tr_enc)\n",
    "\n",
    "    y_val_pred = clf.predict(X_va)\n",
    "\n",
    "    macro_f1 = f1_score(y_val_enc, y_val_pred, average=\"macro\")\n",
    "    acc = accuracy_score(y_val_enc, y_val_pred)\n",
    "\n",
    "    print(f\"macro-F1 (val): {macro_f1:.4f} | accuracy (val): {acc:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        **params,\n",
    "        \"val_macro_f1\": macro_f1,\n",
    "        \"val_accuracy\": acc,\n",
    "    })\n",
    "\n",
    "    if macro_f1 > best_score:\n",
    "        best_score = macro_f1\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\nBest hyperparameter configuration (XGBoost):\")\n",
    "print(best_params)\n",
    "print(\"Validation macro-F1:\", best_score)\n",
    "\n",
    "results_df_xgb = pd.DataFrame(results).sort_values(\"val_macro_f1\", ascending=False)\n",
    "print(\"\\nOrdered results:\")\n",
    "print(results_df_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ec48de-fc5a-4d0d-b20b-903604dc9ab5",
   "metadata": {},
   "source": [
    "# PERFORMANCE ON TEST SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38c67088-d9be-4b10-890c-10009c6f131d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = np.load(\"D:/dataset/multimodal2/X_train.npy\", allow_pickle = True).astype(np.float32)\n",
    "y_tr = np.load(\"D:/dataset/multimodal2/y_tr_5.npy\", allow_pickle = True)\n",
    "\n",
    "X_va = np.load(\"D:/dataset/multimodal2/X_val.npy\", allow_pickle = True).astype(np.float32)\n",
    "y_va = np.load(\"D:/dataset/multimodal2/y_va_5.npy\", allow_pickle = True)\n",
    "\n",
    "X_trva = np.concatenate((X_tr, X_va), axis = 0)\n",
    "y_trva = np.concatenate((y_tr, y_va), axis = 0)\n",
    "\n",
    "np.save(\"D:/dataset/multimodal2/X_trainval.npy\", X_trva)\n",
    "np.save(\"D:/dataset/multimodal2/y_trva_5.npy\", y_trva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1219695-8f6b-41c6-9d63-05cffb96cd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = np.load(\"D:/dataset/multimodal2/X_trainval.npy\", allow_pickle = True).astype(np.float32)\n",
    "y_tr = np.load(\"D:/dataset/multimodal2/y_trva_5.npy\", allow_pickle = True)\n",
    "\n",
    "X_te = np.load(\"D:/dataset/multimodal2/X_test.npy\", allow_pickle = True).astype(np.float32)\n",
    "y_te = np.load(\"D:/dataset/multimodal2/y_te_5.npy\", allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dc0c7f6-3a98-430a-8b29-36930d8e09e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macro-F1 (test): 0.2530 | accuracy (test): 0.2591\n"
     ]
    }
   ],
   "source": [
    "cfg = SGDClassifier(\n",
    "        loss=\"hinge\",\n",
    "        penalty=\"l2\",\n",
    "        alpha = 0.001,\n",
    "        average = True,\n",
    "        class_weight = None,\n",
    "        random_state=42,\n",
    "        max_iter=500,\n",
    "        tol=1e-3,\n",
    "    )\n",
    "\n",
    "\n",
    "cfg.fit(X_tr, y_tr)\n",
    "y_te_pred = cfg.predict(X_te)\n",
    "macro_f1 = f1_score(y_te, y_te_pred, average=\"macro\")\n",
    "acc = accuracy_score(y_te, y_te_pred)\n",
    "\n",
    "print(f\"macro-F1 (test): {macro_f1:.4f} | accuracy (test): {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce14a0c8-0550-4b82-9890-bf875a16db4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configuration: RandomForestClassifier(max_depth=12, max_features=0.05, min_samples_leaf=2,\n",
      "                       n_estimators=30, n_jobs=-1, random_state=42)\n",
      "macro-F1 (test): 0.2312 | accuracy (test): 0.2391\n",
      "\n",
      "Configuration: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.5, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric='mlogloss',\n",
      "              feature_types=None, feature_weights=None, gamma=0,\n",
      "              grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=150, n_jobs=-1, num_class=5, ...)\n",
      "macro-F1 (test): 0.2621 | accuracy (test): 0.2667\n"
     ]
    }
   ],
   "source": [
    "# Convert the labels into numbers\n",
    "le = LabelEncoder()\n",
    "y_tr_enc = le.fit_transform(y_tr)\n",
    "y_te_enc = le.transform(y_te)\n",
    "\n",
    "cfgs = [\n",
    "    RandomForestClassifier(\n",
    "        max_depth=12, max_features=0.05, min_samples_leaf=2, n_estimators=30, n_jobs=-1, random_state=42\n",
    "    ),\n",
    "    XGBClassifier(colsample_bytree = 0.5, gamma = 0, learning_rate = 0.1, max_depth= 6, n_estimators= 150, reg_lambda= 1, subsample= 0.8,\n",
    "        objective=\"multi:softmax\",\n",
    "        num_class=len(np.unique(y_tr_enc)),\n",
    "        tree_method=\"hist\", eval_metric=\"mlogloss\",\n",
    "        n_jobs=-1, random_state=42, verbosity=0\n",
    "    )\n",
    "]\n",
    "\n",
    "for cfg in cfgs:\n",
    "    print(f\"\\nConfiguration: {cfg}\")\n",
    "\n",
    "    # XGB requires a numerical target\n",
    "    if isinstance(cfg, XGBClassifier):\n",
    "        cfg.fit(X_tr, y_tr_enc)\n",
    "        y_te_pred = cfg.predict(X_te)\n",
    "        macro_f1 = f1_score(y_te_enc, y_te_pred, average=\"macro\")\n",
    "        acc = accuracy_score(y_te_enc, y_te_pred)\n",
    "\n",
    "    else:\n",
    "        cfg.fit(X_tr, y_tr)\n",
    "        y_te_pred = cfg.predict(X_te)\n",
    "        macro_f1 = f1_score(y_te, y_te_pred, average=\"macro\")\n",
    "        acc = accuracy_score(y_te, y_te_pred)\n",
    "\n",
    "    print(f\"macro-F1 (test): {macro_f1:.4f} | accuracy (test): {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36cba24a-daf6-431e-8879-f9a60ff15016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macro-F1 (test): 0.2148 | accuracy (test): 0.2655\n"
     ]
    }
   ],
   "source": [
    "# NAIVE BAYES\n",
    "import scipy.sparse as sp\n",
    "\n",
    "batch_size = 256\n",
    "classes = np.unique(y_tr)\n",
    "\n",
    "clf = GaussianNB(var_smoothing=1e-09)\n",
    "\n",
    "# FIT minibatch\n",
    "for start in range(0, X_tr.shape[0], batch_size):\n",
    "    end = min(start + batch_size, X_tr.shape[0])\n",
    "\n",
    "    X_slice = X_tr[start:end]\n",
    "    Xb = X_slice.toarray() if sp.issparse(X_slice) else X_slice\n",
    "\n",
    "    yb = y_tr[start:end]\n",
    "\n",
    "    if start == 0:\n",
    "        clf.partial_fit(Xb, yb, classes=classes)\n",
    "    else:\n",
    "        clf.partial_fit(Xb, yb)\n",
    "\n",
    "    del Xb, yb, X_slice\n",
    "    gc.collect()\n",
    "\n",
    "# PREDICT minibatch (SU X_te!)\n",
    "y_te_pred = []\n",
    "\n",
    "for start in range(0, X_te.shape[0], batch_size):\n",
    "    end = min(start + batch_size, X_te.shape[0])\n",
    "\n",
    "    X_slice = X_te[start:end]\n",
    "    Xb = X_slice.toarray() if sp.issparse(X_slice) else X_slice\n",
    "\n",
    "    y_te_pred.append(clf.predict(Xb))\n",
    "\n",
    "    del Xb, X_slice\n",
    "    gc.collect()\n",
    "\n",
    "y_te_pred = np.concatenate(y_te_pred)\n",
    "\n",
    "macro_f1 = f1_score(y_te, y_te_pred, average=\"macro\")\n",
    "acc = accuracy_score(y_te, y_te_pred)\n",
    "\n",
    "print(f\"macro-F1 (test): {macro_f1:.4f} | accuracy (test): {acc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (CLIP Env)",
   "language": "python",
   "name": "clip_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
