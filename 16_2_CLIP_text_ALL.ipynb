{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45776990-361b-447d-9e0f-95847cefa4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb, torch, time, os, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from scipy.sparse import load_npz, hstack, save_npz\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from transformers import CLIPTokenizer, CLIPModel\n",
    "import torch\n",
    "import numpy as np\n",
    "import gc, os, time\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8dabcca-8d06-425d-a0f5-c33410bec035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up ready\n"
     ]
    }
   ],
   "source": [
    "DB_PATH = \"D:/db/meta.duckdb\"\n",
    "con = duckdb.connect(DB_PATH)\n",
    "try:\n",
    "    con.execute(\"PRAGMA threads=8;\")\n",
    "except duckdb.InvalidInputException:\n",
    "    pass\n",
    "\n",
    "print(\"Set up ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0481828-454c-4ebb-9d73-320a86eaf2b9",
   "metadata": {},
   "source": [
    "# LOAD DATA FOR CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d4ac7a6-c30c-4eb7-b7f7-7574ddde5221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(773497, 512) 773497\n"
     ]
    }
   ],
   "source": [
    "train = np.load(\"D:/dataset/clip_text_emb_ALL/clip-vit-base-patch32_train_ids_y.npz\", allow_pickle = True)\n",
    "\n",
    "X_tr = train[\"embeddings\"]\n",
    "ids_tr = train[\"ids\"]\n",
    "\n",
    "print(X_tr.shape, len(ids_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5aedb603-fac1-4792-b028-67deceffc477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(412325, 512) 412325\n"
     ]
    }
   ],
   "source": [
    "val = np.load(\"D:/dataset/clip_text_emb_ALL/clip-vit-base-patch32_val_ids_y.npz\", allow_pickle = True)\n",
    "\n",
    "X_va = val[\"embeddings\"]\n",
    "ids_va = val[\"ids\"]\n",
    "\n",
    "print(X_va.shape, len(ids_va))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b9e871d-7c66-4f96-9887-fb56a067d612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(412325, 512) 412325\n"
     ]
    }
   ],
   "source": [
    "test = np.load(\"D:/dataset/clip_text_emb_ALL/clip-vit-base-patch32_test_ids_y.npz\", allow_pickle = True)\n",
    "\n",
    "X_te = test[\"embeddings\"]\n",
    "ids_te = test[\"ids\"]\n",
    "\n",
    "print(X_va.shape, len(ids_va))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76198e6b-ed4d-4beb-a3df-c451b4ef3c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c35643c913b49c1b07217ed7789ee7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metadata_tr = con.sql(\"\"\"\n",
    "    SELECT post_id, er_bins2 FROM md1718\n",
    "    WHERE split = 'train'\n",
    "\"\"\").df().set_index('post_id')\n",
    "\n",
    "# allineamento diretto ai post_id in X\n",
    "y_tr = metadata_tr.loc[ids_tr, 'er_bins2'].values\n",
    "assert len(y_tr) == len(ids_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c73297b-ff77-4135-81a8-b614c1726ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_va = con.sql(\"\"\"\n",
    "    SELECT post_id, er_bins2 FROM md1718\n",
    "    WHERE split = 'validation'\n",
    "\"\"\").df().set_index('post_id')\n",
    "\n",
    "# allineamento diretto ai post_id in X\n",
    "y_va = metadata_va.loc[ids_va, 'er_bins2'].values\n",
    "assert len(y_va) == len(ids_va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28afeb25-6c46-43f3-9e31-42144838efc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_te = con.sql(\"\"\"\n",
    "    SELECT post_id, er_bins2 FROM md1718\n",
    "    WHERE split = 'test'\n",
    "\"\"\").df().set_index('post_id')\n",
    "\n",
    "# allineamento diretto ai post_id in X\n",
    "y_te = metadata_te.loc[ids_te, 'er_bins2'].values\n",
    "assert len(y_te) == len(ids_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35aef779-00b8-44d3-83dd-5fb2f3712e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"D:/dataset/clip_text_emb_ALL/y_tr_2\", y_tr)\n",
    "np.save(\"D:/dataset/clip_text_emb_ALL/y_va_2\", y_va)\n",
    "np.save(\"D:/dataset/clip_text_emb_ALL/y_te_2\", y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6dccc69-67b2-4efe-a2d0-2229bd5b065c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = np.load(\"D:/dataset/clip_text_emb_ALL/clip-vit-base-patch32_train_ids_y.npz\", allow_pickle = True)\n",
    "val = np.load(\"D:/dataset/clip_text_emb_ALL/clip-vit-base-patch32_val_ids_y.npz\", allow_pickle = True)\n",
    "\n",
    "X_tr = train[\"embeddings\"]\n",
    "X_va = val[\"embeddings\"]\n",
    "\n",
    "y_tr = np.load(\"D:/dataset/clip_text_emb_ALL/y_tr_2.npy\", allow_pickle = True)\n",
    "y_va = np.load(\"D:/dataset/clip_text_emb_ALL/y_va_2.npy\", allow_pickle = True)\n",
    "\n",
    "del train, val\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0689fbbf-551f-4c47-a456-c0fbb4895740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination: {'alpha': 1e-05, 'class_weight': None}\n",
      "macro-F1 (val): 0.58376487834214 | accuracy (val): 0.5837652337355241\n",
      "\n",
      "Combination: {'alpha': 1e-05, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.583705364041589 | accuracy (val): 0.5837118777663252\n",
      "\n",
      "Combination: {'alpha': 0.0001, 'class_weight': None}\n",
      "macro-F1 (val): 0.5836143351833228 | accuracy (val): 0.5837191535803068\n",
      "\n",
      "Combination: {'alpha': 0.0001, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.5834232305943959 | accuracy (val): 0.583479051718911\n",
      "\n",
      "Combination: {'alpha': 0.001, 'class_weight': None}\n",
      "macro-F1 (val): 0.5769437978699319 | accuracy (val): 0.5779494330928273\n",
      "\n",
      "Combination: {'alpha': 0.001, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.5770549903029751 | accuracy (val): 0.5777820893712484\n",
      "\n",
      "Combination: {'alpha': 0.01, 'class_weight': None}\n",
      "macro-F1 (val): 0.33756738476842324 | accuracy (val): 0.5046383314133268\n",
      "\n",
      "Combination: {'alpha': 0.01, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.4123171186151787 | accuracy (val): 0.5166312981264779\n",
      "\n",
      "Best hyperparameter configuration:\n",
      "{'alpha': 1e-05, 'class_weight': None}\n",
      "Validation macro-F1: 0.58376487834214\n",
      "\n",
      "Ordered results by macro-F1 (validation):\n",
      "     alpha class_weight  val_macro_f1  val_accuracy\n",
      "0  0.00001         None      0.583765      0.583765\n",
      "1  0.00001     balanced      0.583705      0.583712\n",
      "2  0.00010         None      0.583614      0.583719\n",
      "3  0.00010     balanced      0.583423      0.583479\n",
      "5  0.00100     balanced      0.577055      0.577782\n",
      "4  0.00100         None      0.576944      0.577949\n",
      "7  0.01000     balanced      0.412317      0.516631\n",
      "6  0.01000         None      0.337567      0.504638\n"
     ]
    }
   ],
   "source": [
    "# SGD\n",
    "param_grid = {\n",
    "    \"alpha\": [1e-5, 1e-4, 1e-3, 1e-2],\n",
    "    \"class_weight\": [None, \"balanced\"],\n",
    "}\n",
    "\n",
    "results = []\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    print(f\"\\nCombination: {params}\")\n",
    "\n",
    "    clf = SGDClassifier(\n",
    "        loss=\"hinge\",            \n",
    "        penalty=\"l2\",            \n",
    "        **params,\n",
    "        average = True,\n",
    "        random_state=42,\n",
    "        max_iter=1000,\n",
    "        tol=1e-3,\n",
    "    )\n",
    "\n",
    "    clf.fit(X_tr, y_tr)\n",
    "\n",
    "    y_val_pred = clf.predict(X_va)\n",
    "\n",
    "    macro_f1 = f1_score(y_va, y_val_pred, average=\"macro\")\n",
    "    acc = accuracy_score(y_va, y_val_pred)\n",
    "\n",
    "    print(f\"macro-F1 (val): {macro_f1} | accuracy (val): {acc}\")\n",
    "\n",
    "    results.append({\n",
    "        \"alpha\": params[\"alpha\"],\n",
    "        \"class_weight\": params[\"class_weight\"],\n",
    "        \"val_macro_f1\": macro_f1,\n",
    "        \"val_accuracy\": acc,\n",
    "    })\n",
    "\n",
    "    if macro_f1 > best_score:\n",
    "        best_score = macro_f1\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\nBest hyperparameter configuration:\")\n",
    "print(best_params)\n",
    "print(\"Validation macro-F1:\", best_score)\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(\"val_macro_f1\", ascending=False)\n",
    "print(\"\\nOrdered results by macro-F1 (validation):\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96c3cb70-c318-402b-8964-08e4d8bed391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination: {'var_smoothing': 1e-09}\n",
      "macro-F1 (val): 0.5517 | accuracy (val): 0.5539\n",
      "\n",
      "Combination: {'var_smoothing': 1e-08}\n",
      "macro-F1 (val): 0.5517 | accuracy (val): 0.5539\n",
      "\n",
      "Combination: {'var_smoothing': 1e-07}\n",
      "macro-F1 (val): 0.5517 | accuracy (val): 0.5539\n",
      "\n",
      "Combination: {'var_smoothing': 1e-06}\n",
      "macro-F1 (val): 0.5517 | accuracy (val): 0.5539\n",
      "\n",
      "Best hyperparameter configuration:\n",
      "{'var_smoothing': 1e-09}\n",
      "Validation macro-F1: 0.5516860599919027\n",
      "\n",
      "Ordered results by macro-F1 (validation):\n",
      "   var_smoothing  val_macro_f1  val_accuracy\n",
      "0   1.000000e-09      0.551686      0.553908\n",
      "1   1.000000e-08      0.551686      0.553908\n",
      "2   1.000000e-07      0.551686      0.553908\n",
      "3   1.000000e-06      0.551686      0.553908\n"
     ]
    }
   ],
   "source": [
    "# NAIVE BAYES - GAUSSIAN\n",
    "param_grid_nb = {\n",
    "    \"var_smoothing\": [1e-9, 1e-8, 1e-7, 1e-6]\n",
    "}\n",
    "\n",
    "results = []\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "for params in ParameterGrid(param_grid_nb):\n",
    "    print(f\"\\nCombination: {params}\")\n",
    "\n",
    "    clf = GaussianNB(**params)\n",
    "\n",
    "    # Fit su TRAIN\n",
    "    clf.fit(X_tr, y_tr)\n",
    "\n",
    "    # Valutazione su VALIDATION\n",
    "    y_val_pred = clf.predict(X_va)\n",
    "\n",
    "    macro_f1 = f1_score(y_va, y_val_pred, average=\"macro\")\n",
    "    acc = accuracy_score(y_va, y_val_pred)\n",
    "\n",
    "    print(f\"macro-F1 (val): {macro_f1:.4f} | accuracy (val): {acc:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        \"var_smoothing\": params[\"var_smoothing\"],\n",
    "        \"val_macro_f1\": macro_f1,\n",
    "        \"val_accuracy\": acc,\n",
    "    })\n",
    "\n",
    "    # Aggiorno il best model in base alla macro-F1\n",
    "    if macro_f1 > best_score:\n",
    "        best_score = macro_f1\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\nBest hyperparameter configuration:\")\n",
    "print(best_params)\n",
    "print(\"Validation macro-F1:\", best_score)\n",
    "\n",
    "# Metto i risultati in un DataFrame per ispezionarli meglio\n",
    "results_df = pd.DataFrame(results).sort_values(\"val_macro_f1\", ascending=False)\n",
    "print(\"\\nOrdered results by macro-F1 (validation):\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "deff276a-0186-4c66-9e3a-2e0ea06df787",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.5722 | accuracy (val): 0.5722\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.5738 | accuracy (val): 0.5738\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.5723 | accuracy (val): 0.5723\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.5734 | accuracy (val): 0.5734\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.5726 | accuracy (val): 0.5726\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.5734 | accuracy (val): 0.5734\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.5717 | accuracy (val): 0.5717\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.5739 | accuracy (val): 0.5739\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.5739 | accuracy (val): 0.5739\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.5749 | accuracy (val): 0.5749\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.5732 | accuracy (val): 0.5732\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.5744 | accuracy (val): 0.5744\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.5723 | accuracy (val): 0.5723\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.5744 | accuracy (val): 0.5744\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.5735 | accuracy (val): 0.5735\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.5752 | accuracy (val): 0.5752\n",
      "\n",
      "Best hyperparameter configuration (Random Forest):\n",
      "{'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "Validation macro-F1: 0.5752059318538661\n",
      "\n",
      "Ordered results by macro-F1 (validation):\n",
      "    n_estimators  max_depth  min_samples_leaf max_features  val_macro_f1  \\\n",
      "15            80         12                 5         sqrt      0.575206   \n",
      "9             80         12                 2         0.05      0.574932   \n",
      "13            80         12                 2         sqrt      0.574387   \n",
      "11            80         12                 5         0.05      0.574367   \n",
      "7             80         10                 5         sqrt      0.573899   \n",
      "8             50         12                 2         0.05      0.573870   \n",
      "1             80         10                 2         0.05      0.573761   \n",
      "14            50         12                 5         sqrt      0.573480   \n",
      "3             80         10                 5         0.05      0.573387   \n",
      "5             80         10                 2         sqrt      0.573371   \n",
      "10            50         12                 5         0.05      0.573179   \n",
      "4             50         10                 2         sqrt      0.572572   \n",
      "2             50         10                 5         0.05      0.572347   \n",
      "12            50         12                 2         sqrt      0.572295   \n",
      "0             50         10                 2         0.05      0.572155   \n",
      "6             50         10                 5         sqrt      0.571684   \n",
      "\n",
      "    val_accuracy  \n",
      "15      0.575211  \n",
      "9       0.574932  \n",
      "13      0.574392  \n",
      "11      0.574367  \n",
      "7       0.573899  \n",
      "8       0.573870  \n",
      "1       0.573761  \n",
      "14      0.573487  \n",
      "3       0.573387  \n",
      "5       0.573385  \n",
      "10      0.573179  \n",
      "4       0.572587  \n",
      "2       0.572347  \n",
      "12      0.572296  \n",
      "0       0.572155  \n",
      "6       0.571685  \n"
     ]
    }
   ],
   "source": [
    "# RANDOM FOREST\n",
    "param_grid_rf = {\n",
    "    \"n_estimators\": [50, 80],\n",
    "    \"max_depth\": [10, 12], \n",
    "    \"min_samples_leaf\": [2, 5],\n",
    "    \"max_features\": [0.05, \"sqrt\"],\n",
    "}\n",
    "\n",
    "results = []\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "for params in ParameterGrid(param_grid_rf):\n",
    "    print(f\"\\nCombination: {params}\")\n",
    "\n",
    "    clf = RandomForestClassifier(\n",
    "        **params,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Fit su TRAIN\n",
    "    clf.fit(X_tr, y_tr)\n",
    "\n",
    "    # Valutazione su VALIDATION\n",
    "    y_val_pred = clf.predict(X_va)\n",
    "\n",
    "    macro_f1 = f1_score(y_va, y_val_pred, average=\"macro\")\n",
    "    acc = accuracy_score(y_va, y_val_pred)\n",
    "\n",
    "    print(f\"macro-F1 (val): {macro_f1:.4f} | accuracy (val): {acc:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        \"n_estimators\": params[\"n_estimators\"],\n",
    "        \"max_depth\": params[\"max_depth\"],\n",
    "        \"min_samples_leaf\": params[\"min_samples_leaf\"],\n",
    "        \"max_features\": params[\"max_features\"],\n",
    "        \"val_macro_f1\": macro_f1,\n",
    "        \"val_accuracy\": acc,\n",
    "    })\n",
    "\n",
    "    if macro_f1 > best_score:\n",
    "        best_score = macro_f1\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\nBest hyperparameter configuration (Random Forest):\")\n",
    "print(best_params)\n",
    "print(\"Validation macro-F1:\", best_score)\n",
    "\n",
    "results_df_rf = pd.DataFrame(results).sort_values(\"val_macro_f1\", ascending=False)\n",
    "print(\"\\nOrdered results by macro-F1 (validation):\")\n",
    "print(results_df_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8dfb430-86e0-435a-a500-9393d1227359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.5788 | accuracy (val): 0.5788\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 150, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.5816 | accuracy (val): 0.5816\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.5831 | accuracy (val): 0.5831\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 150, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.5846 | accuracy (val): 0.5847\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.5788 | accuracy (val): 0.5788\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 150, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.5816 | accuracy (val): 0.5816\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.5831 | accuracy (val): 0.5831\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 150, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.5847 | accuracy (val): 0.5847\n",
      "\n",
      "Best hyperparameter configuration (XGBoost):\n",
      "{'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 150, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "Validation macro-F1: 0.5847108930778606\n",
      "\n",
      "Ordered results:\n",
      "   colsample_bytree  gamma  learning_rate  max_depth  n_estimators  \\\n",
      "7               0.5      1            0.1          6           150   \n",
      "3               0.5      0            0.1          6           150   \n",
      "2               0.5      0            0.1          6           100   \n",
      "6               0.5      1            0.1          6           100   \n",
      "5               0.5      1            0.1          4           150   \n",
      "1               0.5      0            0.1          4           150   \n",
      "0               0.5      0            0.1          4           100   \n",
      "4               0.5      1            0.1          4           100   \n",
      "\n",
      "   reg_lambda  subsample  val_macro_f1  val_accuracy  \n",
      "7           1        0.8      0.584711      0.584714  \n",
      "3           1        0.8      0.584648      0.584653  \n",
      "2           1        0.8      0.583113      0.583113  \n",
      "6           1        0.8      0.583108      0.583108  \n",
      "5           1        0.8      0.581569      0.581570  \n",
      "1           1        0.8      0.581569      0.581570  \n",
      "0           1        0.8      0.578764      0.578764  \n",
      "4           1        0.8      0.578764      0.578764  \n"
     ]
    }
   ],
   "source": [
    "# XGBOOST\n",
    "\n",
    "# Convert the labels into numbers\n",
    "le = LabelEncoder()\n",
    "y_tr_enc = le.fit_transform(y_tr)\n",
    "y_val_enc = le.transform(y_va)\n",
    "\n",
    "\n",
    "param_grid_xgb = {\n",
    "    \"n_estimators\": [100, 150], \n",
    "    \"max_depth\": [4, 6], \n",
    "    \"learning_rate\": [0.1], \n",
    "    \"subsample\": [0.8], \n",
    "    \"colsample_bytree\": [0.5],\n",
    "    \"gamma\": [0, 1],\n",
    "    \"reg_lambda\": [1],\n",
    "}\n",
    "\n",
    "results = []\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "for params in ParameterGrid(param_grid_xgb):\n",
    "    print(f\"\\nCombination: {params}\")\n",
    "\n",
    "    clf = XGBClassifier(\n",
    "        **params,\n",
    "        objective=\"multi:softmax\",\n",
    "        num_class=len(np.unique(y_tr_enc)),\n",
    "        tree_method=\"hist\",\n",
    "        eval_metric=\"mlogloss\",\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        verbosity=0,\n",
    "    )\n",
    "\n",
    "    # Fit\n",
    "    clf.fit(X_tr, y_tr_enc)\n",
    "\n",
    "    # Validation\n",
    "    y_val_pred = clf.predict(X_va)\n",
    "\n",
    "    macro_f1 = f1_score(y_val_enc, y_val_pred, average=\"macro\")\n",
    "    acc = accuracy_score(y_val_enc, y_val_pred)\n",
    "\n",
    "    print(f\"macro-F1 (val): {macro_f1:.4f} | accuracy (val): {acc:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        **params,\n",
    "        \"val_macro_f1\": macro_f1,\n",
    "        \"val_accuracy\": acc,\n",
    "    })\n",
    "\n",
    "    if macro_f1 > best_score:\n",
    "        best_score = macro_f1\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\nBest hyperparameter configuration (XGBoost):\")\n",
    "print(best_params)\n",
    "print(\"Validation macro-F1:\", best_score)\n",
    "\n",
    "results_df_xgb = pd.DataFrame(results).sort_values(\"val_macro_f1\", ascending=False)\n",
    "print(\"\\nOrdered results:\")\n",
    "print(results_df_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad840c8-81c2-4762-9cf5-4e43dea76920",
   "metadata": {},
   "source": [
    "# PERFORMANCE SUL TEST SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f7b5ce7-c633-42c9-9b7e-7453db9a48e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.load(\"D:/dataset/clip_text_emb_ALL/clip-vit-base-patch32_train_ids_y.npz\", allow_pickle = True)\n",
    "\n",
    "X_tr = train[\"embeddings\"]\n",
    "ids_tr = train[\"ids\"]\n",
    "\n",
    "y_tr_ids = con.sql(\"\"\"SELECT post_id, er_bins2 FROM md1718 WHERE split = 'train'\"\"\").df()\n",
    "y_tr = (\n",
    "    y_tr_ids.set_index(\"post_id\")\n",
    "            .loc[ids_tr, \"er_bins2\"]\n",
    "            .to_numpy()\n",
    ")\n",
    "\n",
    "del train, ids_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20043d9a-61c4-4de8-a466-ab66edebe7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = np.load(\"D:/dataset/clip_text_emb_ALL/clip-vit-base-patch32_val_ids_y.npz\", allow_pickle = True)\n",
    "\n",
    "X_va = val[\"embeddings\"]\n",
    "ids_va = val[\"ids\"]\n",
    "\n",
    "y_va_ids = con.sql(\"\"\"SELECT post_id, er_bins2 FROM md1718 WHERE split = 'validation'\"\"\").df()\n",
    "y_va = (\n",
    "    y_va_ids.set_index(\"post_id\")\n",
    "            .loc[ids_va, \"er_bins2\"]\n",
    "            .to_numpy()\n",
    ")\n",
    "\n",
    "del val, ids_va"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12037293-b120-49ec-aa0b-d50c5d1e949c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trva = np.concatenate((X_tr, X_va), axis = 0)\n",
    "y_trva = np.concatenate((y_tr, y_va), axis = 0)\n",
    "\n",
    "del X_tr, X_va, y_tr, y_va"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eef2327e-c3ac-420d-bbb5-ed0fc97f7c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "577"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.load(\"D:/dataset/clip_text_emb_ALL/clip-vit-base-patch32_test_ids_y.npz\", allow_pickle = True)\n",
    "\n",
    "X_te = test[\"embeddings\"]\n",
    "ids_te = test[\"ids\"]\n",
    "\n",
    "y_te_ids = con.sql(\"\"\"SELECT post_id, er_bins2 FROM md1718 WHERE split = 'test'\"\"\").df()\n",
    "y_te = (\n",
    "    y_te_ids.set_index(\"post_id\")\n",
    "            .loc[ids_te, \"er_bins2\"]\n",
    "            .to_numpy()\n",
    ")\n",
    "\n",
    "del test, ids_te, y_tr_ids, y_te_ids\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "590e8770-b3e9-48fd-a1a4-7fd77c33c82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configuration: GaussianNB()\n",
      "macro-F1 (test): 0.5478 | accuracy (test): 0.5506\n",
      "\n",
      "Configuration: RandomForestClassifier(max_depth=12, max_features=0.05, min_samples_leaf=5,\n",
      "                       n_estimators=80, n_jobs=-1, random_state=42)\n",
      "macro-F1 (test): 0.5705 | accuracy (test): 0.5705\n",
      "\n",
      "Configuration: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.5, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric='mlogloss',\n",
      "              feature_types=None, feature_weights=None, gamma=1,\n",
      "              grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=150, n_jobs=-1, num_class=2, ...)\n",
      "macro-F1 (test): 0.5813 | accuracy (test): 0.5813\n"
     ]
    }
   ],
   "source": [
    "# Convert the labels into numbers\n",
    "le = LabelEncoder()\n",
    "y_tr_enc = le.fit_transform(y_tr)\n",
    "y_te_enc = le.transform(y_te)\n",
    "\n",
    "\n",
    "cfgs = [\n",
    "    GaussianNB(var_smoothing = 1e-09),\n",
    "    RandomForestClassifier(\n",
    "        max_depth=12, max_features=0.05, min_samples_leaf=5, n_estimators=80, n_jobs=-1, random_state=42\n",
    "    ),\n",
    "    XGBClassifier(colsample_bytree = 0.5, gamma = 1, learning_rate = 0.1, max_depth= 6, n_estimators= 150, reg_lambda= 1, subsample= 0.8,\n",
    "        objective=\"multi:softmax\",\n",
    "        num_class=len(np.unique(y_tr_enc)),\n",
    "        tree_method=\"hist\", eval_metric=\"mlogloss\",\n",
    "        n_jobs=-1, random_state=42, verbosity=0\n",
    "    )\n",
    "]\n",
    "\n",
    "for cfg in cfgs:\n",
    "    print(f\"\\nConfiguration: {cfg}\")\n",
    "\n",
    "    # XGB requires a numerical target\n",
    "    if isinstance(cfg, XGBClassifier):\n",
    "        cfg.fit(X_tr, y_tr_enc)\n",
    "        y_te_pred = cfg.predict(X_te)\n",
    "        macro_f1 = f1_score(y_te_enc, y_te_pred, average=\"macro\")\n",
    "        acc = accuracy_score(y_te_enc, y_te_pred)\n",
    "\n",
    "    else:\n",
    "        cfg.fit(X_tr, y_tr)\n",
    "        y_te_pred = cfg.predict(X_te)\n",
    "        macro_f1 = f1_score(y_te, y_te_pred, average=\"macro\")\n",
    "        acc = accuracy_score(y_te, y_te_pred)\n",
    "\n",
    "    print(f\"macro-F1 (test): {macro_f1:.4f} | accuracy (test): {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1552870a-3e15-4f9e-986e-5be339014b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macro-F1 (test): 0.5801 | accuracy (test): 0.5801\n"
     ]
    }
   ],
   "source": [
    "cfg = SGDClassifier(\n",
    "        loss=\"hinge\",\n",
    "        penalty=\"l2\",\n",
    "        alpha = 1e-05,\n",
    "        average = True,\n",
    "        class_weight = None,\n",
    "        random_state=42,\n",
    "        max_iter=1000,\n",
    "        tol=1e-3,\n",
    "    )\n",
    "\n",
    "\n",
    "cfg.fit(X_tr, y_tr)\n",
    "y_te_pred = cfg.predict(X_te)\n",
    "macro_f1 = f1_score(y_te, y_te_pred, average=\"macro\")\n",
    "acc = accuracy_score(y_te, y_te_pred)\n",
    "\n",
    "print(f\"macro-F1 (test): {macro_f1:.4f} | accuracy (test): {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925b17aa-43e4-4695-be97-61620ff9aa73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (CLIP Env)",
   "language": "python",
   "name": "clip_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
