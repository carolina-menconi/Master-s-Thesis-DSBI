{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f99ddbe3-faf2-4609-bf3e-704906e39f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, duckdb, torch, timm, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import LinearSVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import torchvision.transforms as T\n",
    "from pathlib import Path\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "import duckdb, torch\n",
    "from transformers import CLIPModel, CLIPProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1c79aa9-0d0a-4fe2-8353-8808b0281a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up ready\n"
     ]
    }
   ],
   "source": [
    "DB_PATH = \"D:/db/meta.duckdb\"\n",
    "con = duckdb.connect(DB_PATH)\n",
    "try:\n",
    "    con.execute(\"PRAGMA threads=8;\")\n",
    "except duckdb.InvalidInputException:\n",
    "    pass\n",
    "\n",
    "print(\"Set up ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d9d483-f17a-4902-a3d1-2f7b33df2178",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4fee9db-b135-4e8e-8f60-ae76e0be9f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(773497, 512) 773497\n"
     ]
    }
   ],
   "source": [
    "# TEXT\n",
    "train = np.load(\"D:/dataset/clip_text_emb_ALL/clip-vit-base-patch32_train_ids_y.npz\", allow_pickle = True)\n",
    "\n",
    "X_tr_text = train[\"embeddings\"]\n",
    "ids_tr_text = train[\"ids\"]\n",
    "\n",
    "print(X_tr_text.shape, len(ids_tr_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8e800c2-9230-4c13-8379-db4123e06959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(960048, 512) 960048\n"
     ]
    }
   ],
   "source": [
    "# IMAGE\n",
    "train = np.load(\"D:/dataset/clip_img_emb_ALL/clip_vit_b32_train_ALL.npz\", allow_pickle = True)\n",
    "\n",
    "X_tr_img = train[\"feats\"]\n",
    "ids_tr_img = train[\"post_id\"]\n",
    "\n",
    "print(X_tr_img.shape, len(ids_tr_img))\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"post_id\": ids_tr_img\n",
    "})\n",
    "\n",
    "# Inseriamo gli embeddings in un array di oggetti\n",
    "df[\"emb\"] = list(X_tr_img)\n",
    "\n",
    "# Aggrega per post_id\n",
    "agg = df.groupby(\"post_id\")[\"emb\"].apply(lambda x: np.mean(x.tolist(), axis=0))\n",
    "\n",
    "X_tr_img = np.stack(agg.values)\n",
    "post_ids_unique_tr_img = agg.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d7be7f7-6484-40db-8e2c-653d7b4f011c",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_train_final = pd.read_csv(\"D:/dataset/meta_classification/meta_train_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6768fed5-b5b0-4b93-a8af-3b4bb941d594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alignment train\n",
    "\n",
    "ids_text = set(ids_tr_text)\n",
    "ids_img = set(post_ids_unique_tr_img)\n",
    "ids_meta = set(meta_train_final.post_id)\n",
    "\n",
    "ids_tr_common = sorted(list(ids_text & ids_img & ids_meta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc5be904-977d-4a93-9818-020b420352b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text\n",
    "df_text = pd.DataFrame(X_tr_text, index=ids_tr_text)\n",
    "X_tr_text_aligned = df_text.loc[ids_tr_common].values # reordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9e6aed6-b3ed-4bd5-afd4-9cec967ae33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Img\n",
    "df_img_agg = pd.DataFrame(X_tr_img, index=post_ids_unique_tr_img)\n",
    "X_tr_img_aligned = df_img_agg.loc[ids_tr_common].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14f1befd-c705-4508-8be6-3899c8d2c915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata\n",
    "meta_train_aligned = (\n",
    "    meta_train_final.set_index(\"post_id\")\n",
    "                    .loc[ids_tr_common]\n",
    "                    .reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af784166-4053-4f5b-9351-63c3ba72ff0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target\n",
    "y_df = con.execute(\"\"\"\n",
    "    SELECT post_id, er_bins\n",
    "    FROM md1718\n",
    "    WHERE split = 'train'\"\"\").df()\n",
    "\n",
    "\n",
    "y_tr_aligned = (\n",
    "    y_df.set_index(\"post_id\")\n",
    "        .loc[ids_tr_common, \"er_bins\"]\n",
    "        .to_numpy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84052b5d-87a7-4d20-8b3e-3d1d84f24b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tutto allineato correttamente!\n"
     ]
    }
   ],
   "source": [
    "assert X_tr_text_aligned.shape[0] == X_tr_img_aligned.shape[0] == len(y_tr_aligned)\n",
    "print(\"Tutto allineato correttamente!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06215185-32c8-46fc-a92b-f16830c4013c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = np.concatenate((X_tr_text_aligned, X_tr_img_aligned, meta_train_aligned.drop(columns=[\"post_id\"])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30adca8-efb6-4c93-a4cc-ca7ca921ff79",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"D:/dataset/multimodal3/X_tr.npy\", X_tr)\n",
    "np.save(\"D:/dataset/multimodal3/y_tr_5.npy\", y_tr_aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b99206c-acef-45e2-8404-343a20b43982",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"D:/dataset/multimodal3/ids_tr_order.npy\", ids_tr_common)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac93e83-31d6-4cfd-81d8-d595f248a81d",
   "metadata": {},
   "source": [
    "# VALIDATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5861268d-5284-4ce7-bd9b-e688ca148d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(412325, 512) 412325\n"
     ]
    }
   ],
   "source": [
    "# TEXT\n",
    "val = np.load(\"D:/dataset/clip_text_emb_ALL/clip-vit-base-patch32_val_ids_y.npz\", allow_pickle = True)\n",
    "\n",
    "X_va_text = val[\"embeddings\"]\n",
    "ids_va_text = val[\"ids\"]\n",
    "\n",
    "print(X_va_text.shape, len(ids_va_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e60996ba-3d76-4bb6-80cf-28d853178697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(556982, 512) 556982\n"
     ]
    }
   ],
   "source": [
    "# IMAGE\n",
    "val = np.load(\"D:/dataset/clip_img_emb_ALL/clip_vit_b32_validation_ALL.npz\", allow_pickle = True)\n",
    "\n",
    "X_va_img = val[\"feats\"]\n",
    "ids_va_img = val[\"post_id\"]\n",
    "\n",
    "print(X_va_img.shape, len(ids_va_img))\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"post_id\": ids_va_img\n",
    "})\n",
    "\n",
    "# Inseriamo gli embeddings in un array di oggetti\n",
    "df[\"emb\"] = list(X_va_img)\n",
    "\n",
    "# Aggrega per post_id\n",
    "agg = df.groupby(\"post_id\")[\"emb\"].apply(lambda x: np.mean(x.tolist(), axis=0))\n",
    "\n",
    "X_va_img = np.stack(agg.values)\n",
    "post_ids_unique_va_img = agg.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d1b7073-20b5-404e-8436-b438762007d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_val_final = pd.read_csv(\"D:/dataset/meta_classification/meta_val_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00d672c2-61b1-44ba-a34f-84a61f55fd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alignment train\n",
    "\n",
    "ids_text = set(ids_va_text)\n",
    "ids_img = set(post_ids_unique_va_img)\n",
    "ids_meta = set(meta_val_final.post_id)\n",
    "\n",
    "ids_va_common = sorted(list(ids_text & ids_img & ids_meta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce272497-558c-4c4e-9ac5-645fc0fd2eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text\n",
    "df_text = pd.DataFrame(X_va_text, index=ids_va_text)\n",
    "X_va_text_aligned = df_text.loc[ids_va_common].values # reordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "795ff1ce-4c7c-4107-809c-d0a650bc22ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Img\n",
    "df_img_agg = pd.DataFrame(X_va_img, index=post_ids_unique_va_img)\n",
    "X_va_img_aligned = df_img_agg.loc[ids_va_common].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d707862-7220-4e14-a1c9-ac86fc3847b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata\n",
    "meta_val_aligned = (\n",
    "    meta_val_final.set_index(\"post_id\")\n",
    "                    .loc[ids_va_common]\n",
    "                    .reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "980adde1-b9d9-4dbe-bb55-e5bdd3df3427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96ac6615e0db4b14b4fcfc1fb204f521",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# target\n",
    "y_df = con.execute(\"\"\"\n",
    "    SELECT post_id, er_bins\n",
    "    FROM md1718\n",
    "    WHERE split = 'validation'\"\"\").df()\n",
    "\n",
    "\n",
    "y_va_aligned = (\n",
    "    y_df.set_index(\"post_id\")\n",
    "        .loc[ids_va_common, \"er_bins\"]\n",
    "        .to_numpy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cf865c3-956e-4051-a198-2b2c291430f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tutto allineato correttamente!\n"
     ]
    }
   ],
   "source": [
    "assert X_va_text_aligned.shape[0] == X_va_img_aligned.shape[0] == len(y_va_aligned)\n",
    "print(\"Tutto allineato correttamente!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66bdf471-981a-4081-b4cb-010082115c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_va = np.concatenate((X_va_text_aligned, X_va_img_aligned, meta_val_aligned.drop(columns=[\"post_id\"])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22fee71e-b9b4-416c-8d65-d6d474676f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"D:/dataset/multimodal3/X_va.npy\", X_va)\n",
    "np.save(\"D:/dataset/multimodal3/y_va_5.npy\", y_va_aligned)\n",
    "np.save(\"D:/dataset/multimodal3/ids_va_order.npy\", ids_va_common)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaecd49-2587-425d-9bb0-39f77ebbf7c7",
   "metadata": {},
   "source": [
    "# CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c174436c-bcc2-4862-861b-6f17f5d4a15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = np.load(\"D:/dataset/multimodal3/X_tr.npy\", allow_pickle = True).astype(np.float32)\n",
    "X_va = np.load(\"D:/dataset/multimodal3/X_va.npy\", allow_pickle = True).astype(np.float32)\n",
    "\n",
    "y_tr = np.load(\"D:/dataset/multimodal3/y_tr_5.npy\", allow_pickle = True)\n",
    "y_va = np.load(\"D:/dataset/multimodal3/y_va_5.npy\", allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceaeb233-cb79-4248-a69b-7b9528bd0de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination: {'alpha': 1e-05, 'class_weight': None}\n",
      "macro-F1 (val): 0.30567533295750626 | accuracy (val): 0.3439665312556842\n",
      "\n",
      "Combination: {'alpha': 1e-05, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.28707184825034193 | accuracy (val): 0.3439058994725035\n",
      "\n",
      "Combination: {'alpha': 0.0001, 'class_weight': None}\n",
      "macro-F1 (val): 0.3011291696763808 | accuracy (val): 0.3444685624204208\n",
      "\n",
      "Combination: {'alpha': 0.0001, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.2815948284113871 | accuracy (val): 0.34449038986236585\n",
      "\n",
      "Combination: {'alpha': 0.001, 'class_weight': None}\n",
      "macro-F1 (val): 0.29265261111623764 | accuracy (val): 0.3436148669132359\n",
      "\n",
      "Combination: {'alpha': 0.001, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.2747436191445606 | accuracy (val): 0.3426665858242891\n",
      "\n",
      "Combination: {'alpha': 0.01, 'class_weight': None}\n",
      "macro-F1 (val): 0.287368476260512 | accuracy (val): 0.3421863821014976\n",
      "\n",
      "Combination: {'alpha': 0.01, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.27279159830595273 | accuracy (val): 0.34167464985145213\n",
      "\n",
      "Best hyperparameter configuration:\n",
      "{'alpha': 1e-05, 'class_weight': None}\n",
      "Validation macro-F1: 0.30567533295750626\n",
      "\n",
      "Ordered results by macro-F1 (validation):\n",
      "     alpha class_weight  val_macro_f1  val_accuracy\n",
      "0  0.00001         None      0.305675      0.343967\n",
      "2  0.00010         None      0.301129      0.344469\n",
      "4  0.00100         None      0.292653      0.343615\n",
      "6  0.01000         None      0.287368      0.342186\n",
      "1  0.00001     balanced      0.287072      0.343906\n",
      "3  0.00010     balanced      0.281595      0.344490\n",
      "5  0.00100     balanced      0.274744      0.342667\n",
      "7  0.01000     balanced      0.272792      0.341675\n"
     ]
    }
   ],
   "source": [
    "# SGD\n",
    "param_grid = {\n",
    "    \"alpha\": [1e-5, 1e-4, 1e-3, 1e-2],\n",
    "    \"class_weight\": [None, \"balanced\"],\n",
    "}\n",
    "\n",
    "results = []\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    print(f\"\\nCombination: {params}\")\n",
    "\n",
    "    clf = SGDClassifier(\n",
    "        loss=\"hinge\",            \n",
    "        penalty=\"l2\",            \n",
    "        **params,\n",
    "        average = True,\n",
    "        random_state=42,\n",
    "        max_iter=1000,\n",
    "        tol=1e-3,\n",
    "    )\n",
    "\n",
    "    clf.fit(X_tr, y_tr)\n",
    "\n",
    "    y_val_pred = clf.predict(X_va)\n",
    "\n",
    "    macro_f1 = f1_score(y_va, y_val_pred, average=\"macro\")\n",
    "    acc = accuracy_score(y_va, y_val_pred)\n",
    "\n",
    "    print(f\"macro-F1 (val): {macro_f1} | accuracy (val): {acc}\")\n",
    "\n",
    "    results.append({\n",
    "        \"alpha\": params[\"alpha\"],\n",
    "        \"class_weight\": params[\"class_weight\"],\n",
    "        \"val_macro_f1\": macro_f1,\n",
    "        \"val_accuracy\": acc,\n",
    "    })\n",
    "\n",
    "    if macro_f1 > best_score:\n",
    "        best_score = macro_f1\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\nBest hyperparameter configuration:\")\n",
    "print(best_params)\n",
    "print(\"Validation macro-F1:\", best_score)\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(\"val_macro_f1\", ascending=False)\n",
    "print(\"\\nOrdered results by macro-F1 (validation):\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f049210-b353-4d2f-9745-fb0e596220ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination: {'var_smoothing': 1e-09}\n",
      "macro-F1 (val): 0.2571 | accuracy (val): 0.2991\n",
      "\n",
      "Combination: {'var_smoothing': 1e-08}\n",
      "macro-F1 (val): 0.2571 | accuracy (val): 0.2991\n",
      "\n",
      "Combination: {'var_smoothing': 1e-07}\n",
      "macro-F1 (val): 0.2571 | accuracy (val): 0.2992\n",
      "\n",
      "Combination: {'var_smoothing': 1e-06}\n",
      "macro-F1 (val): 0.2571 | accuracy (val): 0.2991\n",
      "\n",
      "Best hyperparameter configuration:\n",
      "{'var_smoothing': 1e-07}\n",
      "Validation macro-F1: 0.2571072970651239\n",
      "\n",
      "Ordered results by macro-F1 (validation):\n",
      "   var_smoothing  val_macro_f1  val_accuracy\n",
      "2   1.000000e-07      0.257107      0.299177\n",
      "0   1.000000e-09      0.257081      0.299150\n",
      "1   1.000000e-08      0.257076      0.299148\n",
      "3   1.000000e-06      0.257070      0.299145\n"
     ]
    }
   ],
   "source": [
    "# NAIVE BAYES - GAUSSIAN\n",
    "param_grid_nb = {\n",
    "    \"var_smoothing\": [1e-9, 1e-8, 1e-7, 1e-6]\n",
    "}\n",
    "\n",
    "results = []\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "for params in ParameterGrid(param_grid_nb):\n",
    "    print(f\"\\nCombination: {params}\")\n",
    "\n",
    "    clf = GaussianNB(**params)\n",
    "\n",
    "    # Fit su TRAIN\n",
    "    clf.fit(X_tr, y_tr)\n",
    "\n",
    "    # Valutazione su VALIDATION\n",
    "    y_val_pred = clf.predict(X_va)\n",
    "\n",
    "    macro_f1 = f1_score(y_va, y_val_pred, average=\"macro\")\n",
    "    acc = accuracy_score(y_va, y_val_pred)\n",
    "\n",
    "    print(f\"macro-F1 (val): {macro_f1:.4f} | accuracy (val): {acc:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        \"var_smoothing\": params[\"var_smoothing\"],\n",
    "        \"val_macro_f1\": macro_f1,\n",
    "        \"val_accuracy\": acc,\n",
    "    })\n",
    "\n",
    "    # Aggiorno il best model in base alla macro-F1\n",
    "    if macro_f1 > best_score:\n",
    "        best_score = macro_f1\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\nBest hyperparameter configuration:\")\n",
    "print(best_params)\n",
    "print(\"Validation macro-F1:\", best_score)\n",
    "\n",
    "# Metto i risultati in un DataFrame per ispezionarli meglio\n",
    "results_df = pd.DataFrame(results).sort_values(\"val_macro_f1\", ascending=False)\n",
    "print(\"\\nOrdered results by macro-F1 (validation):\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d2aba22-27ed-4f1e-af0f-9f03f31aad04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.3151 | accuracy (val): 0.3185\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.3140 | accuracy (val): 0.3177\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.3181 | accuracy (val): 0.3217\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.3170 | accuracy (val): 0.3204\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.3053 | accuracy (val): 0.3079\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.3038 | accuracy (val): 0.3077\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.3045 | accuracy (val): 0.3076\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.3049 | accuracy (val): 0.3090\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.3206 | accuracy (val): 0.3230\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.3207 | accuracy (val): 0.3230\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.3195 | accuracy (val): 0.3222\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.3200 | accuracy (val): 0.3229\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.3108 | accuracy (val): 0.3120\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.3106 | accuracy (val): 0.3126\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.3106 | accuracy (val): 0.3114\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.3120 | accuracy (val): 0.3134\n",
      "\n",
      "Best hyperparameter configuration (Random Forest):\n",
      "{'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "Validation macro-F1: 0.32065263861164517\n",
      "\n",
      "Ordered results by macro-F1 (validation):\n",
      "    n_estimators  max_depth  min_samples_leaf max_features  val_macro_f1  \\\n",
      "9             80         12                 2         0.05      0.320653   \n",
      "8             50         12                 2         0.05      0.320618   \n",
      "11            80         12                 5         0.05      0.319979   \n",
      "10            50         12                 5         0.05      0.319484   \n",
      "2             50         10                 5         0.05      0.318122   \n",
      "3             80         10                 5         0.05      0.317039   \n",
      "0             50         10                 2         0.05      0.315149   \n",
      "1             80         10                 2         0.05      0.313961   \n",
      "15            80         12                 5         sqrt      0.312010   \n",
      "12            50         12                 2         sqrt      0.310847   \n",
      "14            50         12                 5         sqrt      0.310609   \n",
      "13            80         12                 2         sqrt      0.310607   \n",
      "4             50         10                 2         sqrt      0.305309   \n",
      "7             80         10                 5         sqrt      0.304902   \n",
      "6             50         10                 5         sqrt      0.304522   \n",
      "5             80         10                 2         sqrt      0.303816   \n",
      "\n",
      "    val_accuracy  \n",
      "9       0.322952  \n",
      "8       0.322993  \n",
      "11      0.322930  \n",
      "10      0.322171  \n",
      "2       0.321681  \n",
      "3       0.320388  \n",
      "0       0.318458  \n",
      "1       0.317660  \n",
      "15      0.313437  \n",
      "12      0.312031  \n",
      "14      0.311432  \n",
      "13      0.312559  \n",
      "4       0.307876  \n",
      "7       0.309035  \n",
      "6       0.307641  \n",
      "5       0.307726  \n"
     ]
    }
   ],
   "source": [
    "# RANDOM FOREST\n",
    "param_grid_rf = {\n",
    "    \"n_estimators\": [50, 80],\n",
    "    \"max_depth\": [10, 12],\n",
    "    \"min_samples_leaf\": [2, 5],\n",
    "    \"max_features\": [0.05, \"sqrt\"],\n",
    "}\n",
    "\n",
    "results = []\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "for params in ParameterGrid(param_grid_rf):\n",
    "    print(f\"\\nCombination: {params}\")\n",
    "\n",
    "    clf = RandomForestClassifier(\n",
    "        **params,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Fit su TRAIN\n",
    "    clf.fit(X_tr, y_tr)\n",
    "\n",
    "    # Valutazione su VALIDATION\n",
    "    y_val_pred = clf.predict(X_va)\n",
    "\n",
    "    macro_f1 = f1_score(y_va, y_val_pred, average=\"macro\")\n",
    "    acc = accuracy_score(y_va, y_val_pred)\n",
    "\n",
    "    print(f\"macro-F1 (val): {macro_f1:.4f} | accuracy (val): {acc:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        \"n_estimators\": params[\"n_estimators\"],\n",
    "        \"max_depth\": params[\"max_depth\"],\n",
    "        \"min_samples_leaf\": params[\"min_samples_leaf\"],\n",
    "        \"max_features\": params[\"max_features\"],\n",
    "        \"val_macro_f1\": macro_f1,\n",
    "        \"val_accuracy\": acc,\n",
    "    })\n",
    "\n",
    "    # Aggiorno il best model in base alla macro-F1\n",
    "    if macro_f1 > best_score:\n",
    "        best_score = macro_f1\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\nBest hyperparameter configuration (Random Forest):\")\n",
    "print(best_params)\n",
    "print(\"Validation macro-F1:\", best_score)\n",
    "\n",
    "# Metto i risultati in un DataFrame per ispezionarli meglio\n",
    "results_df_rf = pd.DataFrame(results).sort_values(\"val_macro_f1\", ascending=False)\n",
    "print(\"\\nOrdered results by macro-F1 (validation):\")\n",
    "print(results_df_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73452edd-967b-46e5-9c70-1c04ae7f84bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.3250 | accuracy (val): 0.3389\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 150, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.3294 | accuracy (val): 0.3427\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.3336 | accuracy (val): 0.3456\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 150, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.3385 | accuracy (val): 0.3492\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.3250 | accuracy (val): 0.3389\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 150, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.3296 | accuracy (val): 0.3426\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.3341 | accuracy (val): 0.3456\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 150, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.3378 | accuracy (val): 0.3487\n",
      "\n",
      "Best hyperparameter configuration (XGBoost):\n",
      "{'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 150, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "Validation macro-F1: 0.33849489525206383\n",
      "\n",
      "Ordered results:\n",
      "   colsample_bytree  gamma  learning_rate  max_depth  n_estimators  \\\n",
      "3               0.5      0            0.1          6           150   \n",
      "7               0.5      1            0.1          6           150   \n",
      "6               0.5      1            0.1          6           100   \n",
      "2               0.5      0            0.1          6           100   \n",
      "5               0.5      1            0.1          4           150   \n",
      "1               0.5      0            0.1          4           150   \n",
      "0               0.5      0            0.1          4           100   \n",
      "4               0.5      1            0.1          4           100   \n",
      "\n",
      "   reg_lambda  subsample  val_macro_f1  val_accuracy  \n",
      "3           1        0.8      0.338495      0.349232  \n",
      "7           1        0.8      0.337808      0.348732  \n",
      "6           1        0.8      0.334063      0.345574  \n",
      "2           1        0.8      0.333623      0.345567  \n",
      "5           1        0.8      0.329604      0.342642  \n",
      "1           1        0.8      0.329403      0.342659  \n",
      "0           1        0.8      0.324999      0.338864  \n",
      "4           1        0.8      0.324999      0.338864  \n"
     ]
    }
   ],
   "source": [
    "# XGBOOST\n",
    "\n",
    "# Convert the labels into numbers\n",
    "le = LabelEncoder()\n",
    "y_tr_enc = le.fit_transform(y_tr)\n",
    "y_val_enc = le.transform(y_va)\n",
    "\n",
    "\n",
    "param_grid_xgb = {\n",
    "    \"n_estimators\": [100, 150],\n",
    "    \"max_depth\": [4, 6],\n",
    "    \"learning_rate\": [0.1],\n",
    "    \"subsample\": [0.8],\n",
    "    \"colsample_bytree\": [0.5], \n",
    "    \"gamma\": [0, 1], \n",
    "    \"reg_lambda\": [1], \n",
    "}\n",
    "\n",
    "results = []\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "for params in ParameterGrid(param_grid_xgb):\n",
    "    print(f\"\\nCombination: {params}\")\n",
    "\n",
    "    clf = XGBClassifier(\n",
    "        **params,\n",
    "        objective=\"multi:softmax\",\n",
    "        num_class=len(np.unique(y_tr_enc)),\n",
    "        tree_method=\"hist\",\n",
    "        eval_metric=\"mlogloss\",\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        verbosity=0,\n",
    "    )\n",
    "\n",
    "    # Fit\n",
    "    clf.fit(X_tr, y_tr_enc)\n",
    "\n",
    "    # Validation\n",
    "    y_val_pred = clf.predict(X_va)\n",
    "\n",
    "    macro_f1 = f1_score(y_val_enc, y_val_pred, average=\"macro\")\n",
    "    acc = accuracy_score(y_val_enc, y_val_pred)\n",
    "\n",
    "    print(f\"macro-F1 (val): {macro_f1:.4f} | accuracy (val): {acc:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        **params,\n",
    "        \"val_macro_f1\": macro_f1,\n",
    "        \"val_accuracy\": acc,\n",
    "    })\n",
    "\n",
    "    if macro_f1 > best_score:\n",
    "        best_score = macro_f1\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\nBest hyperparameter configuration (XGBoost):\")\n",
    "print(best_params)\n",
    "print(\"Validation macro-F1:\", best_score)\n",
    "\n",
    "results_df_xgb = pd.DataFrame(results).sort_values(\"val_macro_f1\", ascending=False)\n",
    "print(\"\\nOrdered results:\")\n",
    "print(results_df_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd977ab-47de-4a8f-b241-61c01875fd7b",
   "metadata": {},
   "source": [
    "# PERFORMANCE SUL TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "472ae804-a4f1-4613-aaa9-3a3022f62fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(423604, 512) 423604\n"
     ]
    }
   ],
   "source": [
    "# TEXT\n",
    "test = np.load(\"D:/dataset/clip_text_emb_ALL/clip-vit-base-patch32_test_ids_y.npz\", allow_pickle = True)\n",
    "\n",
    "X_te_text = test[\"embeddings\"]\n",
    "ids_te_text = test[\"ids\"]\n",
    "\n",
    "print(X_te_text.shape, len(ids_te_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b180701a-8fae-4cdf-be5c-ac1a496eb38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(588557, 512) 588557\n"
     ]
    }
   ],
   "source": [
    "# IMAGE\n",
    "test = np.load(\"D:/dataset/clip_img_emb_ALL/clip_vit_b32_test_ALL.npz\", allow_pickle = True)\n",
    "\n",
    "X_te_img = test[\"feats\"]\n",
    "ids_te_img = test[\"post_id\"]\n",
    "\n",
    "print(X_te_img.shape, len(ids_te_img))\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"post_id\": ids_te_img\n",
    "})\n",
    "\n",
    "# Inseriamo gli embeddings in un array di oggetti\n",
    "df[\"emb\"] = list(X_te_img)\n",
    "\n",
    "# Aggrega per post_id\n",
    "agg = df.groupby(\"post_id\")[\"emb\"].apply(lambda x: np.mean(x.tolist(), axis=0))\n",
    "\n",
    "X_te_img = np.stack(agg.values)\n",
    "post_ids_unique_te_img = agg.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8592a39d-26a3-45a4-874b-dc149998396e",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_te_final = pd.read_csv(\"D:/dataset/meta_classification/meta_test_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df1b029a-5619-4ad9-ba8c-0730acb661dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alignment train\n",
    "\n",
    "ids_text = set(ids_te_text)\n",
    "ids_img = set(post_ids_unique_te_img)\n",
    "ids_meta = set(meta_te_final.post_id)\n",
    "\n",
    "ids_te_common = sorted(list(ids_text & ids_img & ids_meta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6ee3452-63df-45f3-a42d-a819c753842d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text\n",
    "df_text = pd.DataFrame(X_te_text, index=ids_te_text)\n",
    "X_te_text_aligned = df_text.loc[ids_te_common].values # reordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "811d7392-0d18-48bd-9207-b71c80a75af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Img\n",
    "df_img_agg = pd.DataFrame(X_te_img, index=post_ids_unique_te_img)\n",
    "X_te_img_aligned = df_img_agg.loc[ids_te_common].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28a74eef-353d-4e4b-a17e-575a6410ccf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata\n",
    "meta_te_aligned = (\n",
    "    meta_te_final.set_index(\"post_id\")\n",
    "                    .loc[ids_te_common]\n",
    "                    .reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d661f59-480d-4f5f-814f-3bbb2c4eb086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target\n",
    "y_df = con.execute(\"\"\"\n",
    "    SELECT post_id, er_bins\n",
    "    FROM md1718\n",
    "    WHERE split = 'test'\"\"\").df()\n",
    "\n",
    "\n",
    "y_te_aligned = (\n",
    "    y_df.set_index(\"post_id\")\n",
    "        .loc[ids_te_common, \"er_bins\"]\n",
    "        .to_numpy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf1a951e-1250-43d9-afa3-5b717155035e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tutto allineato correttamente!\n"
     ]
    }
   ],
   "source": [
    "assert X_te_text_aligned.shape[0] == X_te_img_aligned.shape[0] == len(y_te_aligned)\n",
    "print(\"Tutto allineato correttamente!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cbdeb42-14ba-4d0a-ab2c-48d67c2e861e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_te = np.concatenate((X_te_text_aligned, X_te_img_aligned, meta_te_aligned.drop(columns=[\"post_id\"])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9799914c-7399-48f1-aeb1-8ebf6ba9f5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"D:/dataset/multimodal3/X_te.npy\", X_te)\n",
    "np.save(\"D:/dataset/multimodal3/y_te_5.npy\", y_te_aligned)\n",
    "np.save(\"D:/dataset/multimodal3/ids_te_order.npy\", ids_te_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d28d1432-74a9-4773-bb96-64ec1555d754",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = np.load(\"D:/dataset/multimodal3/X_tr.npy\", allow_pickle = True).astype(np.float32)\n",
    "y_tr = np.load(\"D:/dataset/multimodal3/y_tr_5.npy\", allow_pickle = True)\n",
    "\n",
    "X_va = np.load(\"D:/dataset/multimodal3/X_va.npy\", allow_pickle = True).astype(np.float32)\n",
    "y_va = np.load(\"D:/dataset/multimodal3/y_va_5.npy\", allow_pickle = True)\n",
    "\n",
    "X_trva = np.concatenate((X_tr, X_va), axis = 0)\n",
    "y_trva = np.concatenate((y_tr, y_va), axis = 0)\n",
    "\n",
    "np.save(\"D:/dataset/multimodal3/X_trva.npy\", X_trva)\n",
    "np.save(\"D:/dataset/multimodal3/X_trva_5.npy\", X_trva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3ddc73-5454-4fb2-b135-b409fd3a9417",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = np.load(\"D:/dataset/multimodal3/X_trva.npy\", allow_pickle = True).astype(np.float32)\n",
    "y_tr = np.load(\"D:/dataset/multimodal3/y_trva_5.npy\", allow_pickle = True)\n",
    "\n",
    "X_te = np.load(\"D:/dataset/multimodal3/X_te.npy\", allow_pickle = True).astype(np.float32)\n",
    "y_te = np.load(\"D:/dataset/multimodal3/y_te_5.npy\", allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f364153-6a1c-47ac-a746-137c4a2964b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macro-F1 (test): 0.3041 | accuracy (test): 0.3467\n"
     ]
    }
   ],
   "source": [
    "cfg = SGDClassifier(\n",
    "        loss=\"hinge\",\n",
    "        penalty=\"l2\",\n",
    "        alpha = 1e-05,\n",
    "        average = True,\n",
    "        class_weight = None,\n",
    "        random_state=42,\n",
    "        max_iter=1000,\n",
    "        tol=1e-3,\n",
    "    )\n",
    "\n",
    "\n",
    "cfg.fit(X_tr, y_tr)\n",
    "y_te_pred = cfg.predict(X_te)\n",
    "macro_f1 = f1_score(y_te, y_te_pred, average=\"macro\")\n",
    "acc = accuracy_score(y_te, y_te_pred)\n",
    "\n",
    "print(f\"macro-F1 (test): {macro_f1:.4f} | accuracy (test): {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc8f6eb0-fde1-48a6-86e5-5356f06d5b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configuration: RandomForestClassifier(max_depth=12, max_features=0.05, min_samples_leaf=2,\n",
      "                       n_estimators=80, n_jobs=-1, random_state=42)\n",
      "macro-F1 (train): 0.3194 | accuracy (train): 0.3232\n",
      "\n",
      "Configuration: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.5, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric='mlogloss',\n",
      "              feature_types=None, feature_weights=None, gamma=0,\n",
      "              grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=150, n_jobs=-1, num_class=5, ...)\n",
      "macro-F1 (train): 0.3381 | accuracy (train): 0.3507\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y_tr_enc = le.fit_transform(y_tr)\n",
    "y_te_enc = le.transform(y_te)\n",
    "\n",
    "cfgs = [\n",
    "    RandomForestClassifier(\n",
    "        max_depth=12, max_features=0.05, min_samples_leaf=2, n_estimators=80, n_jobs=-1, random_state=42\n",
    "    ),\n",
    "    XGBClassifier(colsample_bytree = 0.5, gamma = 0, learning_rate = 0.1, max_depth= 6, n_estimators= 150, reg_lambda= 1, subsample= 0.8,\n",
    "        objective=\"multi:softmax\",\n",
    "        num_class=len(np.unique(y_tr_enc)),\n",
    "        tree_method=\"hist\", eval_metric=\"mlogloss\",\n",
    "        n_jobs=-1, random_state=42, verbosity=0\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "for cfg in cfgs:\n",
    "    print(f\"\\nConfiguration: {cfg}\")\n",
    "\n",
    "    # XGB requires a numerical target\n",
    "    if isinstance(cfg, XGBClassifier):\n",
    "        cfg.fit(X_tr, y_tr_enc)\n",
    "        y_te_pred = cfg.predict(X_te)\n",
    "        macro_f1 = f1_score(y_te_enc, y_te_pred, average=\"macro\")\n",
    "        acc = accuracy_score(y_te_enc, y_te_pred)\n",
    "\n",
    "    else:\n",
    "        cfg.fit(X_tr, y_tr)\n",
    "        y_te_pred = cfg.predict(X_te)\n",
    "        macro_f1 = f1_score(y_te, y_te_pred, average=\"macro\")\n",
    "        acc = accuracy_score(y_te, y_te_pred)\n",
    "\n",
    "    print(f\"macro-F1 (train): {macro_f1:.4f} | accuracy (train): {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d50d5703-7115-4e8e-80f3-19d36336fc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macro-F1 (test): 0.2589 | accuracy (test): 0.3027\n"
     ]
    }
   ],
   "source": [
    "# TEST SU GAUSSIAN NAIVE BAYES\n",
    "\n",
    "batch_size = 256\n",
    "classes = np.unique(y_tr)\n",
    "\n",
    "clf = GaussianNB(var_smoothing = 1e-07)\n",
    "\n",
    "\n",
    "# Fit the model using minibatch for memory\n",
    "for start in range(0, X_tr.shape[0], batch_size):\n",
    "    # print(f\"Batch {start} fit\")\n",
    "    end = min(start + batch_size, X_tr.shape[0])\n",
    "\n",
    "    Xb = X_tr[start:end]\n",
    "    yb = y_tr[start:end]\n",
    "\n",
    "    if start == 0:\n",
    "        clf.partial_fit(Xb, yb, classes=classes)\n",
    "    else:\n",
    "        clf.partial_fit(Xb, yb)\n",
    "\n",
    "    del Xb, yb\n",
    "    gc.collect()\n",
    "\n",
    "# Predict using minibatches\n",
    "y_te_pred = []\n",
    "\n",
    "for start in range(0, X_te.shape[0], batch_size):\n",
    "    # print(f\"Batch {start} predict\")\n",
    "    end = min(start + batch_size, X_te.shape[0])\n",
    "\n",
    "    Xb = X_te[start:end]\n",
    "    y_te_pred.append(clf.predict(Xb))\n",
    "\n",
    "    del Xb\n",
    "    gc.collect()\n",
    "\n",
    "y_te_pred = np.concatenate(y_te_pred)\n",
    "\n",
    "macro_f1 = f1_score(y_te, y_te_pred, average=\"macro\")\n",
    "acc = accuracy_score(y_te, y_te_pred)\n",
    "\n",
    "print(f\"macro-F1 (test): {macro_f1:.4f} | accuracy (test): {acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (CLIP Env)",
   "language": "python",
   "name": "clip_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
