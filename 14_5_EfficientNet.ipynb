{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae083fdc-44f6-4204-a9ab-979031ad259a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, duckdb, torch, timm, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import torchvision.transforms as T\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e430f4d-dbc4-407f-9faf-c1b04be1d0db",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a5feb8f-2655-46fb-993b-fb32edcba32e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51539f715659418ebb340c768e17d9e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Campione estratto da DuckDB: 5000 righe\n"
     ]
    }
   ],
   "source": [
    "IMAGE_FOLDER = r\"D:\\dataset\\images_224_rgb\"\n",
    "\n",
    "DB_PATH = \"D:/db/meta.duckdb\"\n",
    "\n",
    "SAMPLE_SIZE = 5000\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "con = duckdb.connect(DB_PATH)\n",
    "\n",
    "query = f\"\"\"\n",
    "    WITH imgs AS (\n",
    "        SELECT\n",
    "            post_id,\n",
    "            full_image_file,\n",
    "            ROW_NUMBER() OVER (PARTITION BY post_id ORDER BY full_image_file) AS rn\n",
    "        FROM images_manifest1718_clean\n",
    "        WHERE full_image_file IS NOT NULL\n",
    "    )\n",
    "    SELECT\n",
    "        imgs.full_image_file AS image_filename,\n",
    "        m.er_bins\n",
    "    FROM md1718 m\n",
    "    JOIN imgs\n",
    "        ON m.post_id = imgs.post_id\n",
    "    WHERE imgs.rn = 1\n",
    "    ORDER BY random()\n",
    "    LIMIT {SAMPLE_SIZE}\n",
    "\"\"\"\n",
    "\n",
    "df = con.execute(query).df()\n",
    "print(f\"Campione estratto da DuckDB: {len(df)} righe\")\n",
    "\n",
    "# Numeric labels\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df['er_bins'])\n",
    "\n",
    "# Fixed split\n",
    "indices = np.arange(len(df))\n",
    "train_idx, test_idx = train_test_split(\n",
    "    indices,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32064437-1cf7-4582-8eb0-92d814446661",
   "metadata": {},
   "outputs": [],
   "source": [
    "EFF_MODELS = {\n",
    "    \"b0\": \"efficientnet_b0\",\n",
    "    \"b3\": \"efficientnet_b3\",\n",
    "}\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a05d51a-0a33-4785-ac6e-575a60a349a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_image_embeddings(model_name, model_id, df):\n",
    "    print(f\"\\nLoading EfficientNet {model_name}...\")\n",
    "\n",
    "    model = timm.create_model(model_id, pretrained=True, num_classes=0)  \n",
    "    model.eval()\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "\n",
    "    embeddings = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for filename in df[\"image_filename\"]:\n",
    "        path = os.path.join(IMAGE_FOLDER, filename)\n",
    "\n",
    "        try:\n",
    "            img = Image.open(path).convert(\"RGB\")\n",
    "        except:\n",
    "            # fallback: random noise if image missing\n",
    "            img = Image.fromarray(np.zeros((224,224,3), dtype=np.uint8))\n",
    "\n",
    "        tensor = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            emb = model(tensor).cpu().numpy().flatten()\n",
    "\n",
    "        embeddings.append(emb)\n",
    "\n",
    "    embeddings = np.vstack(embeddings)\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed = end_time - start_time\n",
    "\n",
    "    print(f\"Extraction time for {model_name}: {elapsed:.2f} s\")\n",
    "    print(f\"Embedding dimension: {embeddings.shape[1]}\")\n",
    "\n",
    "    return embeddings, elapsed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9caec216-a9fc-41cd-a785-d92142dcf94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_classifiers(X, y, train_idx, test_idx):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # Linear SVM\n",
    "    svm = LinearSVC(random_state=RANDOM_STATE)\n",
    "    t0 = time.time()\n",
    "    svm.fit(X_train, y_train)\n",
    "    t1 = time.time()\n",
    "\n",
    "    t2 = time.time()\n",
    "    pred = svm.predict(X_test)\n",
    "    t3 = time.time()\n",
    "\n",
    "    results.append({\n",
    "        \"Classifier\": \"LinearSVM\",\n",
    "        \"Train Time (s)\": t1 - t0,\n",
    "        \"Inference Time (s)\": t3 - t2,\n",
    "        \"Accuracy\": accuracy_score(y_test, pred),\n",
    "        \"F1-macro\": f1_score(y_test, pred, average=\"macro\")\n",
    "    })\n",
    "\n",
    "    # Gaussian NB\n",
    "    nb = GaussianNB()\n",
    "    t0 = time.time()\n",
    "    nb.fit(X_train, y_train)\n",
    "    t1 = time.time()\n",
    "\n",
    "    t2 = time.time()\n",
    "    pred = nb.predict(X_test)\n",
    "    t3 = time.time()\n",
    "\n",
    "    results.append({\n",
    "        \"Classifier\": \"NaiveBayes\",\n",
    "        \"Train Time (s)\": t1 - t0,\n",
    "        \"Inference Time (s)\": t3 - t2,\n",
    "        \"Accuracy\": accuracy_score(y_test, pred),\n",
    "        \"F1-macro\": f1_score(y_test, pred, average=\"macro\")\n",
    "    })\n",
    "\n",
    "    # XGBoost\n",
    "    xgb = XGBClassifier(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective=\"multi:softmax\",\n",
    "        eval_metric=\"mlogloss\",\n",
    "        tree_method=\"auto\",\n",
    "        n_jobs=-1,\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "\n",
    "    t0 = time.time()\n",
    "    xgb.fit(X_train, y_train)\n",
    "    t1 = time.time()\n",
    "\n",
    "    t2 = time.time()\n",
    "    pred = xgb.predict(X_test)\n",
    "    t3 = time.time()\n",
    "\n",
    "    results.append({\n",
    "        \"Classifier\": \"XGBoost\",\n",
    "        \"Train Time (s)\": t1 - t0,\n",
    "        \"Inference Time (s)\": t3 - t2,\n",
    "        \"Accuracy\": accuracy_score(y_test, pred),\n",
    "        \"F1-macro\": f1_score(y_test, pred, average=\"macro\")\n",
    "    })\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "352d4131-4a0f-4eb2-a7e3-a2ab16d7b1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading EfficientNet b0...\n",
      "Extraction time for b0: 731.12 s\n",
      "Embedding dimension: 1280\n",
      "\n",
      "Loading EfficientNet b3...\n",
      "Extraction time for b3: 665.18 s\n",
      "Embedding dimension: 1536\n",
      "\n",
      " FINAL RESULTS\n",
      "Encoder  Embedding Time (s) Classifier  Train Time (s)  Inference Time (s)  Accuracy  F1-macro\n",
      "     b0          731.115472  LinearSVM       19.204432            0.032499     0.233  0.232503\n",
      "     b0          731.115472    XGBoost      231.400897            0.034284     0.230  0.227878\n",
      "     b3          665.178898  LinearSVM       34.021003            0.015665     0.222  0.221060\n",
      "     b3          665.178898    XGBoost      279.483445            0.031693     0.218  0.215283\n",
      "     b3          665.178898 NaiveBayes        0.055974            0.103390     0.222  0.212353\n",
      "     b0          731.115472 NaiveBayes        0.045640            0.064164     0.216  0.199012\n"
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "\n",
    "for name, model_id in EFF_MODELS.items():\n",
    "    X, emb_time = extract_image_embeddings(name, model_id, df)\n",
    "    clf_results = benchmark_classifiers(X, y, train_idx, test_idx)\n",
    "\n",
    "    for r in clf_results:\n",
    "        all_results.append({\n",
    "            \"Encoder\": name,\n",
    "            \"Embedding Time (s)\": emb_time,\n",
    "            **r\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df = results_df.sort_values([\"F1-macro\", \"Accuracy\"], ascending=False)\n",
    "\n",
    "print(\"\\n FINAL RESULTS\")\n",
    "print(results_df.to_string(index=False))\n",
    "results_df.to_csv(\"classification_image_benchmark_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc4af78-eddc-445c-86eb-0047b6609bdd",
   "metadata": {},
   "source": [
    "# EMBEDDINGS EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9555f32b-118f-412d-b5ec-bcace5b37e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up ready\n"
     ]
    }
   ],
   "source": [
    "DB_PATH = \"D:/db/meta.duckdb\"\n",
    "con = duckdb.connect(DB_PATH)\n",
    "try:\n",
    "    con.execute(\"PRAGMA threads=8;\")\n",
    "except duckdb.InvalidInputException:\n",
    "    pass\n",
    "\n",
    "print(\"Set up ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7a3d828-c9b4-4cbd-8ad1-1b7b4c2c24f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cad46cd1bb244238983c0a21171f1bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<_duckdb.DuckDBPyConnection at 0x2277cbe2730>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# con.execute(\"\"\"CREATE OR REPLACE TABLE img_splits AS\n",
    "# SELECT m.post_id, m.split, i.full_image_file\n",
    "# FROM md1718 m\n",
    "# JOIN images_manifest1718_clean i ON m.post_id = i.post_id\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26bdb2be-19c2-40ec-94aa-f494a03ba515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>n_images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>588557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>validation</td>\n",
       "      <td>556982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>960048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        split  n_images\n",
       "0        test    588557\n",
       "1  validation    556982\n",
       "2       train    960048"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.sql(\"\"\"SELECT split, COUNT(*) AS n_images\n",
    "FROM img_splits\n",
    "GROUP BY split\"\"\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8479beeb-bc1d-4f0a-8c27-6a1f24017cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data config: {'input_size': (3, 224, 224), 'interpolation': 'bicubic', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225), 'crop_pct': 0.875, 'crop_mode': 'center'}\n"
     ]
    }
   ],
   "source": [
    "# 1) Configuration and set up\n",
    "\n",
    "# Define the model used\n",
    "MODEL_NAME = \"efficientnet_b0\"\n",
    "\n",
    "# Define the pre-trained backbone used to extract image features:\n",
    "# - num_classes = 0 allows to return a feature vector\n",
    "# - global_pool='avg' applies a global average on the last spatial layer to get a single vector 1Ã—1280\n",
    "# - pretrained = True uploads ImageNet pre-trained weights\n",
    "backbone = timm.create_model(MODEL_NAME, pretrained=True, num_classes=0, global_pool='avg')\n",
    "\n",
    "# Retrieve the model's data configuration, and store it as a dictionary, as the model expects images with a certain aspect, as it has been trained on ImageNet\n",
    "data_cfg = resolve_data_config({}, model=backbone)\n",
    "\n",
    "# Define the transformations that needs to be made for the images to align with the model requests\n",
    "eval_tfms  = create_transform(**data_cfg, is_training=False)\n",
    "\n",
    "# Freeze weights (requires_grad=False) to just extract the embeddings and not train it on the images\n",
    "for p in backbone.parameters():\n",
    "    p.requires_grad = False\n",
    "backbone.eval()\n",
    "\n",
    "# Set the device that will be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "backbone = backbone.to(device)\n",
    "feat_dim = backbone.num_features\n",
    "print(f\"Backbone {MODEL_NAME} | feat_dim={feat_dim} | device={device}\")\n",
    "\n",
    "print(f\"Backbone {MODEL_NAME} | feat_dim={feat_dim} | device={device}\")\n",
    "print(\"Data config:\", data_cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f7b2e3a-470f-4802-9576-25241642fa5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of files and splits extracted\n",
      "0    D:/dataset/images_224_rgb\\breemarieblog-190483...\n",
      "1    D:/dataset/images_224_rgb\\breemarieblog-190535...\n",
      "2    D:/dataset/images_224_rgb\\breemarieblog-190684...\n",
      "Name: full_image_file, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 2.1) Load data, extend the full_image_file with the entire image path\n",
    "\n",
    "df = con.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM img_splits\n",
    "\"\"\").df()\n",
    "print(\"List of files and splits extracted\")\n",
    "con.close()\n",
    "\n",
    "IMG_DIR = 'D:/dataset/images_224_rgb'\n",
    "df[\"full_image_file\"] = df[\"full_image_file\"].apply(lambda x: os.path.join(IMG_DIR, x))\n",
    "\n",
    "# Check\n",
    "print(df[\"full_image_file\"].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a496e2ca-d640-4c29-b332-a6716190db1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train=960048 | val=556982 | test=588557\n"
     ]
    }
   ],
   "source": [
    "# 2.2) Split and check\n",
    "train_df = df[df[\"split\"]==\"train\"].reset_index(drop=True)\n",
    "val_df   = df[df[\"split\"]==\"validation\"].reset_index(drop=True)\n",
    "test_df  = df[df[\"split\"]==\"test\"].reset_index(drop=True)\n",
    "print(f\"train={len(train_df)} | val={len(val_df)} | test={len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd2fbdc0-0702-4898-a42f-33d14389f8cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36042f5e-dcf9-4c58-86d3-def2afb6f302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backbone: efficientnet_b0 | feature dim = 1280 | device = cpu\n",
      "Batch features shape: torch.Size([32, 1280]) (es. 32 x 1280)\n",
      "Tempo forward batch: 1.374s  |  ~23.3 img/s\n"
     ]
    }
   ],
   "source": [
    "# 3.1 Test the model and observe if it works correctly\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Set of training samples, retrive the image path \n",
    "train_samples = train_df[\"full_image_file\"].tolist()\n",
    "print(\"Samples ready\")\n",
    "\n",
    "def make_loader(paths, transform, batch_size=32, shuffle=False):\n",
    "    def _collate(batch):\n",
    "        imgs = []\n",
    "        for path in batch:\n",
    "            img = Image.open(path).convert(\"RGB\")\n",
    "            img = transform(img)\n",
    "            imgs.append(img)\n",
    "        return torch.stack(imgs)\n",
    "    \n",
    "    return DataLoader(paths, batch_size=batch_size, shuffle=shuffle,\n",
    "                      num_workers=0, pin_memory=True, collate_fn=_collate)\n",
    "\n",
    "train_loader = make_loader(train_samples, eval_tfms, batch_size=BATCH_SIZE, shuffle=False)\n",
    "print(\"DataLoader ready\")\n",
    "\n",
    "# Test a batch from the train_loader and check if it the backbone passes without errors, and with correct form\n",
    "imgs = next(iter(train_loader))\n",
    "imgs = imgs.to(device, non_blocking=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    t0 = time.time()\n",
    "    feats = backbone(imgs)\n",
    "    dt = time.time() - t0\n",
    "\n",
    "print(f\"Batch features shape: {feats.shape}\")\n",
    "print(f\"Time forward batch: {dt:.3f}s  |  ~{imgs.size(0)/dt:.1f} img/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ceed272-4c90-48fd-b53c-3c7c02dd9dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backbone efficientnet_b0 | feat_dim=1280 | device=cpu\n"
     ]
    }
   ],
   "source": [
    "# 3.2 Define functions to extract images, embeddings and save them\n",
    "\n",
    "# Build samples: (path, post_id)\n",
    "def build_samples(df, path_col=\"full_image_file\"):\n",
    "    return list(zip(df[path_col].tolist(), df[\"post_id\"].tolist()))\n",
    "\n",
    "# Loader con post_id + resume\n",
    "def make_loader_with_ids(samples, transform, batch_size=64, shuffle=False, pin_memory=True, start_index=0):\n",
    "    if start_index > 0:\n",
    "        samples = samples[start_index:]\n",
    "\n",
    "    def _collate(batch):\n",
    "        imgs = []\n",
    "        pids = []\n",
    "        for path, pid in batch:\n",
    "            img = Image.open(path).convert(\"RGB\")\n",
    "            img = transform(img)\n",
    "            imgs.append(img)\n",
    "            pids.append(pid)\n",
    "        return torch.stack(imgs), pids\n",
    "\n",
    "    return DataLoader(samples,\n",
    "                      batch_size=batch_size,\n",
    "                      shuffle=shuffle,\n",
    "                      num_workers=0,\n",
    "                      pin_memory=pin_memory,\n",
    "                      collate_fn=_collate)\n",
    "\n",
    "def extract_and_save(\n",
    "    split_name,\n",
    "    samples,\n",
    "    transform,\n",
    "    out_dir=\"emb_cache\",\n",
    "    shard_size=20000,\n",
    "    batch_size=64,\n",
    "):\n",
    "    \n",
    "    out_dir = Path(out_dir)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    prefix = f\"{MODEL_NAME}_{split_name}\"\n",
    "\n",
    "    n = len(samples)\n",
    "    print(f\"[{split_name}] Totale esempi: {n}\")\n",
    "\n",
    "    shard_files = []\n",
    "\n",
    "    # loop a shard di samples\n",
    "    for start in range(0, n, shard_size):\n",
    "        shard_samples = samples[start:start + shard_size]\n",
    "        shard_path = out_dir / f\"{prefix}_{start:07d}.npz\"\n",
    "\n",
    "        if shard_path.exists():\n",
    "            print(f\"[skip] {shard_path.name}\")\n",
    "            shard_files.append(shard_path)\n",
    "            continue\n",
    "\n",
    "        loader = make_loader_with_ids(\n",
    "            shard_samples,\n",
    "            transform,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "        )\n",
    "\n",
    "        feats_buf = []\n",
    "        id_buf = []\n",
    "\n",
    "        t0 = time.time()\n",
    "        with torch.no_grad():\n",
    "            for imgs, pids in loader:\n",
    "                imgs = imgs.to(device, non_blocking=True)\n",
    "                feats = backbone(imgs).float().cpu().numpy()\n",
    "\n",
    "                feats_buf.append(feats)\n",
    "                id_buf.extend(pids)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.synchronize()\n",
    "\n",
    "        F = np.concatenate(feats_buf, axis=0)\n",
    "        I = np.array(id_buf, dtype=object)\n",
    "\n",
    "        dt = time.time() - t0\n",
    "        rate = F.shape[0] / max(dt, 1e-9)\n",
    "\n",
    "        np.savez_compressed(\n",
    "            shard_path,\n",
    "            feats=F,\n",
    "            post_id=I,\n",
    "            model=MODEL_NAME,\n",
    "            feat_dim=feat_dim,\n",
    "        )\n",
    "\n",
    "        print(f\"[save] {shard_path.name} | {F.shape[0]} esempi | {dt:.1f}s | {rate:.1f} img/s\")\n",
    "        shard_files.append(shard_path)\n",
    "\n",
    "    print(f\"[{split_name}] Concateno {len(shard_files)} shard...\")\n",
    "\n",
    "    feats_all = []\n",
    "    ids_all = []\n",
    "\n",
    "    for f in shard_files:\n",
    "        data = np.load(f, allow_pickle=True)\n",
    "        feats_all.append(data[\"feats\"])\n",
    "        ids_all.append(data[\"post_id\"])\n",
    "\n",
    "    F_all = np.concatenate(feats_all, axis=0)\n",
    "    I_all = np.concatenate(ids_all, axis=0)\n",
    "\n",
    "    all_path = out_dir / f\"{prefix}_ALL.npz\"\n",
    "    np.savez_compressed(\n",
    "        all_path,\n",
    "        feats=F_all,\n",
    "        post_id=I_all,\n",
    "        model=MODEL_NAME,\n",
    "        feat_dim=feat_dim,\n",
    "    )\n",
    "\n",
    "    print(f\"[{split_name}] File unico: {all_path.name} | {F_all.shape[0]} esempi totali\")\n",
    "\n",
    "    return F_all, I_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c944b96f-3dc5-444c-84f3-fc6cfdfe54c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] Totale esempi: 960048\n",
      "[save] efficientnet_b0_train_0000000.npz | 20000 esempi | 1213.8s | 16.5 img/s\n",
      "[save] efficientnet_b0_train_0020000.npz | 20000 esempi | 1219.2s | 16.4 img/s\n",
      "[save] efficientnet_b0_train_0040000.npz | 20000 esempi | 1217.8s | 16.4 img/s\n",
      "[save] efficientnet_b0_train_0060000.npz | 20000 esempi | 1210.4s | 16.5 img/s\n",
      "[save] efficientnet_b0_train_0080000.npz | 20000 esempi | 1232.5s | 16.2 img/s\n",
      "[save] efficientnet_b0_train_0100000.npz | 20000 esempi | 1229.9s | 16.3 img/s\n",
      "[save] efficientnet_b0_train_0120000.npz | 20000 esempi | 1226.4s | 16.3 img/s\n",
      "[save] efficientnet_b0_train_0140000.npz | 20000 esempi | 1235.6s | 16.2 img/s\n",
      "[save] efficientnet_b0_train_0160000.npz | 20000 esempi | 1209.2s | 16.5 img/s\n",
      "[save] efficientnet_b0_train_0180000.npz | 20000 esempi | 1208.5s | 16.5 img/s\n",
      "[save] efficientnet_b0_train_0200000.npz | 20000 esempi | 1212.2s | 16.5 img/s\n",
      "[save] efficientnet_b0_train_0220000.npz | 20000 esempi | 1218.3s | 16.4 img/s\n",
      "[save] efficientnet_b0_train_0240000.npz | 20000 esempi | 1206.9s | 16.6 img/s\n",
      "[save] efficientnet_b0_train_0260000.npz | 20000 esempi | 1210.5s | 16.5 img/s\n",
      "[save] efficientnet_b0_train_0280000.npz | 20000 esempi | 1210.5s | 16.5 img/s\n",
      "[save] efficientnet_b0_train_0300000.npz | 20000 esempi | 1208.3s | 16.6 img/s\n",
      "[save] efficientnet_b0_train_0320000.npz | 20000 esempi | 1203.1s | 16.6 img/s\n",
      "[save] efficientnet_b0_train_0340000.npz | 20000 esempi | 1205.8s | 16.6 img/s\n",
      "[save] efficientnet_b0_train_0360000.npz | 20000 esempi | 1202.0s | 16.6 img/s\n",
      "[save] efficientnet_b0_train_0380000.npz | 20000 esempi | 1212.4s | 16.5 img/s\n",
      "[save] efficientnet_b0_train_0400000.npz | 20000 esempi | 1219.0s | 16.4 img/s\n",
      "[save] efficientnet_b0_train_0420000.npz | 20000 esempi | 1203.9s | 16.6 img/s\n",
      "[save] efficientnet_b0_train_0440000.npz | 20000 esempi | 1203.0s | 16.6 img/s\n",
      "[save] efficientnet_b0_train_0460000.npz | 20000 esempi | 1222.4s | 16.4 img/s\n",
      "[save] efficientnet_b0_train_0480000.npz | 20000 esempi | 1223.6s | 16.3 img/s\n",
      "[save] efficientnet_b0_train_0500000.npz | 20000 esempi | 1212.0s | 16.5 img/s\n",
      "[save] efficientnet_b0_train_0520000.npz | 20000 esempi | 1220.6s | 16.4 img/s\n",
      "[save] efficientnet_b0_train_0540000.npz | 20000 esempi | 1218.9s | 16.4 img/s\n",
      "[save] efficientnet_b0_train_0560000.npz | 20000 esempi | 1233.1s | 16.2 img/s\n",
      "[save] efficientnet_b0_train_0580000.npz | 20000 esempi | 1218.7s | 16.4 img/s\n",
      "[save] efficientnet_b0_train_0600000.npz | 20000 esempi | 1203.3s | 16.6 img/s\n",
      "[save] efficientnet_b0_train_0620000.npz | 20000 esempi | 1221.7s | 16.4 img/s\n",
      "[save] efficientnet_b0_train_0640000.npz | 20000 esempi | 1213.0s | 16.5 img/s\n",
      "[save] efficientnet_b0_train_0660000.npz | 20000 esempi | 1211.7s | 16.5 img/s\n",
      "[save] efficientnet_b0_train_0680000.npz | 20000 esempi | 1220.9s | 16.4 img/s\n",
      "[save] efficientnet_b0_train_0700000.npz | 20000 esempi | 1225.7s | 16.3 img/s\n",
      "[save] efficientnet_b0_train_0720000.npz | 20000 esempi | 1206.5s | 16.6 img/s\n",
      "[save] efficientnet_b0_train_0740000.npz | 20000 esempi | 1230.1s | 16.3 img/s\n",
      "[save] efficientnet_b0_train_0760000.npz | 20000 esempi | 1219.5s | 16.4 img/s\n",
      "[save] efficientnet_b0_train_0780000.npz | 20000 esempi | 1211.0s | 16.5 img/s\n",
      "[save] efficientnet_b0_train_0800000.npz | 20000 esempi | 1217.8s | 16.4 img/s\n",
      "[save] efficientnet_b0_train_0820000.npz | 20000 esempi | 1207.0s | 16.6 img/s\n",
      "[save] efficientnet_b0_train_0840000.npz | 20000 esempi | 1213.3s | 16.5 img/s\n",
      "[save] efficientnet_b0_train_0860000.npz | 20000 esempi | 1212.7s | 16.5 img/s\n",
      "[save] efficientnet_b0_train_0880000.npz | 20000 esempi | 1197.3s | 16.7 img/s\n",
      "[save] efficientnet_b0_train_0900000.npz | 20000 esempi | 1209.9s | 16.5 img/s\n",
      "[save] efficientnet_b0_train_0920000.npz | 20000 esempi | 1214.1s | 16.5 img/s\n",
      "[save] efficientnet_b0_train_0940000.npz | 20000 esempi | 1225.2s | 16.3 img/s\n",
      "[save] efficientnet_b0_train_0960000.npz | 48 esempi | 3.1s | 15.7 img/s\n",
      "[train] Concateno 49 shard...\n",
      "[train] File unico: efficientnet_b0_train_ALL.npz | 960048 esempi totali\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[-0.08969685,  0.10721488, -0.05978236, ..., -0.10028088,\n",
       "          0.00112186,  0.52130145],\n",
       "        [ 0.05077013,  0.0330933 , -0.01632524, ..., -0.08097073,\n",
       "         -0.06800617, -0.09015599],\n",
       "        [ 0.08415666,  0.41065317,  0.0378902 , ...,  0.27694616,\n",
       "          0.974736  , -0.17756397],\n",
       "        ...,\n",
       "        [-0.12931013,  0.34465432, -0.13878323, ..., -0.14236386,\n",
       "          0.63322747, -0.14479609],\n",
       "        [-0.04166615,  0.8030047 ,  0.00396485, ..., -0.09260282,\n",
       "          0.21869075, -0.12982321],\n",
       "        [-0.14429834, -0.08170366, -0.18868421, ..., -0.0985931 ,\n",
       "         -0.1829363 , -0.15703775]], dtype=float32),\n",
       " array(['brentrivera-1543333336599822270',\n",
       "        'brentrivera-1543799326014076320',\n",
       "        'brentrivera-1544838263016975056', ...,\n",
       "        'willljns-1900980824614909347',\n",
       "        'viaggio_animamente-1732100330503797620',\n",
       "        'viaggio_animamente-1794516667193399367'], dtype=object))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_samples = build_samples(train_df)\n",
    "extract_and_save(\"train\", train_samples, eval_tfms, out_dir=\"D:/dataset/efficientnetb0_emb\", shard_size=20000, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3889b30-eabd-4c5d-8953-da618fac6d56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] Totale esempi: 556982\n",
      "[save] efficientnet_b0_val_0000000.npz | 20000 esempi | 1308.1s | 15.3 img/s\n",
      "[save] efficientnet_b0_val_0020000.npz | 20000 esempi | 1285.2s | 15.6 img/s\n",
      "[save] efficientnet_b0_val_0040000.npz | 20000 esempi | 1287.2s | 15.5 img/s\n",
      "[save] efficientnet_b0_val_0060000.npz | 20000 esempi | 1283.0s | 15.6 img/s\n",
      "[save] efficientnet_b0_val_0080000.npz | 20000 esempi | 1279.3s | 15.6 img/s\n",
      "[save] efficientnet_b0_val_0100000.npz | 20000 esempi | 1282.3s | 15.6 img/s\n",
      "[save] efficientnet_b0_val_0120000.npz | 20000 esempi | 1276.4s | 15.7 img/s\n",
      "[save] efficientnet_b0_val_0140000.npz | 20000 esempi | 1287.2s | 15.5 img/s\n",
      "[save] efficientnet_b0_val_0160000.npz | 20000 esempi | 1300.4s | 15.4 img/s\n",
      "[save] efficientnet_b0_val_0180000.npz | 20000 esempi | 1273.0s | 15.7 img/s\n",
      "[save] efficientnet_b0_val_0200000.npz | 20000 esempi | 1273.5s | 15.7 img/s\n",
      "[save] efficientnet_b0_val_0220000.npz | 20000 esempi | 1273.4s | 15.7 img/s\n",
      "[save] efficientnet_b0_val_0240000.npz | 20000 esempi | 1274.8s | 15.7 img/s\n",
      "[save] efficientnet_b0_val_0260000.npz | 20000 esempi | 1288.7s | 15.5 img/s\n",
      "[save] efficientnet_b0_val_0280000.npz | 20000 esempi | 1281.3s | 15.6 img/s\n",
      "[save] efficientnet_b0_val_0300000.npz | 20000 esempi | 1289.0s | 15.5 img/s\n",
      "[save] efficientnet_b0_val_0320000.npz | 20000 esempi | 1269.3s | 15.8 img/s\n",
      "[save] efficientnet_b0_val_0340000.npz | 20000 esempi | 1270.9s | 15.7 img/s\n",
      "[save] efficientnet_b0_val_0360000.npz | 20000 esempi | 1275.6s | 15.7 img/s\n",
      "[save] efficientnet_b0_val_0380000.npz | 20000 esempi | 1266.3s | 15.8 img/s\n",
      "[save] efficientnet_b0_val_0400000.npz | 20000 esempi | 1285.9s | 15.6 img/s\n",
      "[save] efficientnet_b0_val_0420000.npz | 20000 esempi | 1280.3s | 15.6 img/s\n",
      "[save] efficientnet_b0_val_0440000.npz | 20000 esempi | 1254.1s | 15.9 img/s\n",
      "[save] efficientnet_b0_val_0460000.npz | 20000 esempi | 1257.0s | 15.9 img/s\n",
      "[save] efficientnet_b0_val_0480000.npz | 20000 esempi | 1258.6s | 15.9 img/s\n",
      "[save] efficientnet_b0_val_0500000.npz | 20000 esempi | 1261.9s | 15.8 img/s\n",
      "[save] efficientnet_b0_val_0520000.npz | 20000 esempi | 1259.2s | 15.9 img/s\n",
      "[save] efficientnet_b0_val_0540000.npz | 16982 esempi | 1082.4s | 15.7 img/s\n",
      "[val] Concateno 28 shard...\n",
      "[val] File unico: efficientnet_b0_val_ALL.npz | 556982 esempi totali\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[-0.00955195,  0.50942224, -0.02472188, ..., -0.08392821,\n",
       "          0.2056811 , -0.10758663],\n",
       "        [-0.06945565,  0.01800106, -0.16118643, ..., -0.08920514,\n",
       "         -0.0598452 ,  0.5940528 ],\n",
       "        [-0.11799315, -0.12160274,  0.21269923, ..., -0.08459441,\n",
       "         -0.08547642,  1.6258874 ],\n",
       "        ...,\n",
       "        [ 0.90571356, -0.03089917, -0.06676721, ...,  0.17215267,\n",
       "          0.37960213,  0.96493304],\n",
       "        [-0.10017259, -0.15703921,  0.09351613, ..., -0.10389128,\n",
       "         -0.01287235,  0.0635795 ],\n",
       "        [-0.12107382, -0.13659331,  0.5893331 , ..., -0.10891076,\n",
       "          0.91433775,  0.46491456]], dtype=float32),\n",
       " array(['coffeethentravel-1903359253075455932',\n",
       "        'coffeethentravel-1907017958346063810',\n",
       "        'coffeethentravel-1907811296334629541', ...,\n",
       "        'victoirefouquets-1923190337942107249',\n",
       "        'victorborsuk-1916192906608627066',\n",
       "        'victorborsuk-1916192906608627066'], dtype=object))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_samples   = build_samples(val_df)\n",
    "extract_and_save(\"val\", val_samples, eval_tfms, out_dir=\"D:/dataset/efficientnetb0_emb\", shard_size=20000, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e588153a-c16b-42a4-a415-f56bb75ec674",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test] Totale esempi: 588557\n",
      "[save] efficientnet_b0_test_0000000.npz | 20000 esempi | 1276.2s | 15.7 img/s\n",
      "[save] efficientnet_b0_test_0020000.npz | 20000 esempi | 1272.1s | 15.7 img/s\n",
      "[save] efficientnet_b0_test_0040000.npz | 20000 esempi | 1261.5s | 15.9 img/s\n",
      "[save] efficientnet_b0_test_0060000.npz | 20000 esempi | 1259.3s | 15.9 img/s\n",
      "[save] efficientnet_b0_test_0080000.npz | 20000 esempi | 1254.6s | 15.9 img/s\n",
      "[save] efficientnet_b0_test_0100000.npz | 20000 esempi | 1249.2s | 16.0 img/s\n",
      "[save] efficientnet_b0_test_0120000.npz | 20000 esempi | 1266.2s | 15.8 img/s\n",
      "[save] efficientnet_b0_test_0140000.npz | 20000 esempi | 1255.5s | 15.9 img/s\n",
      "[save] efficientnet_b0_test_0160000.npz | 20000 esempi | 1274.1s | 15.7 img/s\n",
      "[save] efficientnet_b0_test_0180000.npz | 20000 esempi | 1255.6s | 15.9 img/s\n",
      "[save] efficientnet_b0_test_0200000.npz | 20000 esempi | 1247.6s | 16.0 img/s\n",
      "[save] efficientnet_b0_test_0220000.npz | 20000 esempi | 1265.8s | 15.8 img/s\n",
      "[save] efficientnet_b0_test_0240000.npz | 20000 esempi | 1272.1s | 15.7 img/s\n",
      "[save] efficientnet_b0_test_0260000.npz | 20000 esempi | 1262.4s | 15.8 img/s\n",
      "[save] efficientnet_b0_test_0280000.npz | 20000 esempi | 1285.0s | 15.6 img/s\n",
      "[save] efficientnet_b0_test_0300000.npz | 20000 esempi | 1273.2s | 15.7 img/s\n",
      "[save] efficientnet_b0_test_0320000.npz | 20000 esempi | 1268.9s | 15.8 img/s\n",
      "[save] efficientnet_b0_test_0340000.npz | 20000 esempi | 1274.1s | 15.7 img/s\n",
      "[save] efficientnet_b0_test_0360000.npz | 20000 esempi | 1295.5s | 15.4 img/s\n",
      "[save] efficientnet_b0_test_0380000.npz | 20000 esempi | 1309.3s | 15.3 img/s\n",
      "[save] efficientnet_b0_test_0400000.npz | 20000 esempi | 1312.0s | 15.2 img/s\n",
      "[save] efficientnet_b0_test_0420000.npz | 20000 esempi | 1321.6s | 15.1 img/s\n",
      "[save] efficientnet_b0_test_0440000.npz | 20000 esempi | 1297.9s | 15.4 img/s\n",
      "[save] efficientnet_b0_test_0460000.npz | 20000 esempi | 1301.7s | 15.4 img/s\n",
      "[save] efficientnet_b0_test_0480000.npz | 20000 esempi | 1293.7s | 15.5 img/s\n",
      "[save] efficientnet_b0_test_0500000.npz | 20000 esempi | 1300.8s | 15.4 img/s\n",
      "[save] efficientnet_b0_test_0520000.npz | 20000 esempi | 1285.8s | 15.6 img/s\n",
      "[save] efficientnet_b0_test_0540000.npz | 20000 esempi | 1291.9s | 15.5 img/s\n",
      "[save] efficientnet_b0_test_0560000.npz | 20000 esempi | 1301.9s | 15.4 img/s\n",
      "[save] efficientnet_b0_test_0580000.npz | 8557 esempi | 570.3s | 15.0 img/s\n",
      "[test] Concateno 30 shard...\n",
      "[test] File unico: efficientnet_b0_test_ALL.npz | 588557 esempi totali\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[-0.11214414,  0.21377252, -0.02436068, ...,  0.00886863,\n",
       "         -0.11792702, -0.14089029],\n",
       "        [ 0.910225  ,  0.2848291 , -0.05918846, ...,  0.4655865 ,\n",
       "          0.18165158,  0.0702652 ],\n",
       "        [-0.08773034, -0.12038821, -0.12598914, ..., -0.13597332,\n",
       "         -0.12463147,  0.00323523],\n",
       "        ...,\n",
       "        [ 0.43508133, -0.03962286,  0.03036041, ...,  0.25463566,\n",
       "         -0.07364696, -0.05859775],\n",
       "        [-0.02892335, -0.14100108,  0.52792597, ...,  0.01876375,\n",
       "         -0.03665268, -0.10178239],\n",
       "        [-0.0559464 , -0.03932384,  0.28081572, ...,  0.4798931 ,\n",
       "          0.47459742, -0.14791866]], dtype=float32),\n",
       " array(['coffeethentravel-1924875490145956005',\n",
       "        'coffeethentravel-1927668952411117227',\n",
       "        'coffeethentravel-1928708312795253682', ...,\n",
       "        'victoirefouquets-1927519468976779024',\n",
       "        'victoirefouquets-1937798696130142630',\n",
       "        'victoirefouquets-1946535289107301734'], dtype=object))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_samples  = build_samples(test_df)\n",
    "extract_and_save(\"test\", test_samples, eval_tfms, out_dir= \"D:/dataset/efficientnetb0_emb\", shard_size=20000, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451aa018-0b88-4f80-9de9-72d9291ca3e0",
   "metadata": {},
   "source": [
    "# LOAD EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e63b0684-904e-4f10-84fa-c363cf0c8295",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dir = Path(\"D:/dataset/efficientnetb0_emb\")\n",
    "MODEL_NAME = \"efficientnet_b0\" \n",
    "\n",
    "def load_effnet_split(split_name, emb_dir=emb_dir, model_name=MODEL_NAME):\n",
    "    all_path = emb_dir / f\"{model_name}_{split_name}_ALL.npz\"\n",
    "    data = np.load(all_path, allow_pickle=True)\n",
    "    F = data[\"feats\"]\n",
    "    P = data[\"post_id\"]\n",
    "    print(split_name, F.shape, len(P))\n",
    "    return F, P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12df1e42-30d3-4b79-9733-6e90f2347121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (960048, 1280) 960048\n",
      "val (556982, 1280) 556982\n"
     ]
    }
   ],
   "source": [
    "X_train, ids_train = load_effnet_split(\"train\")\n",
    "X_val, ids_val = load_effnet_split(\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e269f19d-65ac-4349-b08b-f9a11245ceb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "post_id unici in ids_train: 773497\n",
      "post_id unici in ids_val: 412325\n"
     ]
    }
   ],
   "source": [
    "unique_posts_tr = len(np.unique(ids_train))\n",
    "unique_posts_va = len(np.unique(ids_val))\n",
    "print(\"post_id unici in ids_train:\", unique_posts_tr)\n",
    "print(\"post_id unici in ids_val:\", unique_posts_va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85f1fe75-c925-4bc1-8536-6b55b2460038",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_by_post(F, P, agg=\"mean\"):\n",
    "    df = pd.DataFrame({\n",
    "        \"post_id\": P,\n",
    "        \"feat\": list(F)\n",
    "    })\n",
    "\n",
    "    if agg == \"mean\":\n",
    "        agg_func = lambda arrs: np.mean(np.stack(arrs), axis=0)\n",
    "    elif agg == \"max\":\n",
    "        agg_func = lambda arrs: np.max(np.stack(arrs), axis=0)\n",
    "    else:\n",
    "        raise ValueError(\"agg deve essere 'mean' o 'max'\")\n",
    "\n",
    "    df_post = (\n",
    "        df.groupby(\"post_id\")[\"feat\"]\n",
    "          .apply(agg_func)\n",
    "          .reset_index()\n",
    "    )\n",
    "    # return one record per post\n",
    "    return df_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d75209a2-c193-4335-bbef-05edb1f0d65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_img = aggregate_by_post(X_train, ids_train, agg=\"mean\")\n",
    "df_val_img = aggregate_by_post(X_val, ids_val, agg=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee5c6171-49fa-45d6-8ede-241bd53d966e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(773497, 2) (412325, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df_train_img.shape, df_val_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e57ca817-6633-4668-bff5-750e4ced9983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up ready\n"
     ]
    }
   ],
   "source": [
    "DB_PATH = \"D:/db/meta.duckdb\"\n",
    "con = duckdb.connect(DB_PATH)\n",
    "try:\n",
    "    con.execute(\"PRAGMA threads=8;\")\n",
    "except duckdb.InvalidInputException:\n",
    "    pass\n",
    "\n",
    "print(\"Set up ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a685c41f-5510-4da9-b196-339a06c4d2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_ids = con.sql(\"\"\"SELECT post_id, er_bins FROM md1718 WHERE split = 'train'\"\"\").df()\n",
    "y_val_ids = con.sql(\"\"\"SELECT post_id, er_bins FROM md1718 WHERE split = 'validation'\"\"\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0c8787a-d85a-4134-b400-a4bf7db9a85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train_img.merge(\n",
    "    y_tr_ids[[\"post_id\", \"er_bins\"]],\n",
    "    on=\"post_id\", how=\"inner\"\n",
    ")\n",
    "\n",
    "df_val = df_val_img.merge(\n",
    "    y_val_ids[[\"post_id\", \"er_bins\"]],\n",
    "    on=\"post_id\", how=\"inner\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10814d5c-136a-495a-acca-abf2c5c0a030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat is an array, where the array represent the embedding. It needs to be transformed into a matrix\n",
    "X_tr = np.stack(df_train[\"feat\"].values)\n",
    "y_tr = df_train[\"er_bins\"].values\n",
    "\n",
    "X_va = np.stack(df_val[\"feat\"].values)\n",
    "y_va = df_val[\"er_bins\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08eed57e-01af-48f2-a897-e18c5f53d84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(773497, 1280) (412325, 1280) (773497,) (412325,)\n"
     ]
    }
   ],
   "source": [
    "print(X_tr.shape, X_va.shape, y_tr.shape, y_va.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e62733dc-6d45-4059-b1c2-9df01894c791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    100pintas-1769662389073991144\n",
       "1    100pintas-1782702664733979876\n",
       "2    100pintas-1797067212467389817\n",
       "3    100pintas-1807955339238986900\n",
       "4    100pintas-1808039696742034708\n",
       "Name: post_id, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['post_id'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd2cd3c9-0606-4c80-bf39-fafa057d27a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['medium', 'medium', 'medium', 'medium', 'very_high'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83f0642a-400d-43f6-bec1-f67f24fc9b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_tr = df_train['post_id'].values\n",
    "ids_va = df_val['post_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0aa0e5d-b1f9-4057-90cf-f4da111ec394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1531"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del X_train, X_val, df_train, df_train_img, df_val, df_val_img, ids_train, ids_val, y_tr_ids, y_val_ids\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca223ce7-31d1-4fc7-9a5e-71597bdb3248",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\n",
    "    \"D:/dataset/efficientnetb0_emb/train_data.npz\",\n",
    "    X=X_tr,\n",
    "    y=y_tr,\n",
    "    ids = ids_tr\n",
    ")\n",
    "\n",
    "np.savez_compressed(\n",
    "    \"D:/dataset/efficientnetb0_emb/val_data.npz\",\n",
    "    X=X_va,\n",
    "    y=y_va,\n",
    "    ids = ids_va\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66b8b98e-a1bd-45d6-94b8-30667b850792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test (588557, 1280) 588557\n",
      "post_id unici in ids_test: 423604\n",
      "(423604, 2)\n"
     ]
    }
   ],
   "source": [
    "X_test, ids_test = load_effnet_split(\"test\")\n",
    "unique_posts_te = len(np.unique(ids_test))\n",
    "print(\"post_id unici in ids_test:\", unique_posts_te)\n",
    "df_test_img = aggregate_by_post(X_test, ids_test, agg=\"mean\")\n",
    "print(df_test_img.shape)\n",
    "y_te_ids = con.sql(\"\"\"SELECT post_id, er_bins FROM md1718 WHERE split = 'test'\"\"\").df()\n",
    "df_te = df_test_img.merge(\n",
    "    y_te_ids[[\"post_id\", \"er_bins\"]],\n",
    "    on=\"post_id\", how=\"inner\"\n",
    ")\n",
    "\n",
    "X_te = np.stack(df_te[\"feat\"].values)\n",
    "y_te = df_te[\"er_bins\"].values\n",
    "ids_te = df_te['post_id'].values\n",
    "\n",
    "np.savez_compressed(\n",
    "    \"D:/dataset/efficientnetb0_emb/test_data.npz\",\n",
    "    X=X_te,\n",
    "    y=y_te,\n",
    "    ids = ids_te\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60dd2a02-42e7-4c0d-b9af-aa772d824a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "521"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = np.load(\"D:/dataset/efficientnetb0_emb/train_data.npz\", allow_pickle = True)\n",
    "X_tr = train_data[\"X\"]\n",
    "y_tr = train_data[\"y\"]\n",
    "\n",
    "val_data = np.load(\"D:/dataset/efficientnetb0_emb/val_data.npz\", allow_pickle = True)\n",
    "X_va = val_data[\"X\"]\n",
    "y_va = val_data[\"y\"]\n",
    "\n",
    "del train_data, val_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bf1805-b30a-4691-8e4d-0225ebf0a4ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination: {'alpha': 1e-05, 'average': False, 'class_weight': None}\n",
      "macro-F1 (val): 0.21087314492196318 | accuracy (val): 0.23118898926817438\n",
      "\n",
      "Combination: {'alpha': 1e-05, 'average': False, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.17910031035258323 | accuracy (val): 0.2193221366640393\n",
      "\n",
      "Combination: {'alpha': 1e-05, 'average': True, 'class_weight': None}\n",
      "macro-F1 (val): 0.25418532318082965 | accuracy (val): 0.2557666888983205\n",
      "\n",
      "Combination: {'alpha': 1e-05, 'average': True, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.25074167495132277 | accuracy (val): 0.26270539016552474\n",
      "\n",
      "Combination: {'alpha': 0.0001, 'average': False, 'class_weight': None}\n",
      "macro-F1 (val): 0.20017188705326125 | accuracy (val): 0.22225671496998728\n",
      "\n",
      "Combination: {'alpha': 0.0001, 'average': False, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.1948621138196483 | accuracy (val): 0.21830109743527557\n",
      "\n",
      "Combination: {'alpha': 0.0001, 'average': True, 'class_weight': None}\n",
      "macro-F1 (val): 0.2528260323979179 | accuracy (val): 0.25427029648941973\n",
      "\n",
      "Combination: {'alpha': 0.0001, 'average': True, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.251382939369629 | accuracy (val): 0.2618686715576305\n",
      "\n",
      "Combination: {'alpha': 0.001, 'average': False, 'class_weight': None}\n",
      "macro-F1 (val): 0.21798802230937403 | accuracy (val): 0.22896744073243194\n",
      "\n",
      "Combination: {'alpha': 0.001, 'average': False, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.21630459305710606 | accuracy (val): 0.22574910568119808\n",
      "\n",
      "Combination: {'alpha': 0.001, 'average': True, 'class_weight': None}\n",
      "macro-F1 (val): 0.2530379776489283 | accuracy (val): 0.2541999636209301\n",
      "\n",
      "Combination: {'alpha': 0.001, 'average': True, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.25027987063933405 | accuracy (val): 0.26028981992360395\n",
      "\n",
      "Combination: {'alpha': 0.01, 'average': False, 'class_weight': None}\n",
      "macro-F1 (val): 0.19520096310394594 | accuracy (val): 0.2177578366579761\n",
      "\n",
      "Combination: {'alpha': 0.01, 'average': False, 'class_weight': 'balanced'}\n",
      "macro-F1 (val): 0.19434648823705056 | accuracy (val): 0.21927605650882193\n",
      "\n",
      "Combination: {'alpha': 0.01, 'average': True, 'class_weight': None}\n",
      "macro-F1 (val): 0.25057217669355214 | accuracy (val): 0.25418056145031226\n",
      "\n",
      "Combination: {'alpha': 0.01, 'average': True, 'class_weight': 'balanced'}\n"
     ]
    }
   ],
   "source": [
    "# SGD\n",
    "param_grid = {\n",
    "    \"alpha\": [1e-5, 1e-4, 1e-3, 1e-2],\n",
    "    \"class_weight\": [None, \"balanced\"]\n",
    "}\n",
    "\n",
    "results = []\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    print(f\"\\nCombination: {params}\")\n",
    "\n",
    "    clf = SGDClassifier(\n",
    "        loss=\"hinge\",            \n",
    "        penalty=\"l2\",            \n",
    "        **params,\n",
    "        average = True,\n",
    "        random_state=42,\n",
    "        max_iter=1000,\n",
    "        tol=1e-3,\n",
    "    )\n",
    "\n",
    "    clf.fit(X_tr, y_tr)\n",
    "\n",
    "    y_val_pred = clf.predict(X_va)\n",
    "\n",
    "    macro_f1 = f1_score(y_va, y_val_pred, average=\"macro\")\n",
    "    acc = accuracy_score(y_va, y_val_pred)\n",
    "\n",
    "    print(f\"macro-F1 (val): {macro_f1} | accuracy (val): {acc}\")\n",
    "\n",
    "    results.append({\n",
    "        \"alpha\": params[\"alpha\"],\n",
    "        \"class_weight\": params[\"class_weight\"],\n",
    "        \"val_macro_f1\": macro_f1,\n",
    "        \"val_accuracy\": acc,\n",
    "    })\n",
    "\n",
    "    if macro_f1 > best_score:\n",
    "        best_score = macro_f1\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\nBest hyperparameter configuration:\")\n",
    "print(best_params)\n",
    "print(\"Validation macro-F1:\", best_score)\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(\"val_macro_f1\", ascending=False)\n",
    "print(\"\\nOrdered results by macro-F1 (validation):\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71392ce0-defc-4261-80fe-df3205eb247f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination: {'var_smoothing': 1e-09}\n",
      "macro-F1 (val): 0.2096 | accuracy (val): 0.2616\n",
      "\n",
      "Combination: {'var_smoothing': 1e-08}\n",
      "macro-F1 (val): 0.2096 | accuracy (val): 0.2616\n",
      "\n",
      "Combination: {'var_smoothing': 1e-07}\n",
      "macro-F1 (val): 0.2096 | accuracy (val): 0.2616\n",
      "\n",
      "Combination: {'var_smoothing': 1e-06}\n",
      "macro-F1 (val): 0.2096 | accuracy (val): 0.2616\n",
      "\n",
      "Best hyperparameter configuration:\n",
      "{'var_smoothing': 1e-09}\n",
      "Validation macro-F1: 0.2096407068589068\n",
      "\n",
      "Ordered results by macro-F1 (validation):\n",
      "   var_smoothing  val_macro_f1  val_accuracy\n",
      "0   1.000000e-09      0.209641      0.261595\n",
      "1   1.000000e-08      0.209641      0.261595\n",
      "2   1.000000e-07      0.209641      0.261595\n",
      "3   1.000000e-06      0.209639      0.261592\n"
     ]
    }
   ],
   "source": [
    "# NAIVE BAYES - GAUSSIAN\n",
    "param_grid_nb = {\n",
    "    \"var_smoothing\": [1e-9, 1e-8, 1e-7, 1e-6]\n",
    "}\n",
    "\n",
    "results = []\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "for params in ParameterGrid(param_grid_nb):\n",
    "    print(f\"\\nCombination: {params}\")\n",
    "\n",
    "    clf = GaussianNB(**params)\n",
    "\n",
    "    # Fit su TRAIN\n",
    "    clf.fit(X_tr, y_tr)\n",
    "\n",
    "    # Valutazione su VALIDATION\n",
    "    y_val_pred = clf.predict(X_va)\n",
    "\n",
    "    macro_f1 = f1_score(y_va, y_val_pred, average=\"macro\")\n",
    "    acc = accuracy_score(y_va, y_val_pred)\n",
    "\n",
    "    print(f\"macro-F1 (val): {macro_f1:.4f} | accuracy (val): {acc:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        \"var_smoothing\": params[\"var_smoothing\"],\n",
    "        \"val_macro_f1\": macro_f1,\n",
    "        \"val_accuracy\": acc,\n",
    "    })\n",
    "\n",
    "    # Aggiorno il best model in base alla macro-F1\n",
    "    if macro_f1 > best_score:\n",
    "        best_score = macro_f1\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\nBest hyperparameter configuration:\")\n",
    "print(best_params)\n",
    "print(\"Validation macro-F1:\", best_score)\n",
    "\n",
    "# Metto i risultati in un DataFrame per ispezionarli meglio\n",
    "results_df = pd.DataFrame(results).sort_values(\"val_macro_f1\", ascending=False)\n",
    "print(\"\\nOrdered results by macro-F1 (validation):\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcd977dd-eee2-4719-8a5f-dedf9da36971",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.2014 | accuracy (val): 0.2366\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.1975 | accuracy (val): 0.2363\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.1957 | accuracy (val): 0.2367\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.2024 | accuracy (val): 0.2363\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.1981 | accuracy (val): 0.2364\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.1965 | accuracy (val): 0.2367\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.1978 | accuracy (val): 0.2352\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.1944 | accuracy (val): 0.2352\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.1918 | accuracy (val): 0.2347\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.1995 | accuracy (val): 0.2354\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.1947 | accuracy (val): 0.2347\n",
      "\n",
      "Combination: {'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.1924 | accuracy (val): 0.2349\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.2191 | accuracy (val): 0.2388\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.2145 | accuracy (val): 0.2393\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.2113 | accuracy (val): 0.2393\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.2188 | accuracy (val): 0.2392\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.2141 | accuracy (val): 0.2393\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.2118 | accuracy (val): 0.2399\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.2124 | accuracy (val): 0.2356\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.2089 | accuracy (val): 0.2366\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.2064 | accuracy (val): 0.2372\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.2156 | accuracy (val): 0.2378\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.2103 | accuracy (val): 0.2377\n",
      "\n",
      "Combination: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.2063 | accuracy (val): 0.2383\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.2303 | accuracy (val): 0.2388\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.2296 | accuracy (val): 0.2412\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.2268 | accuracy (val): 0.2414\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.2314 | accuracy (val): 0.2396\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.2283 | accuracy (val): 0.2400\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.2260 | accuracy (val): 0.2412\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.2268 | accuracy (val): 0.2376\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.2241 | accuracy (val): 0.2388\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.2200 | accuracy (val): 0.2393\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 30}\n",
      "macro-F1 (val): 0.2264 | accuracy (val): 0.2374\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "macro-F1 (val): 0.2239 | accuracy (val): 0.2387\n",
      "\n",
      "Combination: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 80}\n",
      "macro-F1 (val): 0.2183 | accuracy (val): 0.2383\n",
      "\n",
      "Best hyperparameter configuration (Random Forest):\n",
      "{'max_depth': 12, 'max_features': 0.05, 'min_samples_leaf': 5, 'n_estimators': 30}\n",
      "Validation macro-F1: 0.23139810895213458\n",
      "\n",
      "Ordered results by macro-F1 (validation):\n",
      "    n_estimators  max_depth  min_samples_leaf max_features  val_macro_f1  \\\n",
      "27            30         12                 5         0.05      0.231398   \n",
      "24            30         12                 2         0.05      0.230335   \n",
      "25            50         12                 2         0.05      0.229641   \n",
      "28            50         12                 5         0.05      0.228260   \n",
      "26            80         12                 2         0.05      0.226808   \n",
      "30            30         12                 2         sqrt      0.226795   \n",
      "33            30         12                 5         sqrt      0.226390   \n",
      "29            80         12                 5         0.05      0.225961   \n",
      "31            50         12                 2         sqrt      0.224068   \n",
      "34            50         12                 5         sqrt      0.223891   \n",
      "32            80         12                 2         sqrt      0.220039   \n",
      "12            30         10                 2         0.05      0.219070   \n",
      "15            30         10                 5         0.05      0.218792   \n",
      "35            80         12                 5         sqrt      0.218333   \n",
      "21            30         10                 5         sqrt      0.215618   \n",
      "13            50         10                 2         0.05      0.214504   \n",
      "16            50         10                 5         0.05      0.214131   \n",
      "18            30         10                 2         sqrt      0.212446   \n",
      "17            80         10                 5         0.05      0.211805   \n",
      "14            80         10                 2         0.05      0.211270   \n",
      "22            50         10                 5         sqrt      0.210284   \n",
      "19            50         10                 2         sqrt      0.208909   \n",
      "20            80         10                 2         sqrt      0.206410   \n",
      "23            80         10                 5         sqrt      0.206279   \n",
      "3             30          8                 5         0.05      0.202379   \n",
      "0             30          8                 2         0.05      0.201390   \n",
      "9             30          8                 5         sqrt      0.199533   \n",
      "4             50          8                 5         0.05      0.198091   \n",
      "6             30          8                 2         sqrt      0.197838   \n",
      "1             50          8                 2         0.05      0.197460   \n",
      "5             80          8                 5         0.05      0.196454   \n",
      "2             80          8                 2         0.05      0.195738   \n",
      "10            50          8                 5         sqrt      0.194704   \n",
      "7             50          8                 2         sqrt      0.194424   \n",
      "11            80          8                 5         sqrt      0.192414   \n",
      "8             80          8                 2         sqrt      0.191762   \n",
      "\n",
      "    val_accuracy  \n",
      "27      0.239590  \n",
      "24      0.238802  \n",
      "25      0.241176  \n",
      "28      0.240012  \n",
      "26      0.241380  \n",
      "30      0.237626  \n",
      "33      0.237352  \n",
      "29      0.241237  \n",
      "31      0.238778  \n",
      "34      0.238707  \n",
      "32      0.239270  \n",
      "12      0.238824  \n",
      "15      0.239214  \n",
      "35      0.238254  \n",
      "21      0.237759  \n",
      "13      0.239289  \n",
      "16      0.239260  \n",
      "18      0.235635  \n",
      "17      0.239915  \n",
      "14      0.239333  \n",
      "22      0.237691  \n",
      "19      0.236580  \n",
      "20      0.237177  \n",
      "23      0.238285  \n",
      "3       0.236270  \n",
      "0       0.236568  \n",
      "9       0.235407  \n",
      "4       0.236420  \n",
      "6       0.235179  \n",
      "1       0.236331  \n",
      "5       0.236670  \n",
      "2       0.236706  \n",
      "10      0.234740  \n",
      "7       0.235232  \n",
      "11      0.234907  \n",
      "8       0.234730  \n"
     ]
    }
   ],
   "source": [
    "# RANDOM FOREST\n",
    "param_grid_rf = {\n",
    "    \"n_estimators\": [30, 50, 80],\n",
    "    \"max_depth\": [8, 10, 12],\n",
    "    \"min_samples_leaf\": [2, 5],\n",
    "    \"max_features\": [0.05, \"sqrt\"],\n",
    "}\n",
    "\n",
    "results = []\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "for params in ParameterGrid(param_grid_rf):\n",
    "    print(f\"\\nCombination: {params}\")\n",
    "\n",
    "    clf = RandomForestClassifier(\n",
    "        **params,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Fit su TRAIN\n",
    "    clf.fit(X_tr, y_tr)\n",
    "\n",
    "    # Valutazione su VALIDATION\n",
    "    y_val_pred = clf.predict(X_va)\n",
    "\n",
    "    macro_f1 = f1_score(y_va, y_val_pred, average=\"macro\")\n",
    "    acc = accuracy_score(y_va, y_val_pred)\n",
    "\n",
    "    print(f\"macro-F1 (val): {macro_f1:.4f} | accuracy (val): {acc:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        \"n_estimators\": params[\"n_estimators\"],\n",
    "        \"max_depth\": params[\"max_depth\"],\n",
    "        \"min_samples_leaf\": params[\"min_samples_leaf\"],\n",
    "        \"max_features\": params[\"max_features\"],\n",
    "        \"val_macro_f1\": macro_f1,\n",
    "        \"val_accuracy\": acc,\n",
    "    })\n",
    "\n",
    "    # Aggiorno il best model in base alla macro-F1\n",
    "    if macro_f1 > best_score:\n",
    "        best_score = macro_f1\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\nBest hyperparameter configuration (Random Forest):\")\n",
    "print(best_params)\n",
    "print(\"Validation macro-F1:\", best_score)\n",
    "\n",
    "# Metto i risultati in un DataFrame per ispezionarli meglio\n",
    "results_df_rf = pd.DataFrame(results).sort_values(\"val_macro_f1\", ascending=False)\n",
    "print(\"\\nOrdered results by macro-F1 (validation):\")\n",
    "print(results_df_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f13c643e-4f04-4495-b38a-63887c62b53b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.2517 | accuracy (val): 0.2549\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 150, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.2546 | accuracy (val): 0.2574\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.2552 | accuracy (val): 0.2575\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 150, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.2565 | accuracy (val): 0.2587\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.2517 | accuracy (val): 0.2549\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 150, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.2546 | accuracy (val): 0.2574\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.2550 | accuracy (val): 0.2571\n",
      "\n",
      "Combination: {'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 150, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "macro-F1 (val): 0.2563 | accuracy (val): 0.2584\n",
      "\n",
      "Best hyperparameter configuration (XGBoost):\n",
      "{'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 150, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "Validation macro-F1: 0.2565012111311541\n",
      "\n",
      "Ordered results:\n",
      "   colsample_bytree  gamma  learning_rate  max_depth  n_estimators  \\\n",
      "3               0.5      0            0.1          6           150   \n",
      "7               0.5      1            0.1          6           150   \n",
      "2               0.5      0            0.1          6           100   \n",
      "6               0.5      1            0.1          6           100   \n",
      "1               0.5      0            0.1          4           150   \n",
      "5               0.5      1            0.1          4           150   \n",
      "4               0.5      1            0.1          4           100   \n",
      "0               0.5      0            0.1          4           100   \n",
      "\n",
      "   reg_lambda  subsample  val_macro_f1  val_accuracy  \n",
      "3           1        0.8      0.256501      0.258721  \n",
      "7           1        0.8      0.256275      0.258371  \n",
      "2           1        0.8      0.255242      0.257467  \n",
      "6           1        0.8      0.254984      0.257147  \n",
      "1           1        0.8      0.254637      0.257406  \n",
      "5           1        0.8      0.254581      0.257375  \n",
      "4           1        0.8      0.251741      0.254898  \n",
      "0           1        0.8      0.251739      0.254896  \n"
     ]
    }
   ],
   "source": [
    "# XGBOOST\n",
    "\n",
    "# Convert the labels into numbers\n",
    "le = LabelEncoder()\n",
    "y_tr_enc = le.fit_transform(y_tr)\n",
    "y_val_enc = le.transform(y_va)\n",
    "\n",
    "\n",
    "param_grid_xgb = {\n",
    "    \"n_estimators\": [100, 150],\n",
    "    \"max_depth\": [4, 6],\n",
    "    \"learning_rate\": [0.1],\n",
    "    \"subsample\": [0.8],\n",
    "    \"colsample_bytree\": [0.5],\n",
    "    \"gamma\": [0, 1],\n",
    "    \"reg_lambda\": [1],\n",
    "}\n",
    "\n",
    "results = []\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "for params in ParameterGrid(param_grid_xgb):\n",
    "    print(f\"\\nCombination: {params}\")\n",
    "\n",
    "    clf = XGBClassifier(\n",
    "        **params,\n",
    "        objective=\"multi:softmax\",\n",
    "        num_class=len(np.unique(y_tr_enc)),\n",
    "        tree_method=\"hist\",\n",
    "        eval_metric=\"mlogloss\",\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        verbosity=0,\n",
    "    )\n",
    "\n",
    "    # Fit\n",
    "    clf.fit(X_tr, y_tr_enc)\n",
    "\n",
    "    # Validation\n",
    "    y_val_pred = clf.predict(X_va)\n",
    "\n",
    "    macro_f1 = f1_score(y_val_enc, y_val_pred, average=\"macro\")\n",
    "    acc = accuracy_score(y_val_enc, y_val_pred)\n",
    "\n",
    "    print(f\"macro-F1 (val): {macro_f1:.4f} | accuracy (val): {acc:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        **params,\n",
    "        \"val_macro_f1\": macro_f1,\n",
    "        \"val_accuracy\": acc,\n",
    "    })\n",
    "\n",
    "    if macro_f1 > best_score:\n",
    "        best_score = macro_f1\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\nBest hyperparameter configuration (XGBoost):\")\n",
    "print(best_params)\n",
    "print(\"Validation macro-F1:\", best_score)\n",
    "\n",
    "results_df_xgb = pd.DataFrame(results).sort_values(\"val_macro_f1\", ascending=False)\n",
    "print(\"\\nOrdered results:\")\n",
    "print(results_df_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c240c23-12b2-4be7-9a41-ab5418251851",
   "metadata": {},
   "source": [
    "# PERFORMANCE SUL TEST SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a55aa3d-d944-4cbd-ac7f-88c628aff286",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dir = Path(\"D:/dataset/efficientnetb0_emb\")\n",
    "MODEL_NAME = \"efficientnet_b0\"  # stesso nome di prima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c36758b-6aea-4492-9a5e-cbb6526dd429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (960048, 1280) 960048\n",
      "val (556982, 1280) 556982\n"
     ]
    }
   ],
   "source": [
    "X_train, ids_train = load_effnet_split(\"train\")\n",
    "X_val, ids_val = load_effnet_split(\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "813e0147-afca-45b2-bd67-880763aae9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test (588557, 1280) 588557\n"
     ]
    }
   ],
   "source": [
    "X_test, ids_test = load_effnet_split(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "deb372ec-6b7b-4666-9632-884c9b03a6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "post_id unici in ids_train: 773497\n",
      "post_id unici in ids_val: 412325\n",
      "post_id unici in ids_test: 423604\n"
     ]
    }
   ],
   "source": [
    "unique_posts_tr = len(np.unique(ids_train))\n",
    "unique_posts_va = len(np.unique(ids_val))\n",
    "unique_posts_te = len(np.unique(ids_test))\n",
    "print(\"post_id unici in ids_train:\", unique_posts_tr)\n",
    "print(\"post_id unici in ids_val:\", unique_posts_va)\n",
    "print(\"post_id unici in ids_test:\", unique_posts_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "584892bd-b43c-44bb-9769-7336e32f3baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del unique_posts_tr, unique_posts_va, unique_posts_te\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34e5be66-3166-40b1-b072-4f1de493753f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_img = aggregate_by_post(X_train, ids_train, agg=\"mean\")\n",
    "df_val_img = aggregate_by_post(X_val,   ids_val,   agg=\"mean\")\n",
    "df_test_img = aggregate_by_post(X_test,   ids_test,   agg=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1952b415-b3f6-41f2-8f00-7ccf583c1baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(773497, 2) (412325, 2) (423604, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df_train_img.shape, df_val_img.shape, df_test_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "728ba2ed-f656-470a-90ce-ebae8e5bd7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up ready\n"
     ]
    }
   ],
   "source": [
    "DB_PATH = \"D:/db/meta.duckdb\"\n",
    "con = duckdb.connect(DB_PATH)\n",
    "try:\n",
    "    con.execute(\"PRAGMA threads=8;\")\n",
    "except duckdb.InvalidInputException:\n",
    "    pass\n",
    "\n",
    "print(\"Set up ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82edbd0e-3c3d-4543-b4d6-4a1d92c6f5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_ids = con.sql(\"\"\"SELECT post_id, er_bins FROM md1718 WHERE split = 'train'\"\"\").df()\n",
    "y_val_ids = con.sql(\"\"\"SELECT post_id, er_bins FROM md1718 WHERE split = 'validation'\"\"\").df()\n",
    "y_test_ids = con.sql(\"\"\"SELECT post_id, er_bins FROM md1718 WHERE split = 'test'\"\"\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "219bdf85-4805-4093-aec1-4bd61f16cf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train_img.merge(\n",
    "    y_tr_ids[[\"post_id\", \"er_bins\"]],\n",
    "    on=\"post_id\", how=\"inner\"\n",
    ")\n",
    "\n",
    "df_val = df_val_img.merge(\n",
    "    y_val_ids[[\"post_id\", \"er_bins\"]],\n",
    "    on=\"post_id\", how=\"inner\"\n",
    ")\n",
    "\n",
    "df_test = df_test_img.merge(\n",
    "    y_test_ids[[\"post_id\", \"er_bins\"]],\n",
    "    on=\"post_id\", how=\"inner\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2904851-6904-49d7-bd87-6c93d74d3b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del X_train, X_val, X_test, df_train_img, df_val_img, df_test_img\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce57abb7-9d2c-4ec8-a356-4152ed1e833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = np.stack(df_train[\"feat\"].values)\n",
    "y_tr = df_train[\"er_bins\"].values\n",
    "\n",
    "X_va = np.stack(df_val[\"feat\"].values)\n",
    "y_va = df_val[\"er_bins\"].values\n",
    "\n",
    "X_te = np.stack(df_test[\"feat\"].values)\n",
    "y_te = df_test[\"er_bins\"].values\n",
    "\n",
    "X_trva = np.concatenate((X_tr, X_va), axis = 0)\n",
    "y_trva = np.concatenate((y_tr, y_va), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ba31393-fc16-4cbe-b46a-54d17269878f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1185822, 1280) (423604, 1280) (1185822,) (423604,)\n"
     ]
    }
   ],
   "source": [
    "print(X_trva.shape, X_te.shape, y_trva.shape, y_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44d05af0-773b-4b20-a2e9-78faa4ea8231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_train, df_val, df_test\n",
    "del ids_train, ids_val, ids_test, y_tr_ids, y_val_ids, y_test_ids\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7974d5d1-d535-40fd-b2eb-e98b2c5225e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\n",
    "    \"D:/dataset/efficientnetb0_emb/trainval_data.npz\",\n",
    "    X=X_trva,\n",
    "    y=y_trva\n",
    ")\n",
    "\n",
    "np.savez_compressed(\n",
    "    \"D:/dataset/efficientnetb0_emb/test_data.npz\",\n",
    "    X=X_te,\n",
    "    y=y_te\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43484cbe-7e70-4fd1-ab23-aad32fddebbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.load(\"D:/dataset/efficientnetb0_emb/train_data.npz\", allow_pickle = True)\n",
    "X_tr = train[\"X\"]\n",
    "y_tr = train[\"y\"]\n",
    "\n",
    "test_data = np.load(\"D:/dataset/efficientnetb0_emb/test_data.npz\", allow_pickle = True)\n",
    "X_te = test_data[\"X\"]\n",
    "y_te = test_data[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96f6030e-abdd-4f15-94c0-bfd4e3cc5b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(773497, 1280) (423604, 1280) (773497,) (423604,)\n"
     ]
    }
   ],
   "source": [
    "# del train, test_data\n",
    "# gc.collect()\n",
    "print(X_tr.shape, X_te.shape, y_tr.shape, y_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f24a4f7-c9f7-49ea-9609-cfdf2e7930fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_trva_enc = le.fit_transform(y_trva)\n",
    "y_te_enc = le.transform(y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73492402-8205-486c-8e85-4e99bffd1847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configuration: GaussianNB()\n",
      "macro-F1 (test): 0.2101 | accuracy (test): 0.2641\n",
      "\n",
      "Configuration: RandomForestClassifier(max_depth=12, max_features=0.05, min_samples_leaf=5,\n",
      "                       n_estimators=30, n_jobs=-1, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "cfgs = [\n",
    "    GaussianNB(var_smoothing = 1e-09),\n",
    "    # RandomForestClassifier(\n",
    "    #     max_depth=12, max_features=0.05, min_samples_leaf=5, n_estimators=30, n_jobs=-1, random_state=42\n",
    "    # ),\n",
    "    # XGBClassifier(colsample_bytree = 0.5, gamma = 0, learning_rate = 0.1, max_depth= 6, n_estimators= 150, reg_lambda= 1, subsample= 0.8,\n",
    "    #     objective=\"multi:softmax\",\n",
    "    #     num_class=len(np.unique(y_trva_enc)),\n",
    "    #     tree_method=\"hist\", eval_metric=\"mlogloss\",\n",
    "    #     n_jobs=-1, random_state=42, verbosity=0\n",
    "    # ),\n",
    "]\n",
    "\n",
    "\n",
    "for cfg in cfgs:\n",
    "    print(f\"\\nConfiguration: {cfg}\")\n",
    "\n",
    "    # XGB requires a numerical target\n",
    "    if isinstance(cfg, XGBClassifier):\n",
    "        cfg.fit(X_trva, y_trva_enc)\n",
    "        y_te_pred = cfg.predict(X_te)\n",
    "        macro_f1 = f1_score(y_te_enc, y_te_pred, average=\"macro\")\n",
    "        acc = accuracy_score(y_te_enc, y_te_pred)\n",
    "\n",
    "    else:\n",
    "        cfg.fit(X_trva, y_trva)\n",
    "        y_te_pred = cfg.predict(X_te)\n",
    "        macro_f1 = f1_score(y_te, y_te_pred, average=\"macro\")\n",
    "        acc = accuracy_score(y_te, y_te_pred)\n",
    "\n",
    "    print(f\"macro-F1 (test): {macro_f1:.4f} | accuracy (test): {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0475184a-3454-4ca7-a250-fcf34aff5188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configuration: RandomForestClassifier(max_depth=12, max_features=0.05, min_samples_leaf=5,\n",
      "                       n_estimators=30, n_jobs=-1, random_state=42)\n",
      "macro-F1 (test): 0.2525 | accuracy (test): 0.2544\n",
      "\n",
      "Configuration: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.5, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric='mlogloss',\n",
      "              feature_types=None, feature_weights=None, gamma=0,\n",
      "              grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=150, n_jobs=-1, num_class=5, ...)\n",
      "macro-F1 (test): 0.2554 | accuracy (test): 0.2695\n",
      "\n",
      "Configuration: SGDClassifier(alpha=1.29e-05, max_iter=2000, n_jobs=-1, random_state=42)\n",
      "macro-F1 (test): 0.1776 | accuracy (test): 0.2164\n"
     ]
    }
   ],
   "source": [
    "cfgs = [\n",
    "    # GaussianNB(var_smoothing = 1e-09),\n",
    "    RandomForestClassifier(\n",
    "        max_depth=12, max_features=0.05, min_samples_leaf=5, n_estimators=30, n_jobs=-1, random_state=42\n",
    "    ),\n",
    "    XGBClassifier(colsample_bytree = 0.5, gamma = 0, learning_rate = 0.1, max_depth= 6, n_estimators= 150, reg_lambda= 1, subsample= 0.8,\n",
    "        objective=\"multi:softmax\",\n",
    "        num_class=len(np.unique(y_trva_enc)),\n",
    "        tree_method=\"hist\", eval_metric=\"mlogloss\",\n",
    "        n_jobs=-1, random_state=42, verbosity=0\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "for cfg in cfgs:\n",
    "    print(f\"\\nConfiguration: {cfg}\")\n",
    "\n",
    "    # XGB requires a numerical target\n",
    "    if isinstance(cfg, XGBClassifier):\n",
    "        cfg.fit(X_trva, y_trva_enc)\n",
    "        y_te_pred = cfg.predict(X_te)\n",
    "        macro_f1 = f1_score(y_te_enc, y_te_pred, average=\"macro\")\n",
    "        acc = accuracy_score(y_te_enc, y_te_pred)\n",
    "\n",
    "    else:\n",
    "        cfg.fit(X_trva, y_trva)\n",
    "        y_te_pred = cfg.predict(X_te)\n",
    "        macro_f1 = f1_score(y_te, y_te_pred, average=\"macro\")\n",
    "        acc = accuracy_score(y_te, y_te_pred)\n",
    "\n",
    "    print(f\"macro-F1 (test): {macro_f1:.4f} | accuracy (test): {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13be42de-d8f1-428a-9973-a3f9554ed187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macro-F1 (test): 0.2535 | accuracy (test): 0.2558\n"
     ]
    }
   ],
   "source": [
    "cfg = SGDClassifier(\n",
    "        loss=\"hinge\",\n",
    "        penalty=\"l2\",\n",
    "        alpha = 1e-05,\n",
    "        average = True,\n",
    "        class_weight = None,\n",
    "        random_state=42,\n",
    "        max_iter=1000,\n",
    "        tol=1e-3,\n",
    "    )\n",
    "\n",
    "\n",
    "cfg.fit(X_tr, y_tr)\n",
    "y_te_pred = cfg.predict(X_te)\n",
    "macro_f1 = f1_score(y_te, y_te_pred, average=\"macro\")\n",
    "acc = accuracy_score(y_te, y_te_pred)\n",
    "\n",
    "print(f\"macro-F1 (test): {macro_f1:.4f} | accuracy (test): {acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (CLIP Env)",
   "language": "python",
   "name": "clip_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
